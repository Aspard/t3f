{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensor_nets.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "4PbT4UV21L9p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensor Nets (compressing neural networks)\n",
        "\n",
        "[Open](https://colab.research.google.com/github/Bihaqo/t3f/blob/develop/docs/tutorials/tensor_nets.ipynb) **this page in an interactive mode via Google Colaboratory.**\n",
        "\n",
        "In this notebook we provide an example of how to build a simple Tensor Net (see https://arxiv.org/abs/1509.06569).\n",
        "\n",
        "The main ingredient is the so-called TT-Matrix, a generalization of the Kronecker product matrices, i.e. matrices of the form \n",
        "$$A = A_1 \\otimes A_2 \\cdots \\otimes A_n$$\n",
        "\n",
        "In `t3f` TT-Matrices are represented using the `TensorTrain` class."
      ]
    },
    {
      "metadata": {
        "id": "0Zf7mDAV1L9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eabb2a5e-f0a2-4566-c034-6dac42e19638"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "tf.enable_resource_variables()\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "tf.set_random_seed(0)\n",
        "np.random.seed(0)\n",
        "sess = tf.InteractiveSession()\n",
        "K.set_session(sess)\n",
        "\n",
        "try:\n",
        "    import t3f\n",
        "except ImportError:\n",
        "    # Install T3F if it's not already installed.\n",
        "    !git clone https://github.com/Bihaqo/t3f.git\n",
        "    !cd t3f; pip install .\n",
        "    import t3f"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DTArGyPc1L9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3246e1b-a40f-4450-e884-b8e02a02da2d"
      },
      "cell_type": "code",
      "source": [
        "W = t3f.random_matrix([[4, 7, 4, 7], [5, 5, 5, 5]], tt_rank=2)\n",
        "\n",
        "print(W)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A TT-Matrix of size 784 x 625, underlying tensor shape: (4, 7, 4, 7) x (5, 5, 5, 5), TT-ranks: (1, 2, 2, 2, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oQOaaA4R1L91",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using TT-Matrices we can compactly represent densely connected layers in neural networks, which allows us to greatly reduce number of parameters. Matrix multiplication can be handled by the `t3f.matmul` method which allows for multiplying dense (ordinary) matrices and TT-Matrices. Very simple neural network could look as following (for initialization several options such as `t3f.glorot_initializer`, `t3f.he_initializer` or `t3f.random_matrix` are available):"
      ]
    },
    {
      "metadata": {
        "id": "tLvV49Cd1L93",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "y = tf.placeholder(tf.int64, [None])\n",
        "\n",
        "initializer = t3f.glorot_initializer([[4, 7, 4, 7], [5, 5, 5, 5]], tt_rank=2)\n",
        "W1 = t3f.get_variable('W1', initializer=initializer) \n",
        "b1 = tf.get_variable('b1', shape=[625])\n",
        "h1 = t3f.matmul(x, W1) + b1\n",
        "h1 = tf.nn.relu(h1)\n",
        "\n",
        "W2 = tf.get_variable('W2', shape=[625, 10])\n",
        "b2 = tf.get_variable('b2', shape=[10])\n",
        "h2 = tf.matmul(h1, W2) + b2\n",
        "\n",
        "y_ = tf.one_hot(y, 10)\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=h2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZCtiSnC1L94",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For convenience we have implemented a layer analogous to *Keras* `Dense` layer but with a TT-Matrix instead of an ordinary matrix. An example of fully trainable net is provided below."
      ]
    },
    {
      "metadata": {
        "id": "vJ9KEc201L95",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AVLgpYF_1L99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ad2035ad-9dd2-4c8c-a994-bb60433848b4"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "astcob7O1L9-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some preprocessing..."
      ]
    },
    {
      "metadata": {
        "id": "qoBbdpGP1L9_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train / 127.5 - 1.0\n",
        "x_test = x_test / 127.5 - 1.0\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CEa9GBp81L-C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "tt_layer = t3f.nn.KerasDense(input_dims=[7, 4, 7, 4], output_dims=[5, 5, 5, 5],\n",
        "                             tt_rank=4, activation='relu',\n",
        "                             bias_initializer=1e-3)\n",
        "model.add(tt_layer)\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MApNz_T31L-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "52d6df65-b4df-4882-f084-eda96c944249"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "keras_dense_1 (KerasDense)   (None, 625)               1725      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                6260      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 7,985\n",
            "Trainable params: 7,985\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y4zrSP531L-K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that in the dense layer we only have $1725$ parameters instead of $784 * 625 = 490000$."
      ]
    },
    {
      "metadata": {
        "id": "FyqaT09O1L-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=1e-2)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fF9NrphG1L-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "01796db2-22ed-479c-83d0-b2fae278f036"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=2, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.2311 - acc: 0.9298 - val_loss: 0.1536 - val_acc: 0.9560\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.1380 - acc: 0.9591 - val_loss: 0.1716 - val_acc: 0.9500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86cb2a4400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "J9IVspp61L-R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compression of Dense layers\n",
        "------------------------------------------"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "mIl7XppU1L-S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us now train an ordinary DNN (without TT-Matrices) and show how we can compress it using the TT decomposition. (In contrast to directly training a TT-layer from scratch in the example above.)"
      ]
    },
    {
      "metadata": {
        "id": "FnWQ5MCk1L-S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(625, activation='relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RBS-c6YK1L-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "9273bb8a-26f3-419b-c3f8-f747bc7691d9"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 625)               490625    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                6260      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 496,885\n",
            "Trainable params: 496,885\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SdJIVj5W1L-Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=1e-3)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qdv8q1S61L-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "16a883ef-439d-4ba4-9856-fbc40e573e03"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.2771 - acc: 0.9156 - val_loss: 0.1529 - val_acc: 0.9528\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.1278 - acc: 0.9613 - val_loss: 0.1079 - val_acc: 0.9680\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0960 - acc: 0.9702 - val_loss: 0.1078 - val_acc: 0.9658\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0806 - acc: 0.9744 - val_loss: 0.0948 - val_acc: 0.9714\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0733 - acc: 0.9770 - val_loss: 0.1072 - val_acc: 0.9664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87102116d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "TdLn-FIK1L-g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us convert the matrix used in the Dense layer to the TT-Matrix with tt-ranks equal to 16 (since we trained the network without the low-rank structure assumption we may wish start with high rank values)."
      ]
    },
    {
      "metadata": {
        "id": "TBqfSwZf1L-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0a104a46-b6fe-4657-d1cc-2b2c2a55d900"
      },
      "cell_type": "code",
      "source": [
        "W = model.trainable_weights[0]\n",
        "print(W)\n",
        "Wtt = t3f.to_tt_matrix(W, shape=[[7, 4, 7, 4], [5, 5, 5, 5]], max_tt_rank=16)\n",
        "print(Wtt)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'dense_2/kernel:0' shape=(784, 625) dtype=float32_ref>\n",
            "A TT-Matrix of size 784 x 625, underlying tensor shape: (7, 4, 7, 4) x (5, 5, 5, 5), TT-ranks: (1, 16, 16, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IIbCDkyA1L-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to evaluate the tt-cores of Wtt. We also need to store other parameters for later (biases and the second dense layer)."
      ]
    },
    {
      "metadata": {
        "id": "tscSHv7X1L-i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cores = sess.run(Wtt.tt_cores)\n",
        "other_params = model.get_weights()[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "llryIpkW1L-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can construct a tensor network with the first Dense layer replaced by `Wtt`\n",
        "initialized using the previously computed cores."
      ]
    },
    {
      "metadata": {
        "id": "i8zQfyNu1L-l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "tt_layer = t3f.nn.KerasDense(input_dims=[7, 4, 7, 4], output_dims=[5, 5, 5, 5],\n",
        "                             tt_rank=16, activation='relu')\n",
        "model.add(tt_layer)\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L_BGc2MV1L-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=1e-3)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BllmgHlt1L-q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.set_weights(list(cores) + other_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NwB7UfTV1L-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d51522c4-441e-4e79-9fb4-ff7970c29eda"
      },
      "cell_type": "code",
      "source": [
        "print(\"new accuracy: \", model.evaluate(x_test, y_test)[1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 102us/step\n",
            "new accuracy:  0.6533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rnnru3s51L-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "48ff03a8-dba2-45b2-b9fc-1e0cb0eb9066"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "keras_dense_2 (kerasDense)   (None, 625)               15585     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                6260      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 21,845\n",
            "Trainable params: 21,845\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cba_5ExM1L-5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that even though we now have about 5% of the original number of parameters we still achieve a relatively high accuracy."
      ]
    },
    {
      "metadata": {
        "id": "VFCEZjP11L-5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finetuning the model \n",
        "-------------------------------\n",
        "We can now finetune this tensor network."
      ]
    },
    {
      "metadata": {
        "id": "268p2zec1L-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ae31a89e-1c86-426e-eb06-a470a6ea2357"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=2, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1353 - acc: 0.9589 - val_loss: 0.0983 - val_acc: 0.9710\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0810 - acc: 0.9749 - val_loss: 0.0820 - val_acc: 0.9751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86c9fc22e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "DX2XYk4J1L_A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that we were able to achieve higher validation accuracy than we had in the plain DNN, while keeping the number of parameters extremely small (21845 vs 496885 parameters in the uncompressed model)."
      ]
    },
    {
      "metadata": {
        "id": "w81lLRov1L_A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}