{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST TensorNet example\n",
    "This is an example of building neural networks with a _Tensor Train layer_ (_TT-layer_).\n",
    "\n",
    "In short, the TT-layer is just a fully-connected layer with the weight matrix parametrized as a TT-matrix, which allows it to be much more compact and to use lots of hidden units without slowing down the learning and inference.\n",
    "\n",
    "For the additional information see the following paper:\n",
    "\n",
    "Tensorizing Neural Networks  \n",
    "Alexander Novikov, Dmitry Podoprikhin, Anton Osokin, Dmitry Vetrov; In _Advances in Neural Information Processing Systems 28_ (NIPS-2015) [[arXiv](http://arxiv.org/abs/1509.06569)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import t3f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST data.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build placeholders for the data.\n",
    "x_pl = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "y_pl = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape the images from 28 x 28 to 32 x 32 so it would be easier\n",
    "# to represent the number of pixels (32*32) as a tensor shape (4, 4, 4, 4, 4). \n",
    "x = tf.reshape(x_pl, [-1, 28, 28, 1])\n",
    "x = tf.image.resize_images(x, [32, 32])\n",
    "x = tf.reshape(x, [-1, 32*32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# W1 = tf.get_variable(\"W1\", shape=[32*32, 32*32],\n",
    "#            initializer=tf.contrib.layers.xavier_initializer())\n",
    "# Generate a random TT-matrix of size 1024 x 1024 and make it a variable.\n",
    "W1 = t3f.get_variable(\"W1\",\n",
    "             initializer=t3f.random_matrix(((4, 4, 4, 4, 4), (4, 4, 4, 4, 4)), tt_rank=10))\n",
    "b1 = tf.Variable(tf.zeros([32*32]))\n",
    "# Use t3f.matmul to multiply a TT-matrix by a dense vector matrix x.\n",
    "h1 = tf.nn.relu(t3f.matmul(x, W1) + b1)\n",
    "W2 = tf.get_variable(\"W2\", shape=[32*32, 10],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(h1, W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_pl, logits=y))\n",
    "train_step = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Note that it takes a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x_pl: batch[0], y_pl: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9085\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_pl, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval(feed_dict={x_pl: mnist.test.images, y_pl: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not top notch, but hey, we've used a plain old two layered fully-connected network. Also notice that thanks to the TT-layer, the actual number of parameters is really low: the first (and the largest) fully-connected layer of size 1024 x 1024 uses only 5120 params to represent the TT-matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A TT-Matrix variable of size 1024 x 1024, underlying tensor shape: (4, 4, 4, 4, 4) x (4, 4, 4, 4, 4), TT-ranks: (1, 10, 10, 10, 10, 1)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'number_of_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7fb38550a54c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt3f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'number_of_params'"
     ]
    }
   ],
   "source": [
    "t3f.utils.number_of_params(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5120"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params = 0\n",
    "for core in W1.tt_cores:\n",
    "    num_params += sess.run(tf.size(core))\n",
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
