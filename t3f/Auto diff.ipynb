{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import t3f\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = t3f.random_matrix(([10] * 3, None))\n",
    "w = t3f.get_variable('w', initializer=w)\n",
    "A = t3f.random_matrix(([10] * 3, [10] * 3))\n",
    "A = t3f.get_variable('A', initializer=A)\n",
    "z = t3f.random_matrix(([10] * 3, None))\n",
    "z = t3f.get_variable('z', initializer=z)\n",
    "x = t3f.random_matrix(([10] * 3, None), tt_rank=100)\n",
    "x = t3f.get_variable('x', initializer=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.is_tt_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tangent_space_to_deltas(tt):\n",
    "    if tt.projection_on is None:\n",
    "        raise ValueError('tt argument is supposed to be a projection, but it lacks projection_on field')\n",
    "    num_dims = tt.ndims()\n",
    "    deltas = [None] * num_dims\n",
    "    if tt.is_tt_matrix():\n",
    "        for i in range(1, num_dims - 1):\n",
    "            r1, _, _, r2 = tt.tt_cores[i].get_shape().as_list()\n",
    "            if int(r1 / 2) != r1 / 2:\n",
    "                raise ValueError('tt argument is supposed to be a projection, but its ranks are not even.')\n",
    "            deltas[i] = tt.tt_cores[i][int(r1 / 2):, :, :, :int(r2 / 2)]\n",
    "        _, _, _, r = tt.tt_cores[0].get_shape().as_list()\n",
    "        deltas[0] = tt.tt_cores[0][:, :, :, :int(r / 2)]\n",
    "        r, _, _, _ = tt.tt_cores[num_dims - 1].get_shape().as_list()\n",
    "        deltas[num_dims - 1] = tt.tt_cores[num_dims - 1][int(r / 2):, :, :, :]\n",
    "    else:\n",
    "        for i in range(1, num_dims - 1):\n",
    "            r1, _, r2 = tt.tt_cores[i].get_shape().as_list()\n",
    "            if int(r1 / 2) != r1 / 2:\n",
    "                raise ValueError('tt argument is supposed to be a projection, but its ranks are not even.')\n",
    "            deltas[i] = tt.tt_cores[i][int(r1 / 2):, :, :int(r2 / 2)]\n",
    "        _, _, r = tt.tt_cores[0].get_shape().as_list()\n",
    "        deltas[0] = tt.tt_cores[0][:, :, :int(r / 2)]\n",
    "        r, _, _ = tt.tt_cores[num_dims - 1].get_shape().as_list()\n",
    "        deltas[num_dims - 1] = tt.tt_cores[num_dims - 1][int(r / 2):, :, :]\n",
    "    return deltas\n",
    "\n",
    "def left_q(X, i):\n",
    "    \"\"\"Compute the orthogonal matrix Q_{\\leq i} as defined in [1].\"\"\"\n",
    "    if i < 0:\n",
    "        return np.ones([1, 1], dtype=np.float32)\n",
    "    answ = np.ones([1, 1])\n",
    "    for dim in range(i + 1):\n",
    "        answ = np.tensordot(answ, sess.run(X.tt_cores[dim]), 1)\n",
    "    answ = np.reshape(answ, (-1, answ.shape[-1]))\n",
    "    return answ.astype(np.float32)\n",
    "\n",
    "def right_q(X, i):\n",
    "    \"\"\"Compute the orthogonal matrix Q_{\\geq i} as defined in [1].\"\"\"\n",
    "    if i > X.ndims() - 1:\n",
    "        return np.ones([1, 1], dtype=np.float32)\n",
    "    answ = np.ones([1, 1])\n",
    "    for dim in range(X.ndims() - 1, i - 1, -1):\n",
    "        answ = np.tensordot(sess.run(X.tt_cores[dim]), answ, 1)\n",
    "    answ = np.reshape(answ, (answ.shape[0], -1))\n",
    "    return answ.T.astype(np.float32)\n",
    "\n",
    "def deltas_to_tangent_space(deltas, tt, left, right):\n",
    "    cores = []\n",
    "    dtype = deltas[0].dtype\n",
    "    num_dims = left.ndims()\n",
    "    left_tangent_tt_ranks = t3f.shapes.lazy_tt_ranks(left)\n",
    "    right_tangent_tt_ranks = t3f.shapes.lazy_tt_ranks(left)\n",
    "    raw_shape = t3f.shapes.lazy_raw_shape(left)\n",
    "    right_rank_dim = left.right_tt_rank_dim\n",
    "    left_rank_dim = left.left_tt_rank_dim\n",
    "    for i in range(num_dims):\n",
    "        left_tt_core = left.tt_cores[i]\n",
    "        right_tt_core = right.tt_cores[i]\n",
    "\n",
    "        if i == 0:\n",
    "            tangent_core = tf.concat((deltas[i], left_tt_core),\n",
    "                                     axis=right_rank_dim)\n",
    "        elif i == num_dims - 1:\n",
    "            tangent_core = tf.concat((right_tt_core, deltas[i]),\n",
    "                                     axis=left_rank_dim)\n",
    "        else:\n",
    "            rank_1 = right_tangent_tt_ranks[i]\n",
    "            rank_2 = left_tangent_tt_ranks[i + 1]\n",
    "            if tt.is_tt_matrix():\n",
    "                mode_size_n = raw_shape[0][i]\n",
    "                mode_size_m = raw_shape[1][i]\n",
    "                shape = [rank_1, mode_size_n, mode_size_m, rank_2]\n",
    "            else:\n",
    "                mode_size_n = raw_shape[0][i]\n",
    "                shape = [rank_1, mode_size_n, rank_2]\n",
    "            zeros = tf.zeros(shape, dtype)\n",
    "            upper = tf.concat((right_tt_core, zeros), axis=right_rank_dim)\n",
    "            lower = tf.concat((deltas[i], left_tt_core), axis=right_rank_dim)\n",
    "            tangent_core = tf.concat((upper, lower), axis=left_rank_dim)\n",
    "        cores.append(tangent_core)\n",
    "    tangent = t3f.TensorTrain(cores)\n",
    "    tangent.projection_on = tt\n",
    "    return tangent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _riemannian_grad(func, w, w_projection, left, right):\n",
    "    h = func(w_projection)\n",
    "    cores_grad = tf.gradients(h, w_projection.tt_cores)\n",
    "    deltas = []\n",
    "    for i in range(w.ndims()):\n",
    "        if w.is_tt_matrix():\n",
    "            r1, n, m, r2 = left.tt_cores[i].shape.as_list()\n",
    "        else:\n",
    "            r1, n, r2 = left.tt_cores[i].shape.as_list()\n",
    "        q = tf.reshape(left.tt_cores[i], (-1, r2))\n",
    "        if w.is_tt_matrix():\n",
    "            if i == 0:\n",
    "                curr_grad = cores_grad[i][:, :, :, :r2]\n",
    "            elif i == w.ndims() - 1:\n",
    "                curr_grad = cores_grad[i][r1:, :, :, :]\n",
    "            else:\n",
    "                curr_grad = cores_grad[i][r1:, :, :, :r2]\n",
    "        else:\n",
    "            if i == 0:\n",
    "                curr_grad = cores_grad[i][:, :, :r2]\n",
    "            elif i == w.ndims() - 1:\n",
    "                curr_grad = cores_grad[i][r1:, :, :]\n",
    "            else:\n",
    "                curr_grad = cores_grad[i][r1:, :, :r2]\n",
    "        if i < w.ndims() - 1:\n",
    "            proj = (tf.eye(r1 * n) - q @ tf.transpose(q))\n",
    "            delta = proj @ tf.reshape(curr_grad, (-1, r2))\n",
    "            delta = tf.reshape(delta, left.tt_cores[i].shape)\n",
    "        else:\n",
    "            delta = curr_grad\n",
    "        deltas.append(delta)\n",
    "    return deltas_to_tangent_space(deltas, w, left, right)\n",
    "def riemannian_grad(func, w):\n",
    "    left = t3f.orthogonalize_tt_cores(w)\n",
    "    right = t3f.orthogonalize_tt_cores(left, left_to_right=False)\n",
    "    deltas = [right.tt_cores[0]] + [tf.zeros_like(cc) for cc in right.tt_cores[1:]]\n",
    "    w_projection = deltas_to_tangent_space(deltas, w, left, right)\n",
    "    return _riemannian_grad(func, w, w_projection, left, right)\n",
    "\n",
    "def hessian_by_vector(f, w, vector):\n",
    "    left = t3f.orthogonalize_tt_cores(w)\n",
    "    right = t3f.orthogonalize_tt_cores(left, left_to_right=False)\n",
    "    vector_projected = t3f.project(vector, w)\n",
    "    vector_projected = t3f.expand_batch_dim(vector_projected)\n",
    "    vector_projected.projection_on = w\n",
    "    def new_f(new_w):\n",
    "        grad = _riemannian_grad(f, w, new_w, left, right)\n",
    "        grad = t3f.expand_batch_dim(grad)\n",
    "        # TODO: durty hack.\n",
    "        grad.projection_on = w\n",
    "        return t3f.pairwise_flat_inner_projected(grad, vector_projected)[0, 0]\n",
    "    return riemannian_grad(new_f, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda w: 0.5 * t3f.flat_inner(x, w)**2\n",
    "desired, actual = sess.run([t3f.full(t3f.flat_inner(x, w) * t3f.project(x, w)), t3f.full(riemannian_grad(func, w))])\n",
    "np.testing.assert_allclose(desired, actual, rtol=1e-3)\n",
    "\n",
    "func = lambda w: t3f.quadratic_form(A, w, w)\n",
    "desired = t3f.project(t3f.matmul(t3f.transpose(A) + A, t3f.project(z, w)), w)\n",
    "actual = hessian_by_vector(func, w, z)\n",
    "desired, actual = sess.run([t3f.full(desired), t3f.full(actual)])\n",
    "np.testing.assert_allclose(desired, actual, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1 = riemannian_grad(func, w).op\n",
    "op2 = (t3f.project_matmul(t3f.expand_batch_dim(w), w, A)).op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 µs ± 7.24 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sess.run(op1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 µs ± 2.58 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sess.run(op2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
