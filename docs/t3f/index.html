<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

    <title>t3f API documentation</title>
    <meta name="description" content="" />

  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>
  
  <style type="text/css">
  
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}

  </style>

  <style type="text/css">
  
  html, body {
    margin: 0;
    padding: 0;
    min-height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  } 

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; } 

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;
      
      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/

  </style>

  <style type="text/css">
  .codehilite .hll { background-color: #ffffcc }
.codehilite  { background: #f8f8f8; }
.codehilite .c { color: #408080; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #BC7A00 } /* Comment.Preproc */
.codehilite .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #408080; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #408080; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #FF0000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #00A000 } /* Generic.Inserted */
.codehilite .go { color: #888888 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #7D9029 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #999999; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #A0A000 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #BB6688 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .fm { color: #0000FF } /* Name.Function.Magic */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .vm { color: #19177C } /* Name.Variable.Magic */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */
  </style>

  <style type="text/css">
  
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}

  </style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
</head>
<body>
<a href="#" id="top">Top</a>

<div id="container">
    
  
  <div id="sidebar">
    <h1>Index</h1>
    <ul id="index">

    <li class="set"><h3><a href="#header-functions">Functions</a></h3>
      
  <ul>
    <li class="mono"><a href="#t3f.add">add</a></li>
    <li class="mono"><a href="#t3f.add_n_projected">add_n_projected</a></li>
    <li class="mono"><a href="#t3f.assign">assign</a></li>
    <li class="mono"><a href="#t3f.batch_size">batch_size</a></li>
    <li class="mono"><a href="#t3f.cast">cast</a></li>
    <li class="mono"><a href="#t3f.clean_raw_shape">clean_raw_shape</a></li>
    <li class="mono"><a href="#t3f.concat_along_batch_dim">concat_along_batch_dim</a></li>
    <li class="mono"><a href="#t3f.cores_regularizer">cores_regularizer</a></li>
    <li class="mono"><a href="#t3f.expand_batch_dim">expand_batch_dim</a></li>
    <li class="mono"><a href="#t3f.flat_inner">flat_inner</a></li>
    <li class="mono"><a href="#t3f.frobenius_norm">frobenius_norm</a></li>
    <li class="mono"><a href="#t3f.frobenius_norm_squared">frobenius_norm_squared</a></li>
    <li class="mono"><a href="#t3f.full">full</a></li>
    <li class="mono"><a href="#t3f.get_variable">get_variable</a></li>
    <li class="mono"><a href="#t3f.gram_matrix">gram_matrix</a></li>
    <li class="mono"><a href="#t3f.is_batch_broadcasting_possible">is_batch_broadcasting_possible</a></li>
    <li class="mono"><a href="#t3f.l2_regularizer">l2_regularizer</a></li>
    <li class="mono"><a href="#t3f.lazy_batch_size">lazy_batch_size</a></li>
    <li class="mono"><a href="#t3f.lazy_raw_shape">lazy_raw_shape</a></li>
    <li class="mono"><a href="#t3f.lazy_shape">lazy_shape</a></li>
    <li class="mono"><a href="#t3f.lazy_tt_ranks">lazy_tt_ranks</a></li>
    <li class="mono"><a href="#t3f.matmul">matmul</a></li>
    <li class="mono"><a href="#t3f.multiply">multiply</a></li>
    <li class="mono"><a href="#t3f.multiply_along_batch_dim">multiply_along_batch_dim</a></li>
    <li class="mono"><a href="#t3f.orthogonalize_tt_cores">orthogonalize_tt_cores</a></li>
    <li class="mono"><a href="#t3f.pairwise_flat_inner">pairwise_flat_inner</a></li>
    <li class="mono"><a href="#t3f.pairwise_flat_inner_projected">pairwise_flat_inner_projected</a></li>
    <li class="mono"><a href="#t3f.project">project</a></li>
    <li class="mono"><a href="#t3f.project_matmul">project_matmul</a></li>
    <li class="mono"><a href="#t3f.project_sum">project_sum</a></li>
    <li class="mono"><a href="#t3f.quadratic_form">quadratic_form</a></li>
    <li class="mono"><a href="#t3f.random_matrix">random_matrix</a></li>
    <li class="mono"><a href="#t3f.random_matrix_batch">random_matrix_batch</a></li>
    <li class="mono"><a href="#t3f.random_tensor">random_tensor</a></li>
    <li class="mono"><a href="#t3f.random_tensor_batch">random_tensor_batch</a></li>
    <li class="mono"><a href="#t3f.raw_shape">raw_shape</a></li>
    <li class="mono"><a href="#t3f.round">round</a></li>
    <li class="mono"><a href="#t3f.shape">shape</a></li>
    <li class="mono"><a href="#t3f.sparse_tt_flat_inner">sparse_tt_flat_inner</a></li>
    <li class="mono"><a href="#t3f.sparse_tt_matmul">sparse_tt_matmul</a></li>
    <li class="mono"><a href="#t3f.squeeze_batch_dim">squeeze_batch_dim</a></li>
    <li class="mono"><a href="#t3f.to_tt_matrix">to_tt_matrix</a></li>
    <li class="mono"><a href="#t3f.to_tt_tensor">to_tt_tensor</a></li>
    <li class="mono"><a href="#t3f.transpose">transpose</a></li>
    <li class="mono"><a href="#t3f.tt_ranks">tt_ranks</a></li>
  </ul>

    </li>

    <li class="set"><h3><a href="#header-classes">Classes</a></h3>
      <ul>
        <li class="mono">
        <span class="class_name"><a href="#t3f.TensorTrain">TensorTrain</a></span>
        
          
  <ul>
    <li class="mono"><a href="#t3f.TensorTrain.__init__">__init__</a></li>
    <li class="mono"><a href="#t3f.TensorTrain.eval">eval</a></li>
    <li class="mono"><a href="#t3f.TensorTrain.get_raw_shape">get_raw_shape</a></li>
    <li class="mono"><a href="#t3f.TensorTrain.get_shape">get_shape</a></li>
    <li class="mono"><a href="#t3f.TensorTrain.get_tt_ranks">get_tt_ranks</a></li>
    <li class="mono"><a href="#t3f.TensorTrain.is_tt_matrix">is_tt_matrix</a></li>
    <li class="mono"><a href="#t3f.TensorTrain.is_variable">is_variable</a></li>
    <li class="mono"><a href="#t3f.TensorTrain.ndims">ndims</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#t3f.TensorTrainBase">TensorTrainBase</a></span>
        
          
  <ul>
    <li class="mono"><a href="#t3f.TensorTrainBase.__init__">__init__</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBase.eval">eval</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBase.get_raw_shape">get_raw_shape</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBase.get_shape">get_shape</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBase.get_tt_ranks">get_tt_ranks</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBase.is_tt_matrix">is_tt_matrix</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBase.is_variable">is_variable</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBase.ndims">ndims</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#t3f.TensorTrainBatch">TensorTrainBatch</a></span>
        
          
  <ul>
    <li class="mono"><a href="#t3f.TensorTrainBatch.__init__">__init__</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBatch.eval">eval</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBatch.get_raw_shape">get_raw_shape</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBatch.get_shape">get_shape</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBatch.get_tt_ranks">get_tt_ranks</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBatch.is_tt_matrix">is_tt_matrix</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBatch.is_variable">is_variable</a></li>
    <li class="mono"><a href="#t3f.TensorTrainBatch.ndims">ndims</a></li>
  </ul>

        </li>
      </ul>
    </li>

    </ul>
  </div>

    <article id="content">
      
  

  


  <header id="section-intro">
  <h1 class="title"><span class="name">t3f</span> module</h1>
  
  
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f', this);">Show source &equiv;</a></p>
  <div id="source-t3f" class="source">
    <div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">t3f.tensor_train_base</span> <span class="kn">import</span> <span class="n">TensorTrainBase</span>
<span class="kn">from</span> <span class="nn">t3f.tensor_train</span> <span class="kn">import</span> <span class="n">TensorTrain</span>
<span class="kn">from</span> <span class="nn">t3f.tensor_train_batch</span> <span class="kn">import</span> <span class="n">TensorTrainBatch</span>

<span class="kn">from</span> <span class="nn">t3f.variables</span> <span class="kn">import</span> <span class="n">assign</span>
<span class="kn">from</span> <span class="nn">t3f.variables</span> <span class="kn">import</span> <span class="n">get_variable</span>

<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">add</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">cast</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">flat_inner</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">frobenius_norm</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">frobenius_norm_squared</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">full</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">matmul</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">multiply</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">quadratic_form</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">sparse_tt_flat_inner</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">sparse_tt_matmul</span>
<span class="kn">from</span> <span class="nn">t3f.ops</span> <span class="kn">import</span> <span class="n">transpose</span>

<span class="kn">from</span> <span class="nn">t3f.batch_ops</span> <span class="kn">import</span> <span class="n">concat_along_batch_dim</span>
<span class="kn">from</span> <span class="nn">t3f.batch_ops</span> <span class="kn">import</span> <span class="n">gram_matrix</span>
<span class="kn">from</span> <span class="nn">t3f.batch_ops</span> <span class="kn">import</span> <span class="n">multiply_along_batch_dim</span>
<span class="kn">from</span> <span class="nn">t3f.batch_ops</span> <span class="kn">import</span> <span class="n">pairwise_flat_inner</span>

<span class="kn">from</span> <span class="nn">t3f.initializers</span> <span class="kn">import</span> <span class="n">random_matrix</span>
<span class="kn">from</span> <span class="nn">t3f.initializers</span> <span class="kn">import</span> <span class="n">random_matrix_batch</span>
<span class="kn">from</span> <span class="nn">t3f.initializers</span> <span class="kn">import</span> <span class="n">random_tensor</span>
<span class="kn">from</span> <span class="nn">t3f.initializers</span> <span class="kn">import</span> <span class="n">random_tensor_batch</span>

<span class="kn">from</span> <span class="nn">t3f.regularizers</span> <span class="kn">import</span> <span class="n">cores_regularizer</span>
<span class="kn">from</span> <span class="nn">t3f.regularizers</span> <span class="kn">import</span> <span class="n">l2_regularizer</span>

<span class="kn">from</span> <span class="nn">t3f.riemannian</span> <span class="kn">import</span> <span class="n">add_n_projected</span>
<span class="kn">from</span> <span class="nn">t3f.riemannian</span> <span class="kn">import</span> <span class="n">pairwise_flat_inner_projected</span>
<span class="kn">from</span> <span class="nn">t3f.riemannian</span> <span class="kn">import</span> <span class="n">project</span>
<span class="kn">from</span> <span class="nn">t3f.riemannian</span> <span class="kn">import</span> <span class="n">project_matmul</span>
<span class="kn">from</span> <span class="nn">t3f.riemannian</span> <span class="kn">import</span> <span class="n">project_sum</span>

<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">batch_size</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">clean_raw_shape</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">expand_batch_dim</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">is_batch_broadcasting_possible</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">lazy_batch_size</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">lazy_raw_shape</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">lazy_shape</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">lazy_tt_ranks</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">raw_shape</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">shape</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">squeeze_batch_dim</span>
<span class="kn">from</span> <span class="nn">t3f.shapes</span> <span class="kn">import</span> <span class="n">tt_ranks</span>

<span class="kn">from</span> <span class="nn">t3f.decompositions</span> <span class="kn">import</span> <span class="n">orthogonalize_tt_cores</span>
<span class="kn">from</span> <span class="nn">t3f.decompositions</span> <span class="kn">import</span> <span class="nb">round</span>
<span class="kn">from</span> <span class="nn">t3f.decompositions</span> <span class="kn">import</span> <span class="n">to_tt_matrix</span>
<span class="kn">from</span> <span class="nn">t3f.decompositions</span> <span class="kn">import</span> <span class="n">to_tt_tensor</span>

<span class="c1"># import kronecker</span>
<span class="c1"># import utils</span>

<span class="n">_directly_imported</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;tensor_train_base&#39;</span><span class="p">,</span> <span class="s1">&#39;tensor_train&#39;</span><span class="p">,</span> <span class="s1">&#39;tensor_train_batch&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;variables&#39;</span><span class="p">,</span> <span class="s1">&#39;ops&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_ops&#39;</span><span class="p">,</span> <span class="s1">&#39;initializers&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;regularizers&#39;</span><span class="p">,</span> <span class="s1">&#39;riemannian&#39;</span><span class="p">,</span> <span class="s1">&#39;shapes&#39;</span><span class="p">,</span> <span class="s1">&#39;decompositions&#39;</span><span class="p">]</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">()</span> <span class="k">if</span>
           <span class="n">s</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_directly_imported</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">s</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)]</span>
</pre></div>

  </div>

  </header>

  <section id="section-items">

    <h2 class="section-title" id="header-functions">Functions</h2>
      
  <div class="item">
    <div class="name def" id="t3f.add">
    <p>def <span class="ident">add</span>(</p><p>tt_a, tt_b)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns a TensorTrain corresponding to elementwise sum tt_a + tt_b.</p>
<p>The shapes of tt_a and tt_b should coincide.
Supports broadcasting:
  add(TensorTrainBatch, TensorTrain)
adds TensorTrain to each element in the batch of TTs in TensorTrainBatch.</p>
<p>Args:
  tt_a: <code>TensorTrain</code>, <code>TensorTrainBatch</code>, TT-tensor, or TT-matrix
  tt_b: <code>TensorTrain</code>, <code>TensorTrainBatch</code>, TT-tensor, or TT-matrix</p>
<p>Returns
  a <code>TensorTrain</code> object corresponding to the element-wise sum of arguments if
    both arguments are <code>TensorTrain</code>s.
  OR a <code>TensorTrainBatch</code> if at least one of the arguments is
    <code>TensorTrainBatch</code></p>
<p>Raises
  ValueError if the arguments shapes do not coincide</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.add', this);">Show source &equiv;</a></p>
  <div id="source-t3f.add" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">tt_b</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a TensorTrain corresponding to elementwise sum tt_a + tt_b.</span>

<span class="sd">  The shapes of tt_a and tt_b should coincide.</span>
<span class="sd">  Supports broadcasting:</span>
<span class="sd">    add(TensorTrainBatch, TensorTrain)</span>
<span class="sd">  adds TensorTrain to each element in the batch of TTs in TensorTrainBatch.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt_a: `TensorTrain`, `TensorTrainBatch`, TT-tensor, or TT-matrix</span>
<span class="sd">    tt_b: `TensorTrain`, `TensorTrainBatch`, TT-tensor, or TT-matrix</span>

<span class="sd">  Returns</span>
<span class="sd">    a `TensorTrain` object corresponding to the element-wise sum of arguments if</span>
<span class="sd">      both arguments are `TensorTrain`s.</span>
<span class="sd">    OR a `TensorTrainBatch` if at least one of the arguments is</span>
<span class="sd">      `TensorTrainBatch`</span>

<span class="sd">  Raises</span>
<span class="sd">    ValueError if the arguments shapes do not coincide</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">ndims</span> <span class="o">=</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">()</span> <span class="o">!=</span> <span class="n">tt_b</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The arguments should be both TT-tensors or both &#39;</span>
                     <span class="s1">&#39;TT-matrices&#39;</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span> <span class="o">!=</span> <span class="n">tt_b</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The arguments should have the same shape.&#39;</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">shapes</span><span class="o">.</span><span class="n">is_batch_broadcasting_possible</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">tt_b</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The batch sizes are different and not 1, broadcasting is &#39;</span>
                     <span class="s1">&#39;not available.&#39;</span><span class="p">)</span>

  <span class="n">is_batch_case</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">TensorTrainBatch</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_b</span><span class="p">,</span> <span class="n">TensorTrainBatch</span><span class="p">)</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">None</span>
  <span class="k">if</span> <span class="n">is_batch_case</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
      <span class="n">tt_cores</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">_add_batch_matrix_cores</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">tt_b</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">tt_cores</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">_add_batch_tensor_cores</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">tt_b</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
      <span class="n">tt_cores</span> <span class="o">=</span> <span class="n">_add_matrix_cores</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">tt_b</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">tt_cores</span> <span class="o">=</span> <span class="n">_add_tensor_cores</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">tt_b</span><span class="p">)</span>

  <span class="n">out_ranks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">static_a_ranks</span> <span class="o">=</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>
  <span class="n">static_b_ranks</span> <span class="o">=</span> <span class="n">tt_b</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ndims</span><span class="p">):</span>
    <span class="n">out_ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">static_a_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">static_b_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">])</span>
  <span class="n">out_ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">is_batch_case</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span> <span class="n">out_ranks</span><span class="p">,</span>
                            <span class="n">batch_size</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span> <span class="n">out_ranks</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.add_n_projected">
    <p>def <span class="ident">add_n_projected</span>(</p><p>tt_objects, coef=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Adds all input TT-objects that are projections on the same tangent space.</p>
<p>add_projected((a, b)) is equivalent add(a, b) for a and b that are from the
  same tangent space, but doesn't increase the TT-ranks.</p>
<p>Args:
  tt_objects: a list of TT-objects that are projections on the same tangent
    space.
  coef: a list of numbers or anything else convertable to tf.Tensor.
    If provided, computes weighted sum. The size of this array should be
      len(tt_objects) x tt_objects[0].batch_size</p>
<p>Returns:
  TT-objects representing the sum of the tt_objects (weighted sum if coef is
  provided). The TT-rank of the result equals to the TT-ranks of the arguments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.add_n_projected', this);">Show source &equiv;</a></p>
  <div id="source-t3f.add_n_projected" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">add_n_projected</span><span class="p">(</span><span class="n">tt_objects</span><span class="p">,</span> <span class="n">coef</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Adds all input TT-objects that are projections on the same tangent space.</span>

<span class="sd">    add_projected((a, b)) is equivalent add(a, b) for a and b that are from the</span>
<span class="sd">    same tangent space, but doesn&#39;t increase the TT-ranks.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt_objects: a list of TT-objects that are projections on the same tangent</span>
<span class="sd">      space.</span>
<span class="sd">    coef: a list of numbers or anything else convertable to tf.Tensor.</span>
<span class="sd">      If provided, computes weighted sum. The size of this array should be</span>
<span class="sd">        len(tt_objects) x tt_objects[0].batch_size</span>

<span class="sd">  Returns:</span>
<span class="sd">    TT-objects representing the sum of the tt_objects (weighted sum if coef is</span>
<span class="sd">    provided). The TT-rank of the result equals to the TT-ranks of the arguments.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">for</span> <span class="n">tt</span> <span class="ow">in</span> <span class="n">tt_objects</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="s1">&#39;projection_on&#39;</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Both arguments should be projections on the tangent &#39;</span>
                       <span class="s1">&#39;space of some other TT-object. All projection* functions &#39;</span>
                       <span class="s1">&#39;leave .projection_on field in the resulting TT-object &#39;</span>
                       <span class="s1">&#39;which is not present in the argument you</span><span class="se">\&#39;</span><span class="s1">ve provided.&#39;</span><span class="p">)</span>

  <span class="n">projection_on</span> <span class="o">=</span> <span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">projection_on</span>
  <span class="k">for</span> <span class="n">tt</span> <span class="ow">in</span> <span class="n">tt_objects</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
    <span class="k">if</span> <span class="n">tt</span><span class="o">.</span><span class="n">projection_on</span> <span class="o">!=</span> <span class="n">projection_on</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;All tt_objects should be projections on the tangent &#39;</span>
                       <span class="s1">&#39;space of the same TT-object. The provided arguments are &#39;</span>
                       <span class="s1">&#39;projections on different TT-objects (</span><span class="si">%s</span><span class="s1"> and </span><span class="si">%s</span><span class="s1">). Or at &#39;</span>
                       <span class="s1">&#39;least the pointers are different.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">projection_on</span><span class="p">,</span>
                                                              <span class="n">projection_on</span><span class="p">))</span>

  <span class="n">ndims</span> <span class="o">=</span> <span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
  <span class="n">tt_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_tt_ranks</span><span class="p">(</span><span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">left_rank_dim</span> <span class="o">=</span> <span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">left_tt_rank_dim</span>
  <span class="n">right_rank_dim</span> <span class="o">=</span> <span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">right_tt_rank_dim</span>
  <span class="n">res_cores</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">slice_tt_core</span><span class="p">(</span><span class="n">tt_core</span><span class="p">,</span> <span class="n">left_idx</span><span class="p">,</span> <span class="n">right_idx</span><span class="p">):</span>
    <span class="n">num_tt_core_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tt_core</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="bp">None</span><span class="p">)]</span> <span class="o">*</span> <span class="n">num_tt_core_dims</span>
    <span class="n">idx</span><span class="p">[</span><span class="n">left_rank_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">left_idx</span>
    <span class="n">idx</span><span class="p">[</span><span class="n">right_rank_dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">right_idx</span>
    <span class="k">return</span> <span class="n">tt_core</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

  <span class="n">right_half_rank</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
  <span class="n">left_chunks</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">obj_idx</span><span class="p">,</span> <span class="n">tt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tt_objects</span><span class="p">):</span>
    <span class="n">curr_core</span> <span class="o">=</span> <span class="n">slice_tt_core</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">slice</span><span class="p">(</span><span class="bp">None</span><span class="p">),</span>
                              <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">right_half_rank</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">coef</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">curr_core</span> <span class="o">*=</span> <span class="n">coef</span><span class="p">[</span><span class="n">obj_idx</span><span class="p">]</span>
    <span class="n">left_chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_core</span><span class="p">)</span>
  <span class="n">left_part</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">left_chunks</span><span class="p">)</span>
  <span class="n">first_obj_core</span> <span class="o">=</span> <span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">right_part</span> <span class="o">=</span> <span class="n">slice_tt_core</span><span class="p">(</span><span class="n">first_obj_core</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="bp">None</span><span class="p">),</span>
                             <span class="nb">slice</span><span class="p">(</span><span class="n">right_half_rank</span><span class="p">,</span> <span class="bp">None</span><span class="p">))</span>
  <span class="n">first_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">left_part</span><span class="p">,</span> <span class="n">right_part</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
  <span class="n">res_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">first_core</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">first_obj_core</span> <span class="o">=</span> <span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">left_half_rank</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">right_half_rank</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>

    <span class="n">upper_part</span> <span class="o">=</span> <span class="n">slice_tt_core</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">left_half_rank</span><span class="p">),</span>
                               <span class="nb">slice</span><span class="p">(</span><span class="bp">None</span><span class="p">))</span>
    <span class="n">lower_right_part</span> <span class="o">=</span> <span class="n">slice_tt_core</span><span class="p">(</span><span class="n">first_obj_core</span><span class="p">,</span>
                                     <span class="nb">slice</span><span class="p">(</span><span class="n">left_half_rank</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span>
                                     <span class="nb">slice</span><span class="p">(</span><span class="n">right_half_rank</span><span class="p">,</span> <span class="bp">None</span><span class="p">))</span>

    <span class="n">lower_left_chunks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">obj_idx</span><span class="p">,</span> <span class="n">tt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tt_objects</span><span class="p">):</span>
      <span class="n">curr_core</span> <span class="o">=</span> <span class="n">slice_tt_core</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span>
                                <span class="nb">slice</span><span class="p">(</span><span class="n">left_half_rank</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span>
                                <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">right_half_rank</span><span class="p">))</span>
      <span class="k">if</span> <span class="n">coef</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">curr_core</span> <span class="o">*=</span> <span class="n">coef</span><span class="p">[</span><span class="n">obj_idx</span><span class="p">]</span>
      <span class="n">lower_left_chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_core</span><span class="p">)</span>
    <span class="n">lower_left_part</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">lower_left_chunks</span><span class="p">)</span>
    <span class="n">lower_part</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">lower_left_part</span><span class="p">,</span> <span class="n">lower_right_part</span><span class="p">),</span>
                           <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
    <span class="n">curr_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">upper_part</span><span class="p">,</span> <span class="n">lower_part</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">left_rank_dim</span><span class="p">)</span>
    <span class="n">res_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_core</span><span class="p">)</span>

  <span class="n">left_half_rank</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
  <span class="n">upper_part</span> <span class="o">=</span> <span class="n">slice_tt_core</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">left_half_rank</span><span class="p">),</span>
                             <span class="nb">slice</span><span class="p">(</span><span class="bp">None</span><span class="p">))</span>
  <span class="n">lower_chunks</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">obj_idx</span><span class="p">,</span> <span class="n">tt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tt_objects</span><span class="p">):</span>
    <span class="n">curr_core</span> <span class="o">=</span> <span class="n">slice_tt_core</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">slice</span><span class="p">(</span><span class="n">left_half_rank</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span>
                              <span class="nb">slice</span><span class="p">(</span><span class="bp">None</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">coef</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">curr_core</span> <span class="o">*=</span> <span class="n">coef</span><span class="p">[</span><span class="n">obj_idx</span><span class="p">]</span>
    <span class="n">lower_chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_core</span><span class="p">)</span>
  <span class="n">lower_part</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">lower_chunks</span><span class="p">)</span>
  <span class="n">last_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">upper_part</span><span class="p">,</span> <span class="n">lower_part</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">left_rank_dim</span><span class="p">)</span>
  <span class="n">res_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">last_core</span><span class="p">)</span>

  <span class="n">raw_shape</span> <span class="o">=</span> <span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span>
  <span class="n">static_tt_ranks</span> <span class="o">=</span> <span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">res_cores</span><span class="p">,</span> <span class="n">raw_shape</span><span class="p">,</span> <span class="n">static_tt_ranks</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">TensorTrainBatch</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">res_cores</span><span class="p">,</span> <span class="n">raw_shape</span><span class="p">,</span> <span class="n">static_tt_ranks</span><span class="p">,</span>
                           <span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="c1"># Maintain the projection_on property.</span>
  <span class="n">res</span><span class="o">.</span><span class="n">projection_on</span> <span class="o">=</span> <span class="n">tt_objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">projection_on</span>
  <span class="k">return</span> <span class="n">res</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.assign">
    <p>def <span class="ident">assign</span>(</p><p>ref, value, validate_shape=None, use_locking=None, name=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.assign', this);">Show source &equiv;</a></p>
  <div id="source-t3f.assign" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">assign</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">validate_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">use_locking</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="n">new_cores</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ref</span><span class="o">.</span><span class="n">ndims</span><span class="p">()):</span>
      <span class="n">new_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">ref</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">value</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                 <span class="n">use_locking</span><span class="o">=</span><span class="n">use_locking</span><span class="p">))</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorTrainBatch</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">new_cores</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                            <span class="n">value</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">(),</span> <span class="n">value</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">convert_to_tensors</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">new_cores</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                                  <span class="n">value</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">(),</span>
                                  <span class="n">convert_to_tensors</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.batch_size">
    <p>def <span class="ident">batch_size</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Return the number of elements in a TensorTrainBatch.</p>
<p>Return 0-D integer tensor.</p>
<p>Raises:
  ValueError if got <code>TensorTrain</code> which doesn't have batch_size as input.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.batch_size', this);">Show source &equiv;</a></p>
  <div id="source-t3f.batch_size" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return the number of elements in a TensorTrainBatch.</span>

<span class="sd">  Return 0-D integer tensor.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError if got `TensorTrain` which doesn&#39;t have batch_size as input.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;batch size is not available for a TensorTrain object.&#39;</span><span class="p">)</span>
  <span class="n">first_core</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="c1"># The first dimension of any TT-core in TensorTrainBatch is the batch size.</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">first_core</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.cast">
    <p>def <span class="ident">cast</span>(</p><p>tt_a, dtype)</p>
    </div>
    

    
  
    <div class="desc"><p>Casts a tt-tensor to a new type.</p>
<p>Args:
  tt_a: <code>TensorTrain</code> object.
  dtype: The destination type. </p>
<p>Raises:
  TypeError: If <code>tt_a</code> cannot be cast to the <code>dtype</code>.
  ValueError: If <code>tt_a</code> is not a <code>TensorTrain</code> or <code>TensorTrainBatch</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.cast', this);">Show source &equiv;</a></p>
  <div id="source-t3f.cast" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">cast</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Casts a tt-tensor to a new type.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt_a: `TensorTrain` object.</span>
<span class="sd">    dtype: The destination type. </span>

<span class="sd">  Raises:</span>
<span class="sd">    TypeError: If `tt_a` cannot be cast to the `dtype`.</span>
<span class="sd">    ValueError: If `tt_a` is not a `TensorTrain` or `TensorTrainBatch`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">res_cores</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">cores</span> <span class="o">=</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">tt_cores</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tt_a</span><span class="o">.</span><span class="n">ndims</span><span class="p">()):</span>
    <span class="n">res_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">dtype</span><span class="p">))</span>
  <span class="n">res_shape</span> <span class="o">=</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span>
  <span class="n">res_ranks</span> <span class="o">=</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">res_cores</span><span class="p">,</span> <span class="n">res_shape</span><span class="p">,</span> <span class="n">res_ranks</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">TensorTrainBatch</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">res_cores</span><span class="p">,</span> <span class="n">res_shape</span><span class="p">,</span> <span class="n">res_ranks</span><span class="p">,</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unsupported type of input &quot;</span><span class="si">%s</span><span class="s1">&quot;, should be TensorTrain or &#39;</span>
                     <span class="s1">&#39;TensorTrainBatch.&#39;</span> <span class="o">%</span> <span class="n">tt_a</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.clean_raw_shape">
    <p>def <span class="ident">clean_raw_shape</span>(</p><p>shape)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns a tuple of TensorShapes for any valid shape representation.</p>
<p>Args:
  shape: An np.array, a tf.TensorShape (for tensors), a tuple of
    tf.TensorShapes (for TT-matrices or tensors), or None</p>
<p>Returns:
  A tuple of tf.TensorShape, or None if the input is None</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.clean_raw_shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.clean_raw_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">clean_raw_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a tuple of TensorShapes for any valid shape representation.</span>

<span class="sd">  Args:</span>
<span class="sd">    shape: An np.array, a tf.TensorShape (for tensors), a tuple of</span>
<span class="sd">      tf.TensorShapes (for TT-matrices or tensors), or None</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of tf.TensorShape, or None if the input is None</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">None</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">):</span>
    <span class="c1"># Assume tf.TensorShape.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">):</span>
      <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">((</span><span class="n">shape</span><span class="p">,))</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">np_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># Make sure that the shape is 2-d array both for tensors and TT-matrices.</span>
    <span class="n">np_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np_shape</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># A tensor.</span>
      <span class="n">np_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">np_shape</span><span class="p">]</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np_shape</span><span class="p">)):</span>
      <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">np_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">shape</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.concat_along_batch_dim">
    <p>def <span class="ident">concat_along_batch_dim</span>(</p><p>tt_list)</p>
    </div>
    

    
  
    <div class="desc"><p>Concat all TensorTrainBatch objects along batch dimension.</p>
<p>Args:
  tt_list: a list of TensorTrainBatch objects.</p>
<p>Returns:
  TensorTrainBatch</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.concat_along_batch_dim', this);">Show source &equiv;</a></p>
  <div id="source-t3f.concat_along_batch_dim" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">concat_along_batch_dim</span><span class="p">(</span><span class="n">tt_list</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Concat all TensorTrainBatch objects along batch dimension.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt_list: a list of TensorTrainBatch objects.</span>

<span class="sd">  Returns:</span>
<span class="sd">    TensorTrainBatch</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">ndims</span> <span class="o">=</span> <span class="n">tt_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>

  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_list</span><span class="p">,</span> <span class="n">TensorTrainBase</span><span class="p">):</span>
    <span class="c1"># Not a list but just one element, nothing to concat.</span>
    <span class="k">return</span> <span class="n">tt_list</span>

  <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tt_list</span><span class="p">)):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_list</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">],</span> <span class="n">TensorTrainBatch</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;All objects in the list should be TTBatch objects, got &#39;</span>
                       <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">tt_list</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">])</span>
  <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tt_list</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">tt_list</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span> <span class="o">!=</span> <span class="n">tt_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Shapes of all TT-batch objects should coincide, got </span><span class="si">%s</span><span class="s1"> &#39;</span>
                       <span class="s1">&#39;and </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tt_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                                   <span class="n">tt_list</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()))</span>
    <span class="k">if</span> <span class="n">tt_list</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span> <span class="o">!=</span> <span class="n">tt_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;TT-ranks of all TT-batch objects should coincide, got &#39;</span>
                       <span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> and </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tt_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">(),</span>
                                      <span class="n">tt_list</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()))</span>

  <span class="n">res_cores</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span><span class="p">):</span>
    <span class="n">curr_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">tt</span> <span class="ow">in</span> <span class="n">tt_list</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">res_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_core</span><span class="p">)</span>

  <span class="k">try</span><span class="p">:</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">tt</span><span class="o">.</span><span class="n">batch_size</span> <span class="k">for</span> <span class="n">tt</span> <span class="ow">in</span> <span class="n">tt_list</span><span class="p">])</span>
  <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
    <span class="c1"># The batch sizes are not defined and you can&#39;t sum Nones.</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">None</span>

  <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">res_cores</span><span class="p">,</span> <span class="n">tt_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                          <span class="n">tt_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">(),</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.cores_regularizer">
    <p>def <span class="ident">cores_regularizer</span>(</p><p>core_regularizer, scale, scope=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns a function that applies given regularization to each TT-core.</p>
<p>Args:
  core_regularizer: a function with signature <code>core_regularizer(core)</code> that
    returns the penalty for the given TT-core.
  scale: A scalar multiplier <code>Tensor</code>. 0.0 disables the regularizer.
  scope: An optional scope name.</p>
<p>Returns:
  A function with signature <code>regularizer(weights)</code> that applies
  the regularization.</p>
<p>Raises:
  ValueError: If scale is negative or if scale is not a float.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.cores_regularizer', this);">Show source &equiv;</a></p>
  <div id="source-t3f.cores_regularizer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">cores_regularizer</span><span class="p">(</span><span class="n">core_regularizer</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a function that applies given regularization to each TT-core.</span>

<span class="sd">  Args:</span>
<span class="sd">    core_regularizer: a function with signature `core_regularizer(core)` that</span>
<span class="sd">      returns the penalty for the given TT-core.</span>
<span class="sd">    scale: A scalar multiplier `Tensor`. 0.0 disables the regularizer.</span>
<span class="sd">    scope: An optional scope name.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A function with signature `regularizer(weights)` that applies</span>
<span class="sd">    the regularization.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: If scale is negative or if scale is not a float.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;scale cannot be an integer: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">scale</span><span class="p">,))</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">scale</span> <span class="o">&lt;</span> <span class="mf">0.</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Setting a scale less than 0 on a regularizer: </span><span class="si">%g</span><span class="s1">.&#39;</span> <span class="o">%</span>
                       <span class="n">scale</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">scale</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Scale of 0 disables regularizer.&#39;</span><span class="p">)</span>
      <span class="k">return</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="bp">None</span>

  <span class="k">def</span> <span class="nf">regularizer</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies the regularization to TensorTrain object.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="s1">&#39;l2_regularizer&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">tt</span><span class="p">])</span> <span class="k">as</span> <span class="n">name</span><span class="p">:</span>
      <span class="n">my_scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">tt</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">base_dtype</span><span class="p">,</span>
                                       <span class="n">name</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">)</span>
      <span class="n">penalty</span> <span class="o">=</span> <span class="mf">0.0</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">ndims</span><span class="p">()):</span>
        <span class="n">penalty</span> <span class="o">+=</span> <span class="n">core_regularizer</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">my_scale</span><span class="p">,</span> <span class="n">penalty</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">regularizer</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.expand_batch_dim">
    <p>def <span class="ident">expand_batch_dim</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Creates a 1-element TensorTrainBatch from a TensorTrain.</p>
<p>Args:
  tt: TensorTrain or TensorTrainBatch.</p>
<p>Returns:
  TensorTrainBatch</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.expand_batch_dim', this);">Show source &equiv;</a></p>
  <div id="source-t3f.expand_batch_dim" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">expand_batch_dim</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates a 1-element TensorTrainBatch from a TensorTrain.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: TensorTrain or TensorTrainBatch.</span>

<span class="sd">  Returns:</span>
<span class="sd">    TensorTrainBatch</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tt</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">t3f.tensor_train_batch</span> <span class="kn">import</span> <span class="n">TensorTrainBatch</span>
    <span class="n">tt_cores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">ndims</span><span class="p">()):</span>
      <span class="n">tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span> <span class="n">tt</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">(),</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.flat_inner">
    <p>def <span class="ident">flat_inner</span>(</p><p>a, b)</p>
    </div>
    

    
  
    <div class="desc"><p>Inner product along all axis.</p>
<p>The shapes of a and b should coincide.</p>
<p>Args:
  a: <code>TensorTrain</code>, <code>TensorTrainBatch</code>, tf.Tensor, or tf.SparseTensor
  b: <code>TensorTrain</code>, <code>TensorTrainBatch</code>, tf.Tensor, or tf.SparseTensor</p>
<p>Returns
  a number
    sum of products of all the elements of a and b
  OR or a tf.Tensor of size batch_size
    sum of products of all the elements of a and b for each element in the
    batch.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.flat_inner', this);">Show source &equiv;</a></p>
  <div id="source-t3f.flat_inner" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">flat_inner</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Inner product along all axis.</span>

<span class="sd">  The shapes of a and b should coincide.</span>

<span class="sd">  Args:</span>
<span class="sd">    a: `TensorTrain`, `TensorTrainBatch`, tf.Tensor, or tf.SparseTensor</span>
<span class="sd">    b: `TensorTrain`, `TensorTrainBatch`, tf.Tensor, or tf.SparseTensor</span>

<span class="sd">  Returns</span>
<span class="sd">    a number</span>
<span class="sd">      sum of products of all the elements of a and b</span>
<span class="sd">    OR or a tf.Tensor of size batch_size</span>
<span class="sd">      sum of products of all the elements of a and b for each element in the</span>
<span class="sd">      batch.</span>
<span class="sd">  &quot;&quot;&quot;</span>
<span class="c1">#   TODO: is it safe to check types? What if a class is derived from TT?</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">TensorTrainBase</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">TensorTrainBase</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tt_tt_flat_inner</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tt_dense_flat_inner</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">dense_tt_flat_inner</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tt_sparse_flat_inner</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sparse_tt_flat_inner</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Argument types are not supported in flat_inner: </span><span class="si">%s</span><span class="s1"> x </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
                     <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.frobenius_norm">
    <p>def <span class="ident">frobenius_norm</span>(</p><p>tt, epsilon=1e-05, differentiable=False)</p>
    </div>
    

    
  
    <div class="desc"><p>Frobenius norm of a TensorTrain (sqrt of the sum of squares of all elements).</p>
<p>Args:
  tt: <code>TensorTrain</code> object
  epsilon: the function actually computes sqrt(norm_squared + epsilon) for
    numerical stability (e.g. gradient of sqrt at zero is inf).
  differentiable: bool, whether to use a differentiable implementation or
    a fast and stable implementation based on QR decomposition.</p>
<p>Returns
  a number
  sqrt of the sum of squares of all elements in <code>tt</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.frobenius_norm', this);">Show source &equiv;</a></p>
  <div id="source-t3f.frobenius_norm" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">frobenius_norm</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">differentiable</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Frobenius norm of a TensorTrain (sqrt of the sum of squares of all elements).</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrain` object</span>
<span class="sd">    epsilon: the function actually computes sqrt(norm_squared + epsilon) for</span>
<span class="sd">      numerical stability (e.g. gradient of sqrt at zero is inf).</span>
<span class="sd">    differentiable: bool, whether to use a differentiable implementation or</span>
<span class="sd">      a fast and stable implementation based on QR decomposition.</span>

<span class="sd">  Returns</span>
<span class="sd">    a number</span>
<span class="sd">    sqrt of the sum of squares of all elements in `tt`</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">frobenius_norm_squared</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">differentiable</span><span class="p">)</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.frobenius_norm_squared">
    <p>def <span class="ident">frobenius_norm_squared</span>(</p><p>tt, differentiable=False)</p>
    </div>
    

    
  
    <div class="desc"><p>Frobenius norm squared of a TensorTrain (sum of squares of all elements).</p>
<p>Args:
  tt: <code>TensorTrain</code> object
  differentiable: bool, whether to use a differentiable implementation
    or a fast and stable implementation based on QR decomposition.</p>
<p>Returns
  a number
  sum of squares of all elements in <code>tt</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.frobenius_norm_squared', this);">Show source &equiv;</a></p>
  <div id="source-t3f.frobenius_norm_squared" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">frobenius_norm_squared</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">differentiable</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Frobenius norm squared of a TensorTrain (sum of squares of all elements).</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrain` object</span>
<span class="sd">    differentiable: bool, whether to use a differentiable implementation</span>
<span class="sd">      or a fast and stable implementation based on QR decomposition.</span>

<span class="sd">  Returns</span>
<span class="sd">    a number</span>
<span class="sd">    sum of squares of all elements in `tt`</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">differentiable</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">tt</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
      <span class="n">running_prod</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;aijb,cijd-&gt;bd&#39;</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">running_prod</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;aib,cid-&gt;bd&#39;</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">ndims</span><span class="p">()):</span>
      <span class="n">curr_core</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">tt</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
        <span class="n">running_prod</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ac,aijb,cijd-&gt;bd&#39;</span><span class="p">,</span> <span class="n">running_prod</span><span class="p">,</span> <span class="n">curr_core</span><span class="p">,</span>
                                 <span class="n">curr_core</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">running_prod</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ac,aib,cid-&gt;bd&#39;</span><span class="p">,</span> <span class="n">running_prod</span><span class="p">,</span> <span class="n">curr_core</span><span class="p">,</span>
                                 <span class="n">curr_core</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">running_prod</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">orth_tt</span> <span class="o">=</span> <span class="n">decompositions</span><span class="o">.</span><span class="n">orthogonalize_tt_cores</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">left_to_right</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="c1"># All the cores of orth_tt except the last one are orthogonal, hence</span>
    <span class="c1"># the Frobenius norm of orth_tt equals to the norm of the last core.</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">):</span>
      <span class="n">batch_size</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_batch_size</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
      <span class="n">last_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">orth_tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">last_core</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">orth_tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.full">
    <p>def <span class="ident">full</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Converts a TensorTrain into a regular tensor or matrix (tf.Tensor).</p>
<p>Args:
  tt: <code>TensorTrain</code> or <code>TensorTrainBatch</code> object.</p>
<p>Returns:
  tf.Tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.full', this);">Show source &equiv;</a></p>
  <div id="source-t3f.full" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">full</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Converts a TensorTrain into a regular tensor or matrix (tf.Tensor).</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrain` or `TensorTrainBatch` object.</span>

<span class="sd">  Returns:</span>
<span class="sd">    tf.Tensor.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">TensorTrainBatch</span><span class="p">):</span>
    <span class="c1"># Batch of Tensor Trains.</span>
    <span class="k">return</span> <span class="n">_full_tt_batch</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># TensorTrain object (not batch).</span>
    <span class="k">return</span> <span class="n">_full_tt</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.get_variable">
    <p>def <span class="ident">get_variable</span>(</p><p>name, dtype=None, initializer=None, regularizer=None, trainable=True, collections=None, caching_device=None, validate_shape=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns TensorTrain object with tf.Variables as the TT-cores.</p>
<p>Args:
  name: The name of the new or existing TensorTrain variable.
    Used to name the TT-cores.
  dtype: Type of the new or existing TensorTrain variable TT-cores (defaults
    to DT_FLOAT).
  initializer: TensorTrain or TensorTrainBatch, initializer for the variable
    if one is created.
  regularizer: A (TensorTrain -&gt; Tensor or None) function; the result of
    applying it on a newly created variable will be added to the collection
    GraphKeys.REGULARIZATION_LOSSES and can be used for regularization.
  trainable: If True also add the variable to the graph collection
    GraphKeys.TRAINABLE_VARIABLES (see tf.Variable).
  collections:  List of graph collections keys to add the Variables
    (underlying TT-cores). Defaults to [GraphKeys.GLOBAL_VARIABLES]
    (see tf.Variable).
  caching_device: Optional device string or function describing where
    the Variable should be cached for reading. Defaults to the Variable's
    device. If not None, caches on another device. Typical use is to cache
    on the device where the Ops using the Variable reside, to deduplicate
    copying through Switch and other conditional statements.
  validate_shape: If False, allows the variable to be initialized with a value
    of unknown shape. If True, the default, the shape of initial_value must be
    known.</p>
<p>Returns:
  The created or existing <code>TensorTrain</code> object with tf.Variables TT-cores.</p>
<p>Raises:
  <code>ValueError</code>: when creating a new variable and shape is not declared, when
    violating reuse during variable creation, or when initializer dtype and
    dtype don't match. Reuse is set inside variable_scope.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.get_variable', this);">Show source &equiv;</a></p>
  <div id="source-t3f.get_variable" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_variable</span><span class="p">(</span><span class="n">name</span><span class="p">,</span>
                 <span class="n">dtype</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">initializer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                 <span class="n">collections</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">caching_device</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">validate_shape</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns TensorTrain object with tf.Variables as the TT-cores.</span>

<span class="sd">  Args:</span>
<span class="sd">    name: The name of the new or existing TensorTrain variable.</span>
<span class="sd">      Used to name the TT-cores.</span>
<span class="sd">    dtype: Type of the new or existing TensorTrain variable TT-cores (defaults</span>
<span class="sd">      to DT_FLOAT).</span>
<span class="sd">    initializer: TensorTrain or TensorTrainBatch, initializer for the variable</span>
<span class="sd">      if one is created.</span>
<span class="sd">    regularizer: A (TensorTrain -&gt; Tensor or None) function; the result of</span>
<span class="sd">      applying it on a newly created variable will be added to the collection</span>
<span class="sd">      GraphKeys.REGULARIZATION_LOSSES and can be used for regularization.</span>
<span class="sd">    trainable: If True also add the variable to the graph collection</span>
<span class="sd">      GraphKeys.TRAINABLE_VARIABLES (see tf.Variable).</span>
<span class="sd">    collections:  List of graph collections keys to add the Variables</span>
<span class="sd">      (underlying TT-cores). Defaults to [GraphKeys.GLOBAL_VARIABLES]</span>
<span class="sd">      (see tf.Variable).</span>
<span class="sd">    caching_device: Optional device string or function describing where</span>
<span class="sd">      the Variable should be cached for reading. Defaults to the Variable&#39;s</span>
<span class="sd">      device. If not None, caches on another device. Typical use is to cache</span>
<span class="sd">      on the device where the Ops using the Variable reside, to deduplicate</span>
<span class="sd">      copying through Switch and other conditional statements.</span>
<span class="sd">    validate_shape: If False, allows the variable to be initialized with a value</span>
<span class="sd">      of unknown shape. If True, the default, the shape of initial_value must be</span>
<span class="sd">      known.</span>

<span class="sd">  Returns:</span>
<span class="sd">    The created or existing `TensorTrain` object with tf.Variables TT-cores.</span>

<span class="sd">  Raises:</span>
<span class="sd">    `ValueError`: when creating a new variable and shape is not declared, when</span>
<span class="sd">      violating reuse during variable creation, or when initializer dtype and</span>
<span class="sd">      dtype don&#39;t match. Reuse is set inside variable_scope.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># TODO: support validate shape: check that the tensor dimensions are correct,</span>
  <span class="c1"># but ignore the ranks.</span>
  <span class="c1"># TODO: add validate ranks flag.</span>

  <span class="n">reuse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">()</span><span class="o">.</span><span class="n">reuse</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">reuse</span> <span class="ow">and</span> <span class="n">initializer</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Scope reuse is False and initializer is not provided.&#39;</span><span class="p">)</span>

  <span class="n">variable_cores</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">if</span> <span class="n">reuse</span><span class="p">:</span>
    <span class="c1"># Find an existing variable in the collection.</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">()</span><span class="o">.</span><span class="n">name</span>
    <span class="k">if</span> <span class="n">path</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span> <span class="ow">and</span> <span class="n">path</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;/&#39;</span><span class="p">:</span>
      <span class="n">path</span> <span class="o">+=</span> <span class="s1">&#39;/&#39;</span>
    <span class="n">path</span> <span class="o">+=</span> <span class="n">name</span>

    <span class="n">found_v</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;TensorTrainVariables&#39;</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">path</span><span class="p">:</span>
        <span class="n">found_v</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">break</span>
    <span class="k">if</span> <span class="n">found_v</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;ValueError: Variable </span><span class="si">%s</span><span class="s1"> does not exist, or was not &#39;</span>
                       <span class="s1">&#39;created with t3f.get_tt_variable(). Did you mean to &#39;</span>
                       <span class="s1">&#39;set reuse=None in VarScope?&#39;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
      <span class="c1"># Try to get the first core through tf.get_variable to check that we don&#39;t</span>
      <span class="c1"># violate reuse: it will raise a ValueError otherwise.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;core_0&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">found_v</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># Create new variable.</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
      <span class="n">num_dims</span> <span class="o">=</span> <span class="n">initializer</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_dims</span><span class="p">):</span>
        <span class="n">curr_core_var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;core_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span>
                                        <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>
                                        <span class="n">collections</span><span class="o">=</span><span class="n">collections</span><span class="p">,</span>
                                        <span class="n">caching_device</span><span class="o">=</span><span class="n">caching_device</span><span class="p">)</span>
        <span class="n">variable_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_core_var</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">initializer</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
      <span class="n">v</span> <span class="o">=</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">variable_cores</span><span class="p">,</span> <span class="n">initializer</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                      <span class="n">initializer</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">(),</span>
                      <span class="n">convert_to_tensors</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">v</span> <span class="o">=</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">variable_cores</span><span class="p">,</span> <span class="n">initializer</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                           <span class="n">initializer</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">(),</span> <span class="n">initializer</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                           <span class="n">convert_to_tensors</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="c1"># Add the create TensorTrain object into a collection so that we can</span>
    <span class="c1"># retrieve it in the future by get_tt_variable(&#39;name&#39;).</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="s1">&#39;TensorTrainVariables&#39;</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

    <span class="c1"># Run the regularizer if requested and save the resulting loss.</span>
    <span class="k">if</span> <span class="n">regularizer</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;/Regularizer/&quot;</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">regularizer</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">vlog</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Applied regularizer to </span><span class="si">%s</span><span class="s2"> and added the result </span><span class="si">%s</span><span class="s2"> &quot;</span>
                        <span class="s2">&quot;to REGULARIZATION_LOSSES.&quot;</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">REGULARIZATION_LOSSES</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">v</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.gram_matrix">
    <p>def <span class="ident">gram_matrix</span>(</p><p>tt_vectors, matrix=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Computes Gramian matrix of a batch of TT-vecors.</p>
<p>If matrix is None, computes
  res[i, j] = t3f.flat_inner(tt_vectors[i], tt_vectors[j]).
If matrix is present, computes
    res[i, j] = t3f.flat_inner(tt_vectors[i], t3f.matmul(matrix, tt_vectors[j]))
  or more shortly
    res[i, j] = tt_vectors[i]^T * matrix * tt_vectors[j]
  but is more efficient.</p>
<p>Args:
  tt_vectors: TensorTrainBatch.
  matrix: None, or TensorTrain matrix.</p>
<p>Returns:
  tf.tensor with the Gram matrix.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.gram_matrix', this);">Show source &equiv;</a></p>
  <div id="source-t3f.gram_matrix" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">gram_matrix</span><span class="p">(</span><span class="n">tt_vectors</span><span class="p">,</span> <span class="n">matrix</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes Gramian matrix of a batch of TT-vecors.</span>

<span class="sd">  If matrix is None, computes</span>
<span class="sd">    res[i, j] = t3f.flat_inner(tt_vectors[i], tt_vectors[j]).</span>
<span class="sd">  If matrix is present, computes</span>
<span class="sd">      res[i, j] = t3f.flat_inner(tt_vectors[i], t3f.matmul(matrix, tt_vectors[j]))</span>
<span class="sd">    or more shortly</span>
<span class="sd">      res[i, j] = tt_vectors[i]^T * matrix * tt_vectors[j]</span>
<span class="sd">    but is more efficient.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt_vectors: TensorTrainBatch.</span>
<span class="sd">    matrix: None, or TensorTrain matrix.</span>

<span class="sd">  Returns:</span>
<span class="sd">    tf.tensor with the Gram matrix.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">pairwise_flat_inner</span><span class="p">(</span><span class="n">tt_vectors</span><span class="p">,</span> <span class="n">tt_vectors</span><span class="p">,</span> <span class="n">matrix</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.is_batch_broadcasting_possible">
    <p>def <span class="ident">is_batch_broadcasting_possible</span>(</p><p>tt_a, tt_b)</p>
    </div>
    

    
  
    <div class="desc"><p>Check that the batch broadcasting possible for the given batch sizes.</p>
<p>Returns true if the batch sizes are the same or if one of them is 1.</p>
<p>Args:
  tt_a: TensorTrain or TensorTrainBatch
  tt_b: TensorTrain or TensorTrainBatch</p>
<p>Returns:
  Bool</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.is_batch_broadcasting_possible', this);">Show source &equiv;</a></p>
  <div id="source-t3f.is_batch_broadcasting_possible" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">is_batch_broadcasting_possible</span><span class="p">(</span><span class="n">tt_a</span><span class="p">,</span> <span class="n">tt_b</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Check that the batch broadcasting possible for the given batch sizes.</span>

<span class="sd">  Returns true if the batch sizes are the same or if one of them is 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt_a: TensorTrain or TensorTrainBatch</span>
<span class="sd">    tt_b: TensorTrain or TensorTrainBatch</span>

<span class="sd">  Returns:</span>
<span class="sd">    Bool</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">tt_b</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="c1"># If one of the batch sizes is not available on the compilation stage,</span>
      <span class="c1"># we cannot say if broadcasting is possible.</span>
      <span class="k">return</span> <span class="bp">True</span>
    <span class="k">if</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">==</span> <span class="n">tt_b</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">True</span>
    <span class="k">if</span> <span class="n">tt_a</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">tt_b</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">True</span>
    <span class="k">return</span> <span class="bp">False</span>
  <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
    <span class="c1"># One or both of the arguments are not batch tensor, but single TT tensors.</span>
    <span class="c1"># In this case broadcasting is always possible.</span>
    <span class="k">return</span> <span class="bp">True</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.l2_regularizer">
    <p>def <span class="ident">l2_regularizer</span>(</p><p>scale, scope=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns a function that applies L2 regularization to TensorTrain weights.</p>
<p>Args:
  scale: A scalar multiplier <code>Tensor</code>. 0.0 disables the regularizer.
  scope: An optional scope name.</p>
<p>Returns:
  A function with signature <code>l2(tt)</code> that applies L2 regularization.</p>
<p>Raises:
  ValueError: If scale is negative or if scale is not a float.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.l2_regularizer', this);">Show source &equiv;</a></p>
  <div id="source-t3f.l2_regularizer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">l2_regularizer</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a function that applies L2 regularization to TensorTrain weights.</span>

<span class="sd">  Args:</span>
<span class="sd">    scale: A scalar multiplier `Tensor`. 0.0 disables the regularizer.</span>
<span class="sd">    scope: An optional scope name.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A function with signature `l2(tt)` that applies L2 regularization.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: If scale is negative or if scale is not a float.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;scale cannot be an integer: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">scale</span><span class="p">,))</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">scale</span> <span class="o">&lt;</span> <span class="mf">0.</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Setting a scale less than 0 on a regularizer: </span><span class="si">%g</span><span class="s1">.&#39;</span> <span class="o">%</span>
                       <span class="n">scale</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">scale</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Scale of 0 disables regularizer.&#39;</span><span class="p">)</span>
      <span class="k">return</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="bp">None</span>

  <span class="k">def</span> <span class="nf">l2</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies l2 regularization to TensorTrain object.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">,</span> <span class="s1">&#39;l2_regularizer&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">tt</span><span class="p">])</span> <span class="k">as</span> <span class="n">name</span><span class="p">:</span>
      <span class="n">my_scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">tt</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">base_dtype</span><span class="p">,</span>
                                       <span class="n">name</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">my_scale</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">frobenius_norm_squared</span><span class="p">(</span><span class="n">tt</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">l2</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.lazy_batch_size">
    <p>def <span class="ident">lazy_batch_size</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Return static batch_size if available and dynamic otherwise.</p>
<p>Args:
  tt: <code>TensorTrainBatch</code> object.</p>
<p>Returns:
  A number or a 0-D <code>tf.Tensor</code></p>
<p>Raises:
  ValueError if got <code>TensorTrain</code> which doesn't have batch_size as input.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.lazy_batch_size', this);">Show source &equiv;</a></p>
  <div id="source-t3f.lazy_batch_size" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">lazy_batch_size</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return static batch_size if available and dynamic otherwise.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrainBatch` object.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A number or a 0-D `tf.Tensor`</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError if got `TensorTrain` which doesn&#39;t have batch_size as input.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;batch size is not available for a TensorTrain object.&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">tt</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tt</span><span class="o">.</span><span class="n">batch_size</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">batch_size</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.lazy_raw_shape">
    <p>def <span class="ident">lazy_raw_shape</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns static raw shape of a TensorTrain if defined, and dynamic otherwise.</p>
<p>This operation returns a 2-D integer numpy array representing the raw shape of
the input if it is available on the graph compilation stage and 2-D integer
tensor of dynamic shape otherwise.
If the input is a TT-tensor, the raw shape will have 1 x ndims() elements.
If the input is a TT-matrix, the raw shape will have 2 x ndims() elements
representing the underlying tensor shape of the matrix.</p>
<p>Args:
  tt: <code>TensorTrain</code> object.</p>
<p>Returns:
  A 2-D numpy array or <code>tf.Tensor</code> of size 1 x ndims() or 2 x ndims()</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.lazy_raw_shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.lazy_raw_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">lazy_raw_shape</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns static raw shape of a TensorTrain if defined, and dynamic otherwise.</span>

<span class="sd">  This operation returns a 2-D integer numpy array representing the raw shape of</span>
<span class="sd">  the input if it is available on the graph compilation stage and 2-D integer</span>
<span class="sd">  tensor of dynamic shape otherwise.</span>
<span class="sd">  If the input is a TT-tensor, the raw shape will have 1 x ndims() elements.</span>
<span class="sd">  If the input is a TT-matrix, the raw shape will have 2 x ndims() elements</span>
<span class="sd">  representing the underlying tensor shape of the matrix.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrain` object.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A 2-D numpy array or `tf.Tensor` of size 1 x ndims() or 2 x ndims()</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># If get_shape is fully defined, it guaranties that all elements of raw shape</span>
  <span class="c1"># are defined.</span>
  <span class="k">if</span> <span class="n">tt</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">tt</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()])</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">raw_shape</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.lazy_shape">
    <p>def <span class="ident">lazy_shape</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns static shape of a TensorTrain if defined, and dynamic otherwise.</p>
<p>This operation returns a 1-D integer numpy array representing the shape of the
input if it is available on the graph compilation stage and 1-D integer tensor
of dynamic shape otherwise.</p>
<p>Args:
  tt: <code>TensorTrain</code> object.</p>
<p>Returns:
  A 1-D numpy array or <code>tf.Tensor</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.lazy_shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.lazy_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">lazy_shape</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns static shape of a TensorTrain if defined, and dynamic otherwise.</span>

<span class="sd">  This operation returns a 1-D integer numpy array representing the shape of the</span>
<span class="sd">  input if it is available on the graph compilation stage and 1-D integer tensor</span>
<span class="sd">  of dynamic shape otherwise.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrain` object.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A 1-D numpy array or `tf.Tensor`</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">static_shape</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">static_shape</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">static_shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">shape</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.lazy_tt_ranks">
    <p>def <span class="ident">lazy_tt_ranks</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns static TT-ranks of a TensorTrain if defined, and dynamic otherwise.</p>
<p>This operation returns a 1-D integer numpy array of TT-ranks if they are
available on the graph compilation stage and 1-D integer tensor of dynamic
TT-ranks otherwise.</p>
<p>Args:
  tt: <code>TensorTrain</code> object.</p>
<p>Returns:
  A 1-D numpy array or <code>tf.Tensor</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.lazy_tt_ranks', this);">Show source &equiv;</a></p>
  <div id="source-t3f.lazy_tt_ranks" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">lazy_tt_ranks</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns static TT-ranks of a TensorTrain if defined, and dynamic otherwise.</span>

<span class="sd">  This operation returns a 1-D integer numpy array of TT-ranks if they are</span>
<span class="sd">  available on the graph compilation stage and 1-D integer tensor of dynamic</span>
<span class="sd">  TT-ranks otherwise.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrain` object.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A 1-D numpy array or `tf.Tensor`</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">static_tt_ranks</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">static_tt_ranks</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">static_tt_ranks</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tt_ranks</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.matmul">
    <p>def <span class="ident">matmul</span>(</p><p>a, b)</p>
    </div>
    

    
  
    <div class="desc"><p>Multiplies two matrices that can be TT-, dense, or sparse.</p>
<p>Note that multiplication of two TT-matrices returns a TT-matrix with much
larger ranks.
Also works for multiplying two batches of TT-matrices or a product between a
TT-matrix and a batch of TT-matrices (with broadcasting).</p>
<p>Args:
  a: <code>TensorTrain</code>, <code>TensorTrainBatch</code>, tf.Tensor, or tf.SparseTensor of
    size M x N
  b: <code>TensorTrain</code>, <code>TensorTrainBatch</code>, tf.Tensor, or tf.SparseTensor of
    size N x P</p>
<p>Returns
  If both arguments are <code>TensorTrain</code> objects, returns a <code>TensorTrain</code>
    object containing a TT-matrix of size M x P.
  If at least one of the arguments is a <code>TensorTrainBatch</code> object, returns
    a <code>TensorTrainBatch</code> object containing a batch of TT-matrices of size
    M x P.
  Otherwise, returns tf.Tensor of size M x P.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.matmul', this);">Show source &equiv;</a></p>
  <div id="source-t3f.matmul" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Multiplies two matrices that can be TT-, dense, or sparse.</span>

<span class="sd">  Note that multiplication of two TT-matrices returns a TT-matrix with much</span>
<span class="sd">  larger ranks.</span>
<span class="sd">  Also works for multiplying two batches of TT-matrices or a product between a</span>
<span class="sd">  TT-matrix and a batch of TT-matrices (with broadcasting).</span>

<span class="sd">  Args:</span>
<span class="sd">    a: `TensorTrain`, `TensorTrainBatch`, tf.Tensor, or tf.SparseTensor of</span>
<span class="sd">      size M x N</span>
<span class="sd">    b: `TensorTrain`, `TensorTrainBatch`, tf.Tensor, or tf.SparseTensor of</span>
<span class="sd">      size N x P</span>

<span class="sd">  Returns</span>
<span class="sd">    If both arguments are `TensorTrain` objects, returns a `TensorTrain`</span>
<span class="sd">      object containing a TT-matrix of size M x P.</span>
<span class="sd">    If at least one of the arguments is a `TensorTrainBatch` object, returns</span>
<span class="sd">      a `TensorTrainBatch` object containing a batch of TT-matrices of size</span>
<span class="sd">      M x P.</span>
<span class="sd">    Otherwise, returns tf.Tensor of size M x P.</span>
<span class="sd">  &quot;&quot;&quot;</span>
<span class="c1">#   TODO: is it safe to check types? What if a class is derived from TT?</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">TensorTrainBase</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">TensorTrainBase</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tt_tt_matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tt_dense_matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">dense_tt_matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tt_sparse_matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sparse_tt_matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Argument types are not supported in matmul: </span><span class="si">%s</span><span class="s1"> x </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
                     <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.multiply">
    <p>def <span class="ident">multiply</span>(</p><p>tt_left, right)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns a TensorTrain corresponding to element-wise product tt_left * right.</p>
<p>The shapes of tt_left and right should coincide.</p>
<p>Args:
  tt_left: <code>TensorTrain</code>, TT-tensor or TT-matrix
  right: <code>TensorTrain</code>, TT-tensor or TT-matrix, OR a number.</p>
<p>Returns
  a <code>TensorTrain</code> object corresponding to the element-wise product of the
  arguments.</p>
<p>Raises
  ValueError if the arguments shapes do not coincide.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.multiply', this);">Show source &equiv;</a></p>
  <div id="source-t3f.multiply" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">multiply</span><span class="p">(</span><span class="n">tt_left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a TensorTrain corresponding to element-wise product tt_left * right.</span>

<span class="sd">  The shapes of tt_left and right should coincide.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt_left: `TensorTrain`, TT-tensor or TT-matrix</span>
<span class="sd">    right: `TensorTrain`, TT-tensor or TT-matrix, OR a number.</span>

<span class="sd">  Returns</span>
<span class="sd">    a `TensorTrain` object corresponding to the element-wise product of the</span>
<span class="sd">    arguments.</span>

<span class="sd">  Raises</span>
<span class="sd">    ValueError if the arguments shapes do not coincide.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">right</span><span class="p">,</span> <span class="n">TensorTrainBase</span><span class="p">):</span>
    <span class="c1"># Assume right is a number, not TensorTrain.</span>
    <span class="n">tt_cores</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tt_left</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">)</span>
    <span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">right</span> <span class="o">*</span> <span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_ranks</span> <span class="o">=</span> <span class="n">tt_left</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">ndims</span> <span class="o">=</span> <span class="n">tt_left</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">tt_left</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">()</span> <span class="o">!=</span> <span class="n">right</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The arguments should be both TT-tensors or both &#39;</span>
                       <span class="s1">&#39;TT-matrices&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">tt_left</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span> <span class="o">!=</span> <span class="n">right</span><span class="o">.</span><span class="n">get_shape</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The arguments should have the same shape.&#39;</span><span class="p">)</span>

    <span class="n">a_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_tt_ranks</span><span class="p">(</span><span class="n">tt_left</span><span class="p">)</span>
    <span class="n">b_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_tt_ranks</span><span class="p">(</span><span class="n">right</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_raw_shape</span><span class="p">(</span><span class="n">tt_left</span><span class="p">)</span>

    <span class="n">is_matrix</span> <span class="o">=</span> <span class="n">tt_left</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">()</span>
    <span class="n">tt_cores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span><span class="p">):</span>
      <span class="n">a_core</span> <span class="o">=</span> <span class="n">tt_left</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">b_core</span> <span class="o">=</span> <span class="n">right</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">left_rank</span> <span class="o">=</span> <span class="n">a_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">b_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">right_rank</span> <span class="o">=</span> <span class="n">a_ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">b_ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">is_matrix</span><span class="p">:</span>
        <span class="n">curr_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;aijb,cijd-&gt;acijbd&#39;</span><span class="p">,</span> <span class="n">a_core</span><span class="p">,</span> <span class="n">b_core</span><span class="p">)</span>
        <span class="n">curr_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">curr_core</span><span class="p">,</span> <span class="p">(</span><span class="n">left_rank</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">core_idx</span><span class="p">],</span>
                                           <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">right_rank</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">curr_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;aib,cid-&gt;acibd&#39;</span><span class="p">,</span> <span class="n">a_core</span><span class="p">,</span> <span class="n">b_core</span><span class="p">)</span>
        <span class="n">curr_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">curr_core</span><span class="p">,</span> <span class="p">(</span><span class="n">left_rank</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">core_idx</span><span class="p">],</span>
                                           <span class="n">right_rank</span><span class="p">))</span>
      <span class="n">tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_core</span><span class="p">)</span>

    <span class="n">combined_ranks</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tt_left</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">(),</span> <span class="n">right</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">())</span>
    <span class="n">out_ranks</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span> <span class="o">*</span> <span class="n">b</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">combined_ranks</span><span class="p">]</span>

  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_left</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">tt_left</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span> <span class="n">out_ranks</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">tt_left</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span> <span class="n">out_ranks</span><span class="p">,</span>
                            <span class="n">tt_left</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.multiply_along_batch_dim">
    <p>def <span class="ident">multiply_along_batch_dim</span>(</p><p>batch_tt, weights)</p>
    </div>
    

    
  
    <div class="desc"><p>Multiply each TensorTrain in a batch by a number.</p>
<p>Args:
  batch_tt: TensorTrainBatch object, TT-matrices or TT-tensors.
  weights: 1-D tf.Tensor (or something convertible to it like np.array) of size
   tt.batch_sie with weights. </p>
<p>Returns:
  TensorTrainBatch</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.multiply_along_batch_dim', this);">Show source &equiv;</a></p>
  <div id="source-t3f.multiply_along_batch_dim" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">multiply_along_batch_dim</span><span class="p">(</span><span class="n">batch_tt</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Multiply each TensorTrain in a batch by a number.</span>

<span class="sd">  Args:</span>
<span class="sd">    batch_tt: TensorTrainBatch object, TT-matrices or TT-tensors.</span>
<span class="sd">    weights: 1-D tf.Tensor (or something convertible to it like np.array) of size</span>
<span class="sd">     tt.batch_sie with weights. </span>

<span class="sd">  Returns:</span>
<span class="sd">    TensorTrainBatch</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
  <span class="n">tt_cores</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch_tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">batch_tt</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[:,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[:,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
  <span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">*</span> <span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">out_shape</span> <span class="o">=</span> <span class="n">batch_tt</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span>
  <span class="n">out_ranks</span> <span class="o">=</span> <span class="n">batch_tt</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>
  <span class="n">out_batch_size</span> <span class="o">=</span> <span class="n">batch_tt</span><span class="o">.</span><span class="n">batch_size</span>
  <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">out_shape</span><span class="p">,</span> <span class="n">out_ranks</span><span class="p">,</span> <span class="n">out_batch_size</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.orthogonalize_tt_cores">
    <p>def <span class="ident">orthogonalize_tt_cores</span>(</p><p>tt, left_to_right=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Orthogonalize TT-cores of a TT-object.</p>
<p>Args:
  tt: TenosorTrain or a TensorTrainBatch.
  left_to_right: bool, the direction of orthogonalization.</p>
<p>Returns:
  The same type as the input <code>tt</code> (TenosorTrain or a TensorTrainBatch).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.orthogonalize_tt_cores', this);">Show source &equiv;</a></p>
  <div id="source-t3f.orthogonalize_tt_cores" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">orthogonalize_tt_cores</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">left_to_right</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Orthogonalize TT-cores of a TT-object.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: TenosorTrain or a TensorTrainBatch.</span>
<span class="sd">    left_to_right: bool, the direction of orthogonalization.</span>

<span class="sd">  Returns:</span>
<span class="sd">    The same type as the input `tt` (TenosorTrain or a TensorTrainBatch).</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">TensorTrainBatch</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">left_to_right</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">_orthogonalize_batch_tt_cores_left_to_right</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Batch right to left orthogonalization is not &#39;</span>
                                <span class="s1">&#39;supported yet.&#39;</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">left_to_right</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">_orthogonalize_tt_cores_left_to_right</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">_orthogonalize_tt_cores_right_to_left</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.pairwise_flat_inner">
    <p>def <span class="ident">pairwise_flat_inner</span>(</p><p>tt_1, tt_2, matrix=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Computes all scalar products between two batches of TT-objects.</p>
<p>If matrix is None, computes
  res[i, j] = t3f.flat_inner(tt_1[i], tt_2[j]).</p>
<p>If matrix is present, computes
    res[i, j] = t3f.flat_inner(tt_1[i], t3f.matmul(matrix, tt_2[j]))
  or more shortly
    res[i, j] = tt_1[i]^T * matrix * tt_2[j]
  but is more efficient.</p>
<p>Args:
  tt_1: TensorTrainBatch.
  tt_2: TensorTrainBatch.
  matrix: None, or TensorTrain matrix.</p>
<p>Returns:
  tf.tensor with the matrix of pairwise scalar products (flat inners).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.pairwise_flat_inner', this);">Show source &equiv;</a></p>
  <div id="source-t3f.pairwise_flat_inner" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">pairwise_flat_inner</span><span class="p">(</span><span class="n">tt_1</span><span class="p">,</span> <span class="n">tt_2</span><span class="p">,</span> <span class="n">matrix</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes all scalar products between two batches of TT-objects.</span>

<span class="sd">  If matrix is None, computes</span>
<span class="sd">    res[i, j] = t3f.flat_inner(tt_1[i], tt_2[j]).</span>
<span class="sd">    </span>
<span class="sd">  If matrix is present, computes</span>
<span class="sd">      res[i, j] = t3f.flat_inner(tt_1[i], t3f.matmul(matrix, tt_2[j]))</span>
<span class="sd">    or more shortly</span>
<span class="sd">      res[i, j] = tt_1[i]^T * matrix * tt_2[j]</span>
<span class="sd">    but is more efficient.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt_1: TensorTrainBatch.</span>
<span class="sd">    tt_2: TensorTrainBatch.</span>
<span class="sd">    matrix: None, or TensorTrain matrix.</span>

<span class="sd">  Returns:</span>
<span class="sd">    tf.tensor with the matrix of pairwise scalar products (flat inners).</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">ndims</span> <span class="o">=</span> <span class="n">tt_1</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">matrix</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">curr_core_1</span> <span class="o">=</span> <span class="n">tt_1</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">curr_core_2</span> <span class="o">=</span> <span class="n">tt_2</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">mode_string</span> <span class="o">=</span> <span class="s1">&#39;ij&#39;</span> <span class="k">if</span> <span class="n">tt_1</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;i&#39;</span>
    <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;pa{0}b,qc{0}d-&gt;pqbd&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_string</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">curr_core_1</span><span class="p">,</span> <span class="n">curr_core_2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ndims</span><span class="p">):</span>
      <span class="n">curr_core_1</span> <span class="o">=</span> <span class="n">tt_1</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">curr_core_2</span> <span class="o">=</span> <span class="n">tt_2</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;pqac,pa{0}b,qc{0}d-&gt;pqbd&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_string</span><span class="p">)</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">curr_core_1</span><span class="p">,</span> <span class="n">curr_core_2</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># res[i, j] = tt_1[i] ^ T * matrix * tt_2[j]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">tt_1</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">()</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">tt_2</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">()</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">matrix</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;When passing three arguments to pairwise_flat_inner, &#39;</span>
                       <span class="s1">&#39;the first 2 of them should be TT-vecors and the last &#39;</span>
                       <span class="s1">&#39;should be a TT-matrix. Got </span><span class="si">%s</span><span class="s1">, </span><span class="si">%s</span><span class="s1">, and </span><span class="si">%s</span><span class="s1"> instead.&#39;</span> <span class="o">%</span>
                       <span class="p">(</span><span class="n">tt_1</span><span class="p">,</span> <span class="n">tt_2</span><span class="p">,</span> <span class="n">matrix</span><span class="p">))</span>
    <span class="n">matrix_shape</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">tt_1</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">matrix_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The shape of the first argument should be compatible &#39;</span>
                       <span class="s1">&#39;with the shape of the TT-matrix, that is it should be &#39;</span>
                       <span class="s1">&#39;possible to do the following matmul: &#39;</span>
                       <span class="s1">&#39;transpose(tt_1) * matrix. Got the first argument &#39;</span>
                       <span class="s1">&#39;&quot;</span><span class="si">%s</span><span class="s1">&quot; and matrix &quot;</span><span class="si">%s</span><span class="s1">&quot;&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tt_1</span><span class="p">,</span> <span class="n">matrix</span><span class="p">))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">tt_2</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">matrix_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The shape of the second argument should be compatible &#39;</span>
                       <span class="s1">&#39;with the shape of the TT-matrix, that is it should be &#39;</span>
                       <span class="s1">&#39;possible to do the following matmul: &#39;</span>
                       <span class="s1">&#39;matrix * tt_2. Got the second argument &#39;</span>
                       <span class="s1">&#39;&quot;</span><span class="si">%s</span><span class="s1">&quot; and matrix &quot;</span><span class="si">%s</span><span class="s1">&quot;&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tt_2</span><span class="p">,</span> <span class="n">matrix</span><span class="p">))</span>

    <span class="n">vectors_1_shape</span> <span class="o">=</span> <span class="n">tt_1</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">vectors_1_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">vectors_1_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># TODO: not very efficient, better to use different order in einsum.</span>
      <span class="n">tt_1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tt_1</span><span class="p">)</span>
    <span class="n">vectors_1_shape</span> <span class="o">=</span> <span class="n">tt_1</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
    <span class="n">vectors_2_shape</span> <span class="o">=</span> <span class="n">tt_2</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">vectors_2_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">vectors_2_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># TODO: not very efficient, better to use different order in einsum.</span>
      <span class="n">tt_2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tt_2</span><span class="p">)</span>
    <span class="n">vectors_2_shape</span> <span class="o">=</span> <span class="n">tt_2</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">vectors_1_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># TODO: do something so that in case the shape is undefined on compilation</span>
      <span class="c1"># it still works.</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The tt_vectors_1 argument should be vectors (not &#39;</span>
                       <span class="s1">&#39;matrices) with shape defined on compilation.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">vectors_2_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># TODO: do something so that in case the shape is undefined on compilation</span>
      <span class="c1"># it still works.</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The tt_vectors_2 argument should be vectors (not &#39;</span>
                       <span class="s1">&#39;matrices) with shape defined on compilation.&#39;</span><span class="p">)</span>
    <span class="n">curr_core_1</span> <span class="o">=</span> <span class="n">tt_1</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">curr_core_2</span> <span class="o">=</span> <span class="n">tt_2</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">curr_matrix_core</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># We enumerate the dummy dimension (that takes 1 value) with `k`.</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;pakib,cijd,qekjf-&gt;pqbdf&#39;</span><span class="p">,</span> <span class="n">curr_core_1</span><span class="p">,</span> <span class="n">curr_matrix_core</span><span class="p">,</span>
                    <span class="n">curr_core_2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ndims</span><span class="p">):</span>
      <span class="n">curr_core_1</span> <span class="o">=</span> <span class="n">tt_1</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">curr_core_2</span> <span class="o">=</span> <span class="n">tt_2</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">curr_matrix_core</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;pqace,pakib,cijd,qekjf-&gt;pqbdf&#39;</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">curr_core_1</span><span class="p">,</span>
                      <span class="n">curr_matrix_core</span><span class="p">,</span> <span class="n">curr_core_2</span><span class="p">)</span>

  <span class="c1"># Squeeze to make the result of size batch_size x batch_size instead of</span>
  <span class="c1"># batch_size x batch_size x 1 x 1.</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.pairwise_flat_inner_projected">
    <p>def <span class="ident">pairwise_flat_inner_projected</span>(</p><p>projected_tt_vectors_1, projected_tt_vectors_2)</p>
    </div>
    

    
  
    <div class="desc"><p>Scalar products between two batches of TTs from the same tangent space.</p>
<p>res[i, j] = t3f.flat_inner(projected_tt_vectors_1[i], projected_tt_vectors_1[j]).</p>
<p>pairwise_flat_inner_projected(projected_tt_vectors_1, projected_tt_vectors_2)
is equivalent to
  pairwise_flat_inner(projected_tt_vectors_1, projected_tt_vectors_2)
, but works only on objects from the same tangent space and is much faster
than general pairwise_flat_inner. </p>
<p>Args:
  projected_tt_vectors_1: TensorTrainBatch of tensors projected on the same
    tangent space as projected_tt_vectors_2.
  projected_tt_vectors_2: TensorTrainBatch.</p>
<p>Returns:
  tf.tensor with the scalar product matrix.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.pairwise_flat_inner_projected', this);">Show source &equiv;</a></p>
  <div id="source-t3f.pairwise_flat_inner_projected" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">pairwise_flat_inner_projected</span><span class="p">(</span><span class="n">projected_tt_vectors_1</span><span class="p">,</span>
                                  <span class="n">projected_tt_vectors_2</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Scalar products between two batches of TTs from the same tangent space.</span>
<span class="sd">  </span>
<span class="sd">    res[i, j] = t3f.flat_inner(projected_tt_vectors_1[i], projected_tt_vectors_1[j]).</span>
<span class="sd">  </span>
<span class="sd">  pairwise_flat_inner_projected(projected_tt_vectors_1, projected_tt_vectors_2)</span>
<span class="sd">  is equivalent to</span>
<span class="sd">    pairwise_flat_inner(projected_tt_vectors_1, projected_tt_vectors_2)</span>
<span class="sd">  , but works only on objects from the same tangent space and is much faster</span>
<span class="sd">  than general pairwise_flat_inner. </span>
<span class="sd">  </span>
<span class="sd">  Args:</span>
<span class="sd">    projected_tt_vectors_1: TensorTrainBatch of tensors projected on the same</span>
<span class="sd">      tangent space as projected_tt_vectors_2.</span>
<span class="sd">    projected_tt_vectors_2: TensorTrainBatch.</span>
<span class="sd">    </span>
<span class="sd">  Returns:</span>
<span class="sd">    tf.tensor with the scalar product matrix.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">projected_tt_vectors_1</span><span class="p">,</span> <span class="s1">&#39;projection_on&#39;</span><span class="p">)</span> <span class="ow">or</span> \
      <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">projected_tt_vectors_2</span><span class="p">,</span> <span class="s1">&#39;projection_on&#39;</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Both arguments should be projections on the tangent &#39;</span>
                     <span class="s1">&#39;space of some other TT-object. All projection* functions &#39;</span>
                     <span class="s1">&#39;leave .projection_on field in the resulting TT-object &#39;</span>
                     <span class="s1">&#39;which is not present in the arguments you</span><span class="se">\&#39;</span><span class="s1">ve provided&#39;</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">projected_tt_vectors_1</span><span class="o">.</span><span class="n">projection_on</span> <span class="o">!=</span> <span class="n">projected_tt_vectors_2</span><span class="o">.</span><span class="n">projection_on</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Both arguments should be projections on the tangent &#39;</span>
                     <span class="s1">&#39;space of the same TT-object. The provided arguments are &#39;</span>
                     <span class="s1">&#39;projections on different TT-objects (</span><span class="si">%s</span><span class="s1"> and </span><span class="si">%s</span><span class="s1">). Or at &#39;</span>
                     <span class="s1">&#39;least the pointers are different.&#39;</span> <span class="o">%</span>
                     <span class="p">(</span><span class="n">projected_tt_vectors_1</span><span class="o">.</span><span class="n">projection_on</span><span class="p">,</span>
                      <span class="n">projected_tt_vectors_2</span><span class="o">.</span><span class="n">projection_on</span><span class="p">))</span>

  <span class="c1"># Always work with batches of objects for simplicity.</span>
  <span class="n">projected_tt_vectors_1</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">expand_batch_dim</span><span class="p">(</span><span class="n">projected_tt_vectors_1</span><span class="p">)</span>
  <span class="n">projected_tt_vectors_2</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">expand_batch_dim</span><span class="p">(</span><span class="n">projected_tt_vectors_2</span><span class="p">)</span>

  <span class="n">ndims</span> <span class="o">=</span> <span class="n">projected_tt_vectors_1</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
  <span class="n">tt_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_tt_ranks</span><span class="p">(</span><span class="n">projected_tt_vectors_1</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">projected_tt_vectors_1</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
    <span class="n">right_size</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">curr_core_1</span> <span class="o">=</span> <span class="n">projected_tt_vectors_1</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">curr_core_2</span> <span class="o">=</span> <span class="n">projected_tt_vectors_2</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">curr_du_1</span> <span class="o">=</span> <span class="n">curr_core_1</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">right_size</span><span class="p">]</span>
    <span class="n">curr_du_2</span> <span class="o">=</span> <span class="n">curr_core_2</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">right_size</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;paijb,qaijb-&gt;pq&#39;</span><span class="p">,</span> <span class="n">curr_du_1</span><span class="p">,</span> <span class="n">curr_du_2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ndims</span><span class="p">):</span>
      <span class="n">left_size</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
      <span class="n">right_size</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
      <span class="n">curr_core_1</span> <span class="o">=</span> <span class="n">projected_tt_vectors_1</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">curr_core_2</span> <span class="o">=</span> <span class="n">projected_tt_vectors_2</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">curr_du_1</span> <span class="o">=</span> <span class="n">curr_core_1</span><span class="p">[:,</span> <span class="n">left_size</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">right_size</span><span class="p">]</span>
      <span class="n">curr_du_2</span> <span class="o">=</span> <span class="n">curr_core_2</span><span class="p">[:,</span> <span class="n">left_size</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">right_size</span><span class="p">]</span>
      <span class="n">res</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;paijb,qaijb-&gt;pq&#39;</span><span class="p">,</span> <span class="n">curr_du_1</span><span class="p">,</span> <span class="n">curr_du_2</span><span class="p">)</span>

    <span class="n">left_size</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">curr_core_1</span> <span class="o">=</span> <span class="n">projected_tt_vectors_1</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">curr_core_2</span> <span class="o">=</span> <span class="n">projected_tt_vectors_2</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">curr_du_1</span> <span class="o">=</span> <span class="n">curr_core_1</span><span class="p">[:,</span> <span class="n">left_size</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">curr_du_2</span> <span class="o">=</span> <span class="n">curr_core_2</span><span class="p">[:,</span> <span class="n">left_size</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">res</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;paijb,qaijb-&gt;pq&#39;</span><span class="p">,</span> <span class="n">curr_du_1</span><span class="p">,</span> <span class="n">curr_du_2</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># Working with TT-tensor, not TT-matrix.</span>
    <span class="n">right_size</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">curr_core_1</span> <span class="o">=</span> <span class="n">projected_tt_vectors_1</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">curr_core_2</span> <span class="o">=</span> <span class="n">projected_tt_vectors_2</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">curr_du_1</span> <span class="o">=</span> <span class="n">curr_core_1</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">right_size</span><span class="p">]</span>
    <span class="n">curr_du_2</span> <span class="o">=</span> <span class="n">curr_core_2</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">right_size</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;paib,qaib-&gt;pq&#39;</span><span class="p">,</span> <span class="n">curr_du_1</span><span class="p">,</span> <span class="n">curr_du_2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ndims</span><span class="p">):</span>
      <span class="n">left_size</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
      <span class="n">right_size</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
      <span class="n">curr_core_1</span> <span class="o">=</span> <span class="n">projected_tt_vectors_1</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">curr_core_2</span> <span class="o">=</span> <span class="n">projected_tt_vectors_2</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">curr_du_1</span> <span class="o">=</span> <span class="n">curr_core_1</span><span class="p">[:,</span> <span class="n">left_size</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">right_size</span><span class="p">]</span>
      <span class="n">curr_du_2</span> <span class="o">=</span> <span class="n">curr_core_2</span><span class="p">[:,</span> <span class="n">left_size</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">right_size</span><span class="p">]</span>
      <span class="n">res</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;paib,qaib-&gt;pq&#39;</span><span class="p">,</span> <span class="n">curr_du_1</span><span class="p">,</span> <span class="n">curr_du_2</span><span class="p">)</span>

    <span class="n">left_size</span> <span class="o">=</span> <span class="n">tt_ranks</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">curr_core_1</span> <span class="o">=</span> <span class="n">projected_tt_vectors_1</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">curr_core_2</span> <span class="o">=</span> <span class="n">projected_tt_vectors_2</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">curr_du_1</span> <span class="o">=</span> <span class="n">curr_core_1</span><span class="p">[:,</span> <span class="n">left_size</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">curr_du_2</span> <span class="o">=</span> <span class="n">curr_core_2</span><span class="p">[:,</span> <span class="n">left_size</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">res</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;paib,qaib-&gt;pq&#39;</span><span class="p">,</span> <span class="n">curr_du_1</span><span class="p">,</span> <span class="n">curr_du_2</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">res</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.project">
    <p>def <span class="ident">project</span>(</p><p>what, where)</p>
    </div>
    

    
  
    <div class="desc"><p>Project <code>what</code> TTs on the tangent space of <code>where</code> TT.</p>
<p>project(what, x) = P_x(what)
project(batch_what, x) = batch(P_x(batch_what[0]), ..., P_x(batch_what[N]))</p>
<p>This function implements the algorithm from the paper [1], theorem 3.1.</p>
<p>[1] C. Lubich, I. Oseledets and B. Vandereycken, Time integration of
  Tensor Trains.</p>
<p>Args:
  what: TensorTrain or TensorTrainBatch. In the case of batch returns
    batch with projection of each individual tensor.
  where: TensorTrain, TT-tensor or TT-matrix on which tangent space to project</p>
<p>Returns:
   a TensorTrain with the TT-ranks equal 2 * tangent_space_tens.get_tt_ranks()</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.project', this);">Show source &equiv;</a></p>
  <div id="source-t3f.project" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">project</span><span class="p">(</span><span class="n">what</span><span class="p">,</span> <span class="n">where</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Project `what` TTs on the tangent space of `where` TT.</span>

<span class="sd">  project(what, x) = P_x(what)</span>
<span class="sd">  project(batch_what, x) = batch(P_x(batch_what[0]), ..., P_x(batch_what[N]))</span>

<span class="sd">  This function implements the algorithm from the paper [1], theorem 3.1.</span>

<span class="sd">  [1] C. Lubich, I. Oseledets and B. Vandereycken, Time integration of</span>
<span class="sd">    Tensor Trains.</span>

<span class="sd">  Args:</span>
<span class="sd">    what: TensorTrain or TensorTrainBatch. In the case of batch returns</span>
<span class="sd">      batch with projection of each individual tensor.</span>
<span class="sd">    where: TensorTrain, TT-tensor or TT-matrix on which tangent space to project</span>

<span class="sd">  Returns:</span>
<span class="sd">     a TensorTrain with the TT-ranks equal 2 * tangent_space_tens.get_tt_ranks()</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">where</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The first argument should be a TensorTrain object, got &#39;</span>
                     <span class="s1">&#39;&quot;</span><span class="si">%s</span><span class="s1">&quot;.&#39;</span> <span class="o">%</span> <span class="n">where</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span> <span class="o">!=</span> <span class="n">what</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The shapes of the tensor we want to project and of the &#39;</span>
                     <span class="s1">&#39;tensor on which tangent space we want to project should &#39;</span>
                     <span class="s1">&#39;match, got </span><span class="si">%s</span><span class="s1"> and </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span>
                     <span class="p">(</span><span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                      <span class="n">what</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()))</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">where</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">what</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Dtypes of the arguments should coincide, got </span><span class="si">%s</span><span class="s1"> and </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span>
                     <span class="p">(</span><span class="n">where</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                      <span class="n">what</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

  <span class="n">left_tangent_space_tens</span> <span class="o">=</span> <span class="n">decompositions</span><span class="o">.</span><span class="n">orthogonalize_tt_cores</span><span class="p">(</span>
    <span class="n">where</span><span class="p">)</span>
  <span class="n">right_tangent_space_tens</span> <span class="o">=</span> <span class="n">decompositions</span><span class="o">.</span><span class="n">orthogonalize_tt_cores</span><span class="p">(</span>
    <span class="n">left_tangent_space_tens</span><span class="p">,</span> <span class="n">left_to_right</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

  <span class="n">ndims</span> <span class="o">=</span> <span class="n">where</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">where</span><span class="o">.</span><span class="n">dtype</span>
  <span class="n">raw_shape</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_raw_shape</span><span class="p">(</span><span class="n">where</span><span class="p">)</span>
  <span class="n">right_tangent_tt_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_tt_ranks</span><span class="p">(</span><span class="n">right_tangent_space_tens</span><span class="p">)</span>
  <span class="n">left_tangent_tt_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_tt_ranks</span><span class="p">(</span><span class="n">left_tangent_space_tens</span><span class="p">)</span>

  <span class="c1"># For einsum notation.</span>
  <span class="n">mode_str</span> <span class="o">=</span> <span class="s1">&#39;ij&#39;</span> <span class="k">if</span> <span class="n">where</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;i&#39;</span>
  <span class="n">right_rank_dim</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">right_tt_rank_dim</span>
  <span class="n">left_rank_dim</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">left_tt_rank_dim</span>
  <span class="n">output_is_batch</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">what</span><span class="p">,</span> <span class="n">TensorTrainBatch</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
    <span class="n">output_batch_size</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">batch_size</span>

  <span class="c1"># Always work with batch of TT objects for simplicity.</span>
  <span class="n">what</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">expand_batch_dim</span><span class="p">(</span><span class="n">what</span><span class="p">)</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_batch_size</span><span class="p">(</span><span class="n">what</span><span class="p">)</span>

  <span class="c1"># Prepare rhs vectors.</span>
  <span class="c1"># rhs[core_idx] is of size</span>
  <span class="c1">#   batch_size x tensor_tt_ranks[core_idx] x tangent_tt_ranks[core_idx]</span>
  <span class="n">rhs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">ndims</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">rhs</span><span class="p">[</span><span class="n">ndims</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">tens_core</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">right_tang_core</span> <span class="o">=</span> <span class="n">right_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sa{0}b,sbd,c{0}d-&gt;sac&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
    <span class="n">rhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">tens_core</span><span class="p">,</span> <span class="n">rhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                              <span class="n">right_tang_core</span><span class="p">)</span>

  <span class="c1"># Prepare lhs vectors.</span>
  <span class="c1"># lhs[core_idx] is of size</span>
  <span class="c1">#   batch_size x tangent_tt_ranks[core_idx] x tensor_tt_ranks[core_idx]</span>
  <span class="n">lhs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">ndims</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">lhs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">tens_core</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">left_tang_core</span> <span class="o">=</span> <span class="n">left_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sab,a{0}c,sb{0}d-&gt;scd&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
    <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">left_tang_core</span><span class="p">,</span>
                                  <span class="n">tens_core</span><span class="p">)</span>

  <span class="c1"># Left to right sweep.</span>
  <span class="n">res_cores_list</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span><span class="p">):</span>
    <span class="n">tens_core</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">left_tang_core</span> <span class="o">=</span> <span class="n">left_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">right_tang_core</span> <span class="o">=</span> <span class="n">right_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">core_idx</span> <span class="o">&lt;</span> <span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sab,sb{0}c-&gt;sa{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
      <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">tens_core</span><span class="p">)</span>
      <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;a{0}b,sbc-&gt;sa{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
      <span class="n">proj_core</span> <span class="o">-=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">left_tang_core</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
      <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
        <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sa{0}b,sbc-&gt;sa{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sa{0}b,sbc-&gt;a{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
      <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">proj_core</span><span class="p">,</span> <span class="n">rhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">core_idx</span> <span class="o">==</span> <span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
        <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sab,sb{0}c-&gt;sa{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sab,sb{0}c-&gt;a{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
      <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">tens_core</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
      <span class="c1"># Add batch dimension of size output_batch_size to left_tang_core and</span>
      <span class="c1"># right_tang_core</span>
      <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">left_tang_core</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">right_tang_core</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">where</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
        <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">extended_left_tang_core</span><span class="p">,</span>
                                          <span class="p">[</span><span class="n">output_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">extended_right_tang_core</span><span class="p">,</span>
                                           <span class="p">[</span><span class="n">output_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">extended_left_tang_core</span><span class="p">,</span>
                                          <span class="p">[</span><span class="n">output_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">extended_right_tang_core</span><span class="p">,</span>
                                           <span class="p">[</span><span class="n">output_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">left_tang_core</span>
      <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">right_tang_core</span>

    <span class="k">if</span> <span class="n">core_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">res_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">proj_core</span><span class="p">,</span> <span class="n">extended_left_tang_core</span><span class="p">),</span>
                           <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">core_idx</span> <span class="o">==</span> <span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">res_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">extended_right_tang_core</span><span class="p">,</span> <span class="n">proj_core</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">left_rank_dim</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">rank_1</span> <span class="o">=</span> <span class="n">right_tangent_tt_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">rank_2</span> <span class="o">=</span> <span class="n">left_tangent_tt_ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">where</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
        <span class="n">mode_size_n</span> <span class="o">=</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">core_idx</span><span class="p">]</span>
        <span class="n">mode_size_m</span> <span class="o">=</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">core_idx</span><span class="p">]</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">rank_1</span><span class="p">,</span> <span class="n">mode_size_n</span><span class="p">,</span> <span class="n">mode_size_m</span><span class="p">,</span> <span class="n">rank_2</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">mode_size</span> <span class="o">=</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">core_idx</span><span class="p">]</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">rank_1</span><span class="p">,</span> <span class="n">mode_size</span><span class="p">,</span> <span class="n">rank_2</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">output_batch_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape</span>
      <span class="n">zeros</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">upper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">extended_right_tang_core</span><span class="p">,</span> <span class="n">zeros</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
      <span class="n">lower</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">proj_core</span><span class="p">,</span> <span class="n">extended_left_tang_core</span><span class="p">),</span>
                        <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
      <span class="n">res_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">upper</span><span class="p">,</span> <span class="n">lower</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">left_rank_dim</span><span class="p">)</span>
    <span class="n">res_cores_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res_core</span><span class="p">)</span>
  <span class="c1"># TODO: TT-ranks.</span>
  <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">res_cores_list</span><span class="p">,</span> <span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="n">output_batch_size</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">res_cores_list</span><span class="p">,</span> <span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">())</span>

  <span class="n">res</span><span class="o">.</span><span class="n">projection_on</span> <span class="o">=</span> <span class="n">where</span>
  <span class="k">return</span> <span class="n">res</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.project_matmul">
    <p>def <span class="ident">project_matmul</span>(</p><p>what, where, matrix)</p>
    </div>
    

    
  
    <div class="desc"><p>Project <code>matrix</code> * <code>what</code> TTs on the tangent space of <code>where</code> TT.</p>
<p>project(what, x) = P_x(what)
project(batch_what, x) = batch(P_x(batch_what[0]), ..., P_x(batch_what[N]))</p>
<p>This function implements the algorithm from the paper [1], theorem 3.1.</p>
<p>[1] C. Lubich, I. Oseledets and B. Vandereycken, Time integration of
  Tensor Trains.</p>
<p>Args:
  what: TensorTrain or TensorTrainBatch. In the case of batch returns
    batch with projection of each individual tensor.
  where: TensorTrain, TT-tensor or TT-matrix on which tangent space to project
  matrix: TensorTrain, TT-matrix to multiply by what</p>
<p>Returns:
   a TensorTrain with the TT-ranks equal 2 * tangent_space_tens.get_tt_ranks()</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.project_matmul', this);">Show source &equiv;</a></p>
  <div id="source-t3f.project_matmul" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">project_matmul</span><span class="p">(</span><span class="n">what</span><span class="p">,</span> <span class="n">where</span><span class="p">,</span> <span class="n">matrix</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Project `matrix` * `what` TTs on the tangent space of `where` TT.</span>

<span class="sd">  project(what, x) = P_x(what)</span>
<span class="sd">  project(batch_what, x) = batch(P_x(batch_what[0]), ..., P_x(batch_what[N]))</span>

<span class="sd">  This function implements the algorithm from the paper [1], theorem 3.1.</span>

<span class="sd">  [1] C. Lubich, I. Oseledets and B. Vandereycken, Time integration of</span>
<span class="sd">    Tensor Trains.</span>

<span class="sd">  Args:</span>
<span class="sd">    what: TensorTrain or TensorTrainBatch. In the case of batch returns</span>
<span class="sd">      batch with projection of each individual tensor.</span>
<span class="sd">    where: TensorTrain, TT-tensor or TT-matrix on which tangent space to project</span>
<span class="sd">    matrix: TensorTrain, TT-matrix to multiply by what</span>

<span class="sd">  Returns:</span>
<span class="sd">     a TensorTrain with the TT-ranks equal 2 * tangent_space_tens.get_tt_ranks()</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">where</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The first argument should be a TensorTrain object, got &#39;</span>
                     <span class="s1">&#39;&quot;</span><span class="si">%s</span><span class="s1">&quot;.&#39;</span> <span class="o">%</span> <span class="n">where</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span> <span class="o">!=</span> <span class="n">what</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The shapes of the tensor we want to project and of the &#39;</span>
                     <span class="s1">&#39;tensor on which tangent space we want to project should &#39;</span>
                     <span class="s1">&#39;match, got </span><span class="si">%s</span><span class="s1"> and </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span>
                     <span class="p">(</span><span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                      <span class="n">what</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()))</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">where</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">what</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Dtypes of the arguments should coincide, got </span><span class="si">%s</span><span class="s1"> and </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span>
                     <span class="p">(</span><span class="n">where</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                      <span class="n">what</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

  <span class="n">left_tangent_space_tens</span> <span class="o">=</span> <span class="n">decompositions</span><span class="o">.</span><span class="n">orthogonalize_tt_cores</span><span class="p">(</span>
    <span class="n">where</span><span class="p">)</span>
  <span class="n">right_tangent_space_tens</span> <span class="o">=</span> <span class="n">decompositions</span><span class="o">.</span><span class="n">orthogonalize_tt_cores</span><span class="p">(</span>
    <span class="n">left_tangent_space_tens</span><span class="p">,</span> <span class="n">left_to_right</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

  <span class="n">ndims</span> <span class="o">=</span> <span class="n">where</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">where</span><span class="o">.</span><span class="n">dtype</span>
  <span class="n">raw_shape</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_raw_shape</span><span class="p">(</span><span class="n">where</span><span class="p">)</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_batch_size</span><span class="p">(</span><span class="n">what</span><span class="p">)</span>
  <span class="n">right_tangent_tt_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_tt_ranks</span><span class="p">(</span><span class="n">right_tangent_space_tens</span><span class="p">)</span>
  <span class="n">left_tangent_tt_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_tt_ranks</span><span class="p">(</span><span class="n">left_tangent_space_tens</span><span class="p">)</span>

  <span class="c1"># For einsum notation.</span>
  <span class="n">right_rank_dim</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">right_tt_rank_dim</span>
  <span class="n">left_rank_dim</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">left_tt_rank_dim</span>
  <span class="n">output_is_batch</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">what</span><span class="p">,</span> <span class="n">TensorTrainBatch</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
    <span class="n">output_batch_size</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">batch_size</span>

  <span class="c1"># Always work with batch of TT objects for simplicity.</span>
  <span class="n">what</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">expand_batch_dim</span><span class="p">(</span><span class="n">what</span><span class="p">)</span>

  <span class="c1"># Prepare rhs vectors.</span>
  <span class="c1"># rhs[core_idx] is of size</span>
  <span class="c1">#   batch_size x tensor_tt_ranks[core_idx] x matrix_tt_ranks[core_idx] x tangent_tt_ranks[core_idx]</span>
  <span class="n">rhs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">ndims</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">rhs</span><span class="p">[</span><span class="n">ndims</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">tens_core</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">right_tang_core</span> <span class="o">=</span> <span class="n">right_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">matrix_core</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">rhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bije,cikf,sdef,sajkd-&gt;sabc&#39;</span><span class="p">,</span> <span class="n">matrix_core</span><span class="p">,</span>
                              <span class="n">right_tang_core</span><span class="p">,</span> <span class="n">rhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">tens_core</span><span class="p">)</span>
  <span class="c1"># Prepare lhs vectors.</span>
  <span class="c1"># lhs[core_idx] is of size</span>
  <span class="c1">#   batch_size x tangent_tt_ranks[core_idx] x matrix_tt_ranks[core_idx] x tensor_tt_ranks[core_idx]</span>
  <span class="n">lhs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">ndims</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">lhs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">tens_core</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">left_tang_core</span> <span class="o">=</span> <span class="n">left_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">matrix_core</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="c1"># TODO: brutforce order of indices in lhs??</span>
    <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bije,aikd,sabc,scjkf-&gt;sdef&#39;</span><span class="p">,</span> <span class="n">matrix_core</span><span class="p">,</span>
                                  <span class="n">left_tang_core</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">tens_core</span><span class="p">)</span>

  <span class="c1"># Left to right sweep.</span>
  <span class="n">res_cores_list</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span><span class="p">):</span>
    <span class="n">tens_core</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">matrix_core</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">left_tang_core</span> <span class="o">=</span> <span class="n">left_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">right_tang_core</span> <span class="o">=</span> <span class="n">right_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">core_idx</span> <span class="o">&lt;</span> <span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;scjke,sabc,bijd-&gt;saikde&#39;</span><span class="p">,</span> <span class="n">tens_core</span><span class="p">,</span>
                            <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">matrix_core</span><span class="p">)</span>
      <span class="n">proj_core</span> <span class="o">-=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;aikb,sbcd-&gt;saikcd&#39;</span><span class="p">,</span> <span class="n">left_tang_core</span><span class="p">,</span>
                             <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;saikcb,sbcd-&gt;saikd&#39;</span><span class="p">,</span> <span class="n">proj_core</span><span class="p">,</span> <span class="n">rhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">core_idx</span> <span class="o">==</span> <span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># d and e dimensions take 1 value, since its the last rank.</span>
      <span class="c1"># To make the result shape (?, ?, ?, 1), we are summing d and leaving e,</span>
      <span class="c1"># but we could have done the opposite -- sum e and leave d.</span>
      <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;sabc,bijd,scjke-&gt;saike&#39;</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">matrix_core</span><span class="p">,</span>
                            <span class="n">tens_core</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
      <span class="c1"># Add batch dimension of size output_batch_size to left_tang_core and</span>
      <span class="c1"># right_tang_core</span>
      <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">left_tang_core</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">right_tang_core</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">extended_left_tang_core</span><span class="p">,</span>
                                        <span class="p">[</span><span class="n">output_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">extended_right_tang_core</span><span class="p">,</span>
                                         <span class="p">[</span><span class="n">output_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">left_tang_core</span>
      <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">right_tang_core</span>

    <span class="k">if</span> <span class="n">core_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">res_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">proj_core</span><span class="p">,</span> <span class="n">extended_left_tang_core</span><span class="p">),</span>
                           <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">core_idx</span> <span class="o">==</span> <span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">res_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">extended_right_tang_core</span><span class="p">,</span> <span class="n">proj_core</span><span class="p">),</span>
                           <span class="n">axis</span><span class="o">=</span><span class="n">left_rank_dim</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">rank_1</span> <span class="o">=</span> <span class="n">right_tangent_tt_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">rank_2</span> <span class="o">=</span> <span class="n">left_tangent_tt_ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
      <span class="n">mode_size_n</span> <span class="o">=</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">mode_size_m</span> <span class="o">=</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">rank_1</span><span class="p">,</span> <span class="n">mode_size_n</span><span class="p">,</span> <span class="n">mode_size_m</span><span class="p">,</span> <span class="n">rank_2</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">output_batch_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape</span>
      <span class="n">zeros</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">upper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">extended_right_tang_core</span><span class="p">,</span> <span class="n">zeros</span><span class="p">),</span>
                        <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
      <span class="n">lower</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">proj_core</span><span class="p">,</span> <span class="n">extended_left_tang_core</span><span class="p">),</span>
                        <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
      <span class="n">res_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">upper</span><span class="p">,</span> <span class="n">lower</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">left_rank_dim</span><span class="p">)</span>
    <span class="n">res_cores_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res_core</span><span class="p">)</span>

  <span class="c1"># TODO: TT-ranks.</span>
  <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">res_cores_list</span><span class="p">,</span> <span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="n">output_batch_size</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">res_cores_list</span><span class="p">,</span> <span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">())</span>

  <span class="n">res</span><span class="o">.</span><span class="n">projection_on</span> <span class="o">=</span> <span class="n">where</span>
  <span class="k">return</span> <span class="n">res</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.project_sum">
    <p>def <span class="ident">project_sum</span>(</p><p>what, where, weights=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Project sum of <code>what</code> TTs on the tangent space of <code>where</code> TT.</p>
<p>project_sum(what, x) = P_x(what)
project_sum(batch_what, x) = P_x(\sum_i batch_what[i])
project_sum(batch_what, x, weights) = P_x(\sum_j weights[j] * batch_what[j])</p>
<p>This function implements the algorithm from the paper [1], theorem 3.1.</p>
<p>[1] C. Lubich, I. Oseledets and B. Vandereycken, Time integration of
  Tensor Trains.</p>
<p>Args:
  what: TensorTrain or TensorTrainBatch. In the case of batch returns
    projection of the sum of elements in the batch.
  where: TensorTrain, TT-tensor or TT-matrix on which tangent space to project
  weights: python list or tf.Tensor of numbers or None, weights of the sum</p>
<p>Returns:
   a TensorTrain with the TT-ranks equal 2 * tangent_space_tens.get_tt_ranks()</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.project_sum', this);">Show source &equiv;</a></p>
  <div id="source-t3f.project_sum" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">project_sum</span><span class="p">(</span><span class="n">what</span><span class="p">,</span> <span class="n">where</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Project sum of `what` TTs on the tangent space of `where` TT.</span>

<span class="sd">  project_sum(what, x) = P_x(what)</span>
<span class="sd">  project_sum(batch_what, x) = P_x(\sum_i batch_what[i])</span>
<span class="sd">  project_sum(batch_what, x, weights) = P_x(\sum_j weights[j] * batch_what[j])</span>

<span class="sd">  This function implements the algorithm from the paper [1], theorem 3.1.</span>

<span class="sd">  [1] C. Lubich, I. Oseledets and B. Vandereycken, Time integration of</span>
<span class="sd">    Tensor Trains.</span>

<span class="sd">  Args:</span>
<span class="sd">    what: TensorTrain or TensorTrainBatch. In the case of batch returns</span>
<span class="sd">      projection of the sum of elements in the batch.</span>
<span class="sd">    where: TensorTrain, TT-tensor or TT-matrix on which tangent space to project</span>
<span class="sd">    weights: python list or tf.Tensor of numbers or None, weights of the sum</span>

<span class="sd">  Returns:</span>
<span class="sd">     a TensorTrain with the TT-ranks equal 2 * tangent_space_tens.get_tt_ranks()</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Always work with batch of TT objects for simplicity.</span>
  <span class="n">what</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">expand_batch_dim</span><span class="p">(</span><span class="n">what</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">where</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The first argument should be a TensorTrain object, got &#39;</span>
                     <span class="s1">&#39;&quot;</span><span class="si">%s</span><span class="s1">&quot;.&#39;</span> <span class="o">%</span> <span class="n">where</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span> <span class="o">!=</span> <span class="n">what</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The shapes of the tensor we want to project and of the &#39;</span>
                     <span class="s1">&#39;tensor on which tangent space we want to project should &#39;</span>
                     <span class="s1">&#39;match, got </span><span class="si">%s</span><span class="s1"> and </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span>
                     <span class="p">(</span><span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                      <span class="n">what</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()))</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">where</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">what</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Dtypes of the arguments should coincide, got </span><span class="si">%s</span><span class="s1"> and </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span>
                     <span class="p">(</span><span class="n">where</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                      <span class="n">what</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

  <span class="n">left_tangent_space_tens</span> <span class="o">=</span> <span class="n">decompositions</span><span class="o">.</span><span class="n">orthogonalize_tt_cores</span><span class="p">(</span>
    <span class="n">where</span><span class="p">)</span>
  <span class="n">right_tangent_space_tens</span> <span class="o">=</span> <span class="n">decompositions</span><span class="o">.</span><span class="n">orthogonalize_tt_cores</span><span class="p">(</span>
    <span class="n">left_tangent_space_tens</span><span class="p">,</span> <span class="n">left_to_right</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

  <span class="n">ndims</span> <span class="o">=</span> <span class="n">where</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">where</span><span class="o">.</span><span class="n">dtype</span>
  <span class="n">raw_shape</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_raw_shape</span><span class="p">(</span><span class="n">where</span><span class="p">)</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_batch_size</span><span class="p">(</span><span class="n">what</span><span class="p">)</span>
  <span class="n">right_tangent_tt_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_tt_ranks</span><span class="p">(</span><span class="n">right_tangent_space_tens</span><span class="p">)</span>
  <span class="n">left_tangent_tt_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">lazy_tt_ranks</span><span class="p">(</span><span class="n">left_tangent_space_tens</span><span class="p">)</span>

  <span class="c1"># For einsum notation.</span>
  <span class="n">mode_str</span> <span class="o">=</span> <span class="s1">&#39;ij&#39;</span> <span class="k">if</span> <span class="n">where</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;i&#39;</span>
  <span class="n">right_rank_dim</span> <span class="o">=</span> <span class="n">where</span><span class="o">.</span><span class="n">right_tt_rank_dim</span>
  <span class="n">left_rank_dim</span> <span class="o">=</span> <span class="n">where</span><span class="o">.</span><span class="n">left_tt_rank_dim</span>
  <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">weights_shape</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
    <span class="n">output_is_batch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights_shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">weights_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">output_is_batch</span> <span class="o">=</span> <span class="bp">False</span>
  <span class="n">output_batch_str</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span> <span class="k">if</span> <span class="n">output_is_batch</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
  <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
    <span class="n">right_rank_dim</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">left_rank_dim</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">output_batch_size</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>

  <span class="c1"># Prepare rhs vectors.</span>
  <span class="c1"># rhs[core_idx] is of size</span>
  <span class="c1">#   batch_size x tensor_tt_ranks[core_idx] x tangent_tt_ranks[core_idx]</span>
  <span class="n">rhs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">ndims</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">rhs</span><span class="p">[</span><span class="n">ndims</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">tens_core</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">right_tang_core</span> <span class="o">=</span> <span class="n">right_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sa{0}b,sbd,c{0}d-&gt;sac&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
    <span class="n">rhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">tens_core</span><span class="p">,</span> <span class="n">rhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                              <span class="n">right_tang_core</span><span class="p">)</span>

  <span class="c1"># Prepare lhs vectors.</span>
  <span class="c1"># lhs[core_idx] is of size</span>
  <span class="c1">#   batch_size x tangent_tt_ranks[core_idx] x tensor_tt_ranks[core_idx]</span>
  <span class="n">lhs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">ndims</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">lhs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">tens_core</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">left_tang_core</span> <span class="o">=</span> <span class="n">left_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sab,a{0}c,sb{0}d-&gt;scd&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
    <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">left_tang_core</span><span class="p">,</span>
                                  <span class="n">tens_core</span><span class="p">)</span>

  <span class="c1"># Left to right sweep.</span>
  <span class="n">res_cores_list</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span><span class="p">):</span>
    <span class="n">tens_core</span> <span class="o">=</span> <span class="n">what</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">left_tang_core</span> <span class="o">=</span> <span class="n">left_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">right_tang_core</span> <span class="o">=</span> <span class="n">right_tangent_space_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">core_idx</span> <span class="o">&lt;</span> <span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sab,sb{0}c-&gt;sa{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
      <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">tens_core</span><span class="p">)</span>
      <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;a{0}b,sbc-&gt;sa{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
      <span class="n">proj_core</span> <span class="o">-=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">left_tang_core</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
      <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sa{0}b,sbc-&gt;a{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
        <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">proj_core</span><span class="p">,</span> <span class="n">rhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sa{0}b,sbc-&gt;sa{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">,</span> <span class="n">output_batch_str</span><span class="p">)</span>
        <span class="n">proj_core_s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">proj_core</span><span class="p">,</span> <span class="n">rhs</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;s{1},sa{0}c-&gt;{1}a{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">,</span> <span class="n">output_batch_str</span><span class="p">)</span>
        <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">proj_core_s</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">core_idx</span> <span class="o">==</span> <span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sab,sb{0}c-&gt;a{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">)</span>
        <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">tens_core</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;sab,sb{0}c-&gt;sa{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">,</span> <span class="n">output_batch_str</span><span class="p">)</span>
        <span class="n">proj_core_s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">tens_core</span><span class="p">)</span>
        <span class="n">einsum_str</span> <span class="o">=</span> <span class="s1">&#39;s{1},sa{0}c-&gt;{1}a{0}c&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode_str</span><span class="p">,</span> <span class="n">output_batch_str</span><span class="p">)</span>
        <span class="n">proj_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">einsum_str</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">proj_core_s</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
      <span class="c1"># Add batch dimension of size output_batch_size to left_tang_core and</span>
      <span class="c1"># right_tang_core</span>
      <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">left_tang_core</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">right_tang_core</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">where</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
        <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">extended_left_tang_core</span><span class="p">,</span>
                                          <span class="p">[</span><span class="n">output_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">extended_right_tang_core</span><span class="p">,</span>
                                           <span class="p">[</span><span class="n">output_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">extended_left_tang_core</span><span class="p">,</span>
                                          <span class="p">[</span><span class="n">output_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">extended_right_tang_core</span><span class="p">,</span>
                                           <span class="p">[</span><span class="n">output_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">extended_left_tang_core</span> <span class="o">=</span> <span class="n">left_tang_core</span>
      <span class="n">extended_right_tang_core</span> <span class="o">=</span> <span class="n">right_tang_core</span>

    <span class="k">if</span> <span class="n">core_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">res_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">proj_core</span><span class="p">,</span> <span class="n">extended_left_tang_core</span><span class="p">),</span>
                           <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">core_idx</span> <span class="o">==</span> <span class="n">ndims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">res_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">extended_right_tang_core</span><span class="p">,</span> <span class="n">proj_core</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">left_rank_dim</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">rank_1</span> <span class="o">=</span> <span class="n">right_tangent_tt_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="n">rank_2</span> <span class="o">=</span> <span class="n">left_tangent_tt_ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">where</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
        <span class="n">mode_size_n</span> <span class="o">=</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">core_idx</span><span class="p">]</span>
        <span class="n">mode_size_m</span> <span class="o">=</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">core_idx</span><span class="p">]</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">rank_1</span><span class="p">,</span> <span class="n">mode_size_n</span><span class="p">,</span> <span class="n">mode_size_m</span><span class="p">,</span> <span class="n">rank_2</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">mode_size</span> <span class="o">=</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">core_idx</span><span class="p">]</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">rank_1</span><span class="p">,</span> <span class="n">mode_size</span><span class="p">,</span> <span class="n">rank_2</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">output_batch_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape</span>
      <span class="n">zeros</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">upper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">extended_right_tang_core</span><span class="p">,</span> <span class="n">zeros</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
      <span class="n">lower</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">proj_core</span><span class="p">,</span> <span class="n">extended_left_tang_core</span><span class="p">),</span>
                        <span class="n">axis</span><span class="o">=</span><span class="n">right_rank_dim</span><span class="p">)</span>
      <span class="n">res_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">upper</span><span class="p">,</span> <span class="n">lower</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">left_rank_dim</span><span class="p">)</span>
    <span class="n">res_cores_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res_core</span><span class="p">)</span>
  <span class="c1"># TODO: TT-ranks.</span>
  <span class="k">if</span> <span class="n">output_is_batch</span><span class="p">:</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">res_cores_list</span><span class="p">,</span> <span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="n">output_batch_size</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">res_cores_list</span><span class="p">,</span> <span class="n">where</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">())</span>

  <span class="n">res</span><span class="o">.</span><span class="n">projection_on</span> <span class="o">=</span> <span class="n">where</span>
  <span class="k">return</span> <span class="n">res</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.quadratic_form">
    <p>def <span class="ident">quadratic_form</span>(</p><p>A, b, c)</p>
    </div>
    

    
  
    <div class="desc"><p>Computes the quadratic form b^t A c where A is a TT-matrix (or a batch).</p>
<p>Args:
  A: <code>TensorTrain</code> object containing a TT-matrix or <code>TensorTrainBatch</code>
    with a batch of TT-matrices.
  b: <code>TensorTrain</code> object containing a TT-vector or <code>TensorTrainBatch</code>
    with a batch of TT-vectors.
  c: <code>TensorTrain</code> object containing a TT-vector or <code>TensorTrainBatch</code>
    with a batch of TT-vectors.</p>
<p>Returns:
  A number, the value of the quadratic form if all the arguments are
    <code>TensorTrain</code>s.
  OR tf.tensor of size batch_size if at least one of the arguments is
    <code>TensorTrainBatch</code></p>
<p>Raises:
  ValueError if the argument is not a TT-matrix or if the shapes are
    not consistent.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.quadratic_form', this);">Show source &equiv;</a></p>
  <div id="source-t3f.quadratic_form" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">quadratic_form</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes the quadratic form b^t A c where A is a TT-matrix (or a batch).</span>

<span class="sd">  Args:</span>
<span class="sd">    A: `TensorTrain` object containing a TT-matrix or `TensorTrainBatch`</span>
<span class="sd">      with a batch of TT-matrices.</span>
<span class="sd">    b: `TensorTrain` object containing a TT-vector or `TensorTrainBatch`</span>
<span class="sd">      with a batch of TT-vectors.</span>
<span class="sd">    c: `TensorTrain` object containing a TT-vector or `TensorTrainBatch`</span>
<span class="sd">      with a batch of TT-vectors.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A number, the value of the quadratic form if all the arguments are</span>
<span class="sd">      `TensorTrain`s.</span>
<span class="sd">    OR tf.tensor of size batch_size if at least one of the arguments is</span>
<span class="sd">      `TensorTrainBatch`</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError if the argument is not a TT-matrix or if the shapes are</span>
<span class="sd">      not consistent.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">TensorTrainBase</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">A</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The arguments should be a TT-matrix.&#39;</span><span class="p">)</span>

  <span class="c1"># TODO: support tf.Tensor as b and c.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">TensorTrainBase</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">b</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The arguments should be a TT-matrix.&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">TensorTrainBase</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">c</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The arguments should be a TT-matrix.&#39;</span><span class="p">)</span>

  <span class="c1"># TODO: make a more efficient implementation taylored for this case.</span>
  <span class="k">return</span> <span class="n">flat_inner</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">tt_tt_matmul</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">transpose</span><span class="p">(</span><span class="n">c</span><span class="p">)))</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.random_matrix">
    <p>def <span class="ident">random_matrix</span>(</p><p>shape, tt_rank=2)</p>
    </div>
    

    
  
    <div class="desc"><p>Generate a random TT-matrix of given shape.</p>
<p>Args:
  shape: 2d array, shape[0] is the shape of the matrix row-index,
    shape[1] is the shape of the column index.
    shape[0] and shape[1] should have the same number of elements (d)
    Also supports ommiting one of the dimensions for vectors, e.g.
      random_matrix([[2, 2, 2], None])
    and
      random_matrix([None, [2, 2, 2]])
    will create an 8-element column and row vectors correspondingly.
  tt_rank: a number or a (d+1)-element array with ranks.</p>
<p>Returns:
  TensorTrain containing a TT-matrix of size
    np.prod(shape[0]) x np.prod(shape[1])</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.random_matrix', this);">Show source &equiv;</a></p>
  <div id="source-t3f.random_matrix" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">random_matrix</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">tt_rank</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate a random TT-matrix of given shape.</span>

<span class="sd">  Args:</span>
<span class="sd">    shape: 2d array, shape[0] is the shape of the matrix row-index,</span>
<span class="sd">      shape[1] is the shape of the column index.</span>
<span class="sd">      shape[0] and shape[1] should have the same number of elements (d)</span>
<span class="sd">      Also supports ommiting one of the dimensions for vectors, e.g.</span>
<span class="sd">        random_matrix([[2, 2, 2], None])</span>
<span class="sd">      and</span>
<span class="sd">        random_matrix([None, [2, 2, 2]])</span>
<span class="sd">      will create an 8-element column and row vectors correspondingly.</span>
<span class="sd">    tt_rank: a number or a (d+1)-element array with ranks.</span>

<span class="sd">  Returns:</span>
<span class="sd">    TensorTrain containing a TT-matrix of size</span>
<span class="sd">      np.prod(shape[0]) x np.prod(shape[1])</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># TODO: good distribution to init training.</span>
  <span class="c1"># In case the shape is immutable.</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="c1"># In case shape represents a vector, e.g. [None, [2, 2, 2]]</span>
  <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
  <span class="c1"># In case shape represents a vector, e.g. [[2, 2, 2], None]</span>
  <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tt_rank</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;shape should be 2d array&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;shape[0] should have the same length as shape[1]&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">shape</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;all elements in `shape` should be positive&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">tt_rank</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`rank` should be positive&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`rank` array has inappropriate size&#39;</span><span class="p">)</span>

  <span class="n">num_dims</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span>
  <span class="k">if</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">tt_rank</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_dims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="n">tt_rank</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
  <span class="c1"># TODO: check that ints?</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="c1"># TODO: variable (name?) scope.</span>
  <span class="n">tt_cores</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_dims</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_dims</span><span class="p">):</span>
    <span class="n">curr_core_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">tt_rank</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">],</span>
                       <span class="n">tt_rank</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">curr_core_shape</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tt_rank</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.random_matrix_batch">
    <p>def <span class="ident">random_matrix_batch</span>(</p><p>shape, tt_rank=2, batch_size=1)</p>
    </div>
    

    
  
    <div class="desc"><p>Generate a random batch of TT-matrices of given shape.</p>
<p>Args:
  shape: 2d array, shape[0] is the shape of the matrix row-index,
    shape[1] is the shape of the column index.
    shape[0] and shape[1] should have the same number of elements (d)
    Also supports ommiting one of the dimensions for vectors, e.g.
      random_matrix_batch([[2, 2, 2], None])
    and
      random_matrix_batch([None, [2, 2, 2]])
    will create a batch of one 8-element column and row vector correspondingly.
  tt_rank: a number or a (d+1)-element array with ranks.
  batch_size: an integer.</p>
<p>Returns:
  TensorTrainBatch containing a batch of TT-matrices of size
    np.prod(shape[0]) x np.prod(shape[1])</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.random_matrix_batch', this);">Show source &equiv;</a></p>
  <div id="source-t3f.random_matrix_batch" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">random_matrix_batch</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">tt_rank</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate a random batch of TT-matrices of given shape.</span>

<span class="sd">  Args:</span>
<span class="sd">    shape: 2d array, shape[0] is the shape of the matrix row-index,</span>
<span class="sd">      shape[1] is the shape of the column index.</span>
<span class="sd">      shape[0] and shape[1] should have the same number of elements (d)</span>
<span class="sd">      Also supports ommiting one of the dimensions for vectors, e.g.</span>
<span class="sd">        random_matrix_batch([[2, 2, 2], None])</span>
<span class="sd">      and</span>
<span class="sd">        random_matrix_batch([None, [2, 2, 2]])</span>
<span class="sd">      will create a batch of one 8-element column and row vector correspondingly.</span>
<span class="sd">    tt_rank: a number or a (d+1)-element array with ranks.</span>
<span class="sd">    batch_size: an integer.</span>

<span class="sd">  Returns:</span>
<span class="sd">    TensorTrainBatch containing a batch of TT-matrices of size</span>
<span class="sd">      np.prod(shape[0]) x np.prod(shape[1])</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># TODO: good distribution to init training.</span>
  <span class="c1"># In case the shape is immutable.</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="c1"># In case shape represents a vector, e.g. [None, [2, 2, 2]]</span>
  <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
  <span class="c1"># In case shape represents a vector, e.g. [[2, 2, 2], None]</span>
  <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tt_rank</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;shape should be 2d array&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;shape[0] should have the same length as shape[1]&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">shape</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;all elements in `shape` should be positive&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">tt_rank</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`rank` should be positive&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`rank` array has inappropriate size&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Batch size should be positive&#39;</span><span class="p">)</span>

  <span class="n">num_dims</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span>
  <span class="k">if</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">tt_rank</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_dims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="n">tt_rank</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
  <span class="c1"># TODO: check that ints?</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="c1"># TODO: variable (name?) scope.</span>
  <span class="n">tt_cores</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_dims</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_dims</span><span class="p">):</span>
    <span class="n">curr_core_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tt_rank</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">],</span>
                       <span class="n">tt_rank</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">curr_core_shape</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tt_rank</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.random_tensor">
    <p>def <span class="ident">random_tensor</span>(</p><p>shape, tt_rank=2)</p>
    </div>
    

    
  
    <div class="desc"><p>Generate a random TT-tensor of given shape.</p>
<p>Args:
  shape: array representing the shape of the future tensor
  tt_rank: a number or a (d+1)-element array with ranks.</p>
<p>Returns:
  TensorTrain containing a TT-tensor</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.random_tensor', this);">Show source &equiv;</a></p>
  <div id="source-t3f.random_tensor" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">random_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">tt_rank</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate a random TT-tensor of given shape.</span>

<span class="sd">  Args:</span>
<span class="sd">    shape: array representing the shape of the future tensor</span>
<span class="sd">    tt_rank: a number or a (d+1)-element array with ranks.</span>

<span class="sd">  Returns:</span>
<span class="sd">    TensorTrain containing a TT-tensor</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># TODO: good distribution to init training.</span>
  <span class="c1"># TODO: support shape and tt_ranks as TensorShape?.</span>
  <span class="c1"># TODO: support None as a dimension.</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tt_rank</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;shape should be 1d array&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">shape</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;all elements in `shape` should be positive&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">tt_rank</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`rank` should be positive&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="p">(</span><span class="n">shape</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`rank` array has inappropriate size&#39;</span><span class="p">)</span>

  <span class="n">num_dims</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">size</span>
  <span class="k">if</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">tt_rank</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_dims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">tt_rank</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tt_rank</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="c1"># TODO: check that ints?</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">tt_rank_ext</span> <span class="o">=</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="c1"># TODO: variable (name?) scope.</span>
  <span class="n">tt_cores</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_dims</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_dims</span><span class="p">):</span>
    <span class="n">curr_core_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">tt_rank_ext</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tt_rank_ext</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">curr_core_shape</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tt_rank_ext</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.random_tensor_batch">
    <p>def <span class="ident">random_tensor_batch</span>(</p><p>shape, tt_rank=2, batch_size=1)</p>
    </div>
    

    
  
    <div class="desc"><p>Generate a batch of random TT-tensors of given shape.</p>
<p>Args:
  shape: array representing the shape of the future tensor
  tt_rank: a number or a (d+1)-element array with ranks.
  batch_size: an integer.</p>
<p>Returns:
  TensorTrainBatch containing a TT-tensor</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.random_tensor_batch', this);">Show source &equiv;</a></p>
  <div id="source-t3f.random_tensor_batch" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">random_tensor_batch</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">tt_rank</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate a batch of random TT-tensors of given shape.</span>

<span class="sd">  Args:</span>
<span class="sd">    shape: array representing the shape of the future tensor</span>
<span class="sd">    tt_rank: a number or a (d+1)-element array with ranks.</span>
<span class="sd">    batch_size: an integer.</span>

<span class="sd">  Returns:</span>
<span class="sd">    TensorTrainBatch containing a TT-tensor</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># TODO: good distribution to init training.</span>
  <span class="c1"># TODO: support shape and tt_ranks as TensorShape?.</span>
  <span class="c1"># TODO: support None as a dimension.</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tt_rank</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;shape should be 1d array&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">shape</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;all elements in `shape` should be positive&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">tt_rank</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`rank` should be positive&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="p">(</span><span class="n">shape</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`rank` array has inappropriate size&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Batch size should be positive&#39;</span><span class="p">)</span>

  <span class="n">num_dims</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">size</span>
  <span class="k">if</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">tt_rank</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_dims</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">tt_rank</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tt_rank</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="c1"># TODO: check that ints?</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="n">tt_rank_ext</span> <span class="o">=</span> <span class="n">tt_rank</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="c1"># TODO: variable (name?) scope.</span>
  <span class="n">tt_cores</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_dims</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_dims</span><span class="p">):</span>
    <span class="n">curr_core_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tt_rank_ext</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tt_rank_ext</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">curr_core_shape</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tt_rank_ext</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.raw_shape">
    <p>def <span class="ident">raw_shape</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the shape of a TensorTrain.</p>
<p>This operation returns a 2-D integer tensor representing the shape of
the input.
If the input is a TT-tensor, the shape will have 1 x ndims() elements.
If the input is a TT-matrix, the shape will have 2 x ndims() elements
representing the underlying tensor shape of the matrix.</p>
<p>Args:
  tt: <code>TensorTrain</code> or <code>TensorTrainBatch</code> object.</p>
<p>Returns:
  A 2-D <code>Tensor</code> of size 1 x ndims() or 2 x ndims()</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.raw_shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.raw_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">raw_shape</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the shape of a TensorTrain.</span>

<span class="sd">  This operation returns a 2-D integer tensor representing the shape of</span>
<span class="sd">  the input.</span>
<span class="sd">  If the input is a TT-tensor, the shape will have 1 x ndims() elements.</span>
<span class="sd">  If the input is a TT-matrix, the shape will have 2 x ndims() elements</span>
<span class="sd">  representing the underlying tensor shape of the matrix.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrain` or `TensorTrainBatch` object.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A 2-D `Tensor` of size 1 x ndims() or 2 x ndims()</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">num_dims</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
  <span class="n">num_tensor_axis</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">())</span>
  <span class="n">final_raw_shape</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="c1"># TODO: ugly.</span>
  <span class="kn">from</span> <span class="nn">t3f.tensor_train</span> <span class="kn">import</span> <span class="n">TensorTrain</span>
  <span class="n">axes_shift</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">)</span> <span class="k">else</span> <span class="mi">2</span>
  <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tensor_axis</span><span class="p">):</span>
    <span class="n">curr_raw_shape</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_dims</span><span class="p">):</span>
      <span class="n">curr_raw_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">])[</span><span class="n">ax</span> <span class="o">+</span> <span class="n">axes_shift</span><span class="p">])</span>
    <span class="n">final_raw_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">curr_raw_shape</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">final_raw_shape</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.round">
    <p>def <span class="ident">round</span>(</p><p>tt, max_tt_rank=None, epsilon=None)</p>
    </div>
    

    
  
    <div class="desc"><p>TT-rounding procedure, returns a TT object with smaller TT-ranks.</p>
<p>Args:
  tt: <code>TensorTrain</code> object, TT-tensor or TT-matrix
  max_tt_rank: a number or a list of numbers
    If a number, than defines the maximal TT-rank of the result.
    If a list of numbers, than <code>max_tt_rank</code> length should be d+1
    (where d is the rank of <code>tens</code>) and <code>max_tt_rank[i]</code> defines
    the maximal (i+1)-th TT-rank of the result.
    The following two versions are equivalent
      <code>max_tt_rank = r</code>
    and
      <code>max_tt_rank = r * np.ones(d-1)</code>
  epsilon: a floating point number or None
    If the TT-ranks are not restricted (<code>max_tt_rank=np.inf</code>), then
    the result would be guarantied to be <code>epsilon</code> close to <code>tt</code>
    in terms of relative Frobenius error:
      ||res - tt||_F / ||tt||_F &lt;= epsilon
    If the TT-ranks are restricted, providing a loose <code>epsilon</code> may
    reduce the TT-ranks of the result.
    E.g.
      round(tt, max_tt_rank=100, epsilon=0.9)
    will probably return you a TT-tensor with TT-ranks close to 1, not 100.
    Note that providing a nontrivial (= not equal to None) <code>epsilon</code> will make
    the TT-ranks of the result undefined on the compilation stage
    (e.g. res.get_tt_ranks() will return None, but t3f.tt_ranks(res).eval()
    will work).</p>
<p>Returns:
  <code>TensorTrain</code> object containing a TT-tensor.</p>
<p>Raises:
  ValueError if max_tt_rank is less than 0, if max_tt_rank is not a number and
    not a vector of length d + 1 where d is the number of dimensions (rank) of
    the input tensor, if epsilon is less than 0.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.round', this);">Show source &equiv;</a></p>
  <div id="source-t3f.round" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">round</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">max_tt_rank</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;TT-rounding procedure, returns a TT object with smaller TT-ranks.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrain` object, TT-tensor or TT-matrix</span>
<span class="sd">    max_tt_rank: a number or a list of numbers</span>
<span class="sd">      If a number, than defines the maximal TT-rank of the result.</span>
<span class="sd">      If a list of numbers, than `max_tt_rank` length should be d+1</span>
<span class="sd">      (where d is the rank of `tens`) and `max_tt_rank[i]` defines</span>
<span class="sd">      the maximal (i+1)-th TT-rank of the result.</span>
<span class="sd">      The following two versions are equivalent</span>
<span class="sd">        `max_tt_rank = r`</span>
<span class="sd">      and</span>
<span class="sd">        `max_tt_rank = r * np.ones(d-1)`</span>
<span class="sd">    epsilon: a floating point number or None</span>
<span class="sd">      If the TT-ranks are not restricted (`max_tt_rank=np.inf`), then</span>
<span class="sd">      the result would be guarantied to be `epsilon` close to `tt`</span>
<span class="sd">      in terms of relative Frobenius error:</span>
<span class="sd">        ||res - tt||_F / ||tt||_F &lt;= epsilon</span>
<span class="sd">      If the TT-ranks are restricted, providing a loose `epsilon` may</span>
<span class="sd">      reduce the TT-ranks of the result.</span>
<span class="sd">      E.g.</span>
<span class="sd">        round(tt, max_tt_rank=100, epsilon=0.9)</span>
<span class="sd">      will probably return you a TT-tensor with TT-ranks close to 1, not 100.</span>
<span class="sd">      Note that providing a nontrivial (= not equal to None) `epsilon` will make</span>
<span class="sd">      the TT-ranks of the result undefined on the compilation stage</span>
<span class="sd">      (e.g. res.get_tt_ranks() will return None, but t3f.tt_ranks(res).eval()</span>
<span class="sd">      will work).</span>

<span class="sd">  Returns:</span>
<span class="sd">    `TensorTrain` object containing a TT-tensor.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError if max_tt_rank is less than 0, if max_tt_rank is not a number and</span>
<span class="sd">      not a vector of length d + 1 where d is the number of dimensions (rank) of</span>
<span class="sd">      the input tensor, if epsilon is less than 0.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">TensorTrainBatch</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_round_batch_tt</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">max_tt_rank</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">_round_tt</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">max_tt_rank</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.shape">
    <p>def <span class="ident">shape</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the shape of a TensorTrain.</p>
<p>This operation returns a 1-D integer tensor representing the shape of
  the input. For TT-matrices the shape would have two values, see raw_shape for
  the tensor shape.
If the input is a TensorTrainBatch, the first dimension of the output is the
  batch_size.</p>
<p>Args:
  tt: <code>TensorTrain</code> or <code>TensorTrainBatch</code> object.</p>
<p>Returns:
  A <code>Tensor</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the shape of a TensorTrain.</span>

<span class="sd">  This operation returns a 1-D integer tensor representing the shape of</span>
<span class="sd">    the input. For TT-matrices the shape would have two values, see raw_shape for</span>
<span class="sd">    the tensor shape.</span>
<span class="sd">  If the input is a TensorTrainBatch, the first dimension of the output is the</span>
<span class="sd">    batch_size.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrain` or `TensorTrainBatch` object.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">tt_raw_shape</span> <span class="o">=</span> <span class="n">raw_shape</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">tt</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_prod</span><span class="p">(</span><span class="n">tt_raw_shape</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tt_raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="c1"># TODO: ugly.</span>
  <span class="kn">from</span> <span class="nn">t3f.tensor_train_batch</span> <span class="kn">import</span> <span class="n">TensorTrainBatch</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">TensorTrainBatch</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">batch_size</span><span class="p">(</span><span class="n">tt</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="n">res</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">res</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.sparse_tt_flat_inner">
    <p>def <span class="ident">sparse_tt_flat_inner</span>(</p><p>sparse_a, tt_b)</p>
    </div>
    

    
  
    <div class="desc"><p>Inner product between a tf.SparseTensor and TT-tensor (or TT-matrix) along all axis.</p>
<p>The shapes of sparse_a and tt_b should coincide.</p>
<p>Args:
  sparse_a: tf.SparseTensor
  tt_b: <code>TensorTrain</code> object</p>
<p>Returns
  a number
  sum of products of all the elements of sparse_a and tt_b</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.sparse_tt_flat_inner', this);">Show source &equiv;</a></p>
  <div id="source-t3f.sparse_tt_flat_inner" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">sparse_tt_flat_inner</span><span class="p">(</span><span class="n">sparse_a</span><span class="p">,</span> <span class="n">tt_b</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Inner product between a tf.SparseTensor and TT-tensor (or TT-matrix) along all axis.</span>

<span class="sd">  The shapes of sparse_a and tt_b should coincide.</span>

<span class="sd">  Args:</span>
<span class="sd">    sparse_a: tf.SparseTensor</span>
<span class="sd">    tt_b: `TensorTrain` object</span>

<span class="sd">  Returns</span>
<span class="sd">    a number</span>
<span class="sd">    sum of products of all the elements of sparse_a and tt_b</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.sparse_tt_matmul">
    <p>def <span class="ident">sparse_tt_matmul</span>(</p><p>sparse_matrix_a, tt_matrix_b)</p>
    </div>
    

    
  
    <div class="desc"><p>Multiplies a sparse matrix by a TT-matrix, returns a regular matrix.</p>
<p>Args:
  sparse_matrix_a: tf.SparseTensor of size M x N
  tt_matrix_b: <code>TensorTrain</code> object containing a TT-matrix of size N x P</p>
<p>Returns
  tf.Tensor of size M x P</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.sparse_tt_matmul', this);">Show source &equiv;</a></p>
  <div id="source-t3f.sparse_tt_matmul" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">sparse_tt_matmul</span><span class="p">(</span><span class="n">sparse_matrix_a</span><span class="p">,</span> <span class="n">tt_matrix_b</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Multiplies a sparse matrix by a TT-matrix, returns a regular matrix.</span>

<span class="sd">  Args:</span>
<span class="sd">    sparse_matrix_a: tf.SparseTensor of size M x N</span>
<span class="sd">    tt_matrix_b: `TensorTrain` object containing a TT-matrix of size N x P</span>

<span class="sd">  Returns</span>
<span class="sd">    tf.Tensor of size M x P</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.squeeze_batch_dim">
    <p>def <span class="ident">squeeze_batch_dim</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Converts batch size 1 TensorTrainBatch into TensorTrain.</p>
<p>Args:
  tt: TensorTrain or TensorTrainBatch.</p>
<p>Returns:
  TensorTrain if the input is a TensorTrainBatch with batch_size == 1 (known
    at compilation stage) or a TensorTrain.
  TensorTrainBatch otherwise.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.squeeze_batch_dim', this);">Show source &equiv;</a></p>
  <div id="source-t3f.squeeze_batch_dim" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">squeeze_batch_dim</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Converts batch size 1 TensorTrainBatch into TensorTrain.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: TensorTrain or TensorTrainBatch.</span>

<span class="sd">  Returns:</span>
<span class="sd">    TensorTrain if the input is a TensorTrainBatch with batch_size == 1 (known</span>
<span class="sd">      at compilation stage) or a TensorTrain.</span>
<span class="sd">    TensorTrainBatch otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">tt</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">tt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">tt</span>
  <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
    <span class="c1"># tt object does not have attribute batch_size, probably already</span>
    <span class="c1"># a TensorTrain.</span>
    <span class="k">return</span> <span class="n">tt</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.to_tt_matrix">
    <p>def <span class="ident">to_tt_matrix</span>(</p><p>mat, shape, max_tt_rank=10, epsilon=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Converts a given matrix or vector to a TT-matrix.</p>
<p>The matrix dimensions should factorize into d numbers.
If e.g. the dimensions are prime numbers, it's usually better to
pad the matrix with zeros until the dimensions factorize into
(ideally) 3-8 numbers.</p>
<p>Args:
  mat: two dimensional tf.Tensor (a matrix).
  shape: two dimensional array (np.array or list of lists)
    Represents the tensor shape of the matrix.
    E.g. for a (a1 * a2 * a3) x (b1 * b2 * b3) matrix <code>shape</code> should be
    ((a1, a2, a3), (b1, b2, b3))
    <code>shape[0]`` and</code>shape[1]<code>` should have the same length.
    For vectors you may use ((a1, a2, a3), (1, 1, 1)) or, equivalently,
    ((a1, a2, a3), None)
  max_tt_rank: a number or a list of numbers
    If a number, than defines the maximal TT-rank of the result.
    If a list of numbers, than</code>max_tt_rank<code>length should be d+1
    (where d is the length of</code>shape[0]<code>) and</code>max_tt_rank[i]<code>defines
    the maximal (i+1)-th TT-rank of the result.
    The following two versions are equivalent</code>max_tt_rank = r<code>and</code>max_tt_rank = r * np.ones(d-1)<code>epsilon: a floating point number or None
    If the TT-ranks are not restricted (</code>max_tt_rank=np.inf<code>), then
    the result would be guarantied to be</code>epsilon<code>close to</code>mat<code>in terms of relative Frobenius error:
      ||res - mat||_F / ||mat||_F &lt;= epsilon
    If the TT-ranks are restricted, providing a loose</code>epsilon<code>may reduce
    the TT-ranks of the result.
    E.g.
      to_tt_matrix(mat, shape, max_tt_rank=100, epsilon=0.9)
    will probably return you a TT-matrix with TT-ranks close to 1, not 100.
    Note that providing a nontrivial (= not equal to None)</code>epsilon` will make
    the TT-ranks of the result undefined on the compilation stage
    (e.g. res.get_tt_ranks() will return None, but t3f.tt_ranks(res).eval()
    will work).</p>
<p>Returns:
  <code>TensorTrain</code> object containing a TT-matrix.</p>
<p>Raises:
  ValueError if max_tt_rank is less than 0, if max_tt_rank is not a number and
    not a vector of length d + 1 where d is the number of dimensions (rank) of
    the input tensor, if epsilon is less than 0.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.to_tt_matrix', this);">Show source &equiv;</a></p>
  <div id="source-t3f.to_tt_matrix" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">to_tt_matrix</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">max_tt_rank</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Converts a given matrix or vector to a TT-matrix.</span>

<span class="sd">  The matrix dimensions should factorize into d numbers.</span>
<span class="sd">  If e.g. the dimensions are prime numbers, it&#39;s usually better to</span>
<span class="sd">  pad the matrix with zeros until the dimensions factorize into</span>
<span class="sd">  (ideally) 3-8 numbers.</span>

<span class="sd">  Args:</span>
<span class="sd">    mat: two dimensional tf.Tensor (a matrix).</span>
<span class="sd">    shape: two dimensional array (np.array or list of lists)</span>
<span class="sd">      Represents the tensor shape of the matrix.</span>
<span class="sd">      E.g. for a (a1 * a2 * a3) x (b1 * b2 * b3) matrix `shape` should be</span>
<span class="sd">      ((a1, a2, a3), (b1, b2, b3))</span>
<span class="sd">      `shape[0]`` and `shape[1]`` should have the same length.</span>
<span class="sd">      For vectors you may use ((a1, a2, a3), (1, 1, 1)) or, equivalently,</span>
<span class="sd">      ((a1, a2, a3), None)</span>
<span class="sd">    max_tt_rank: a number or a list of numbers</span>
<span class="sd">      If a number, than defines the maximal TT-rank of the result.</span>
<span class="sd">      If a list of numbers, than `max_tt_rank` length should be d+1</span>
<span class="sd">      (where d is the length of `shape[0]`) and `max_tt_rank[i]` defines</span>
<span class="sd">      the maximal (i+1)-th TT-rank of the result.</span>
<span class="sd">      The following two versions are equivalent</span>
<span class="sd">        `max_tt_rank = r`</span>
<span class="sd">      and</span>
<span class="sd">        `max_tt_rank = r * np.ones(d-1)`</span>
<span class="sd">    epsilon: a floating point number or None</span>
<span class="sd">      If the TT-ranks are not restricted (`max_tt_rank=np.inf`), then</span>
<span class="sd">      the result would be guarantied to be `epsilon` close to `mat`</span>
<span class="sd">      in terms of relative Frobenius error:</span>
<span class="sd">        ||res - mat||_F / ||mat||_F &lt;= epsilon</span>
<span class="sd">      If the TT-ranks are restricted, providing a loose `epsilon` may reduce</span>
<span class="sd">      the TT-ranks of the result.</span>
<span class="sd">      E.g.</span>
<span class="sd">        to_tt_matrix(mat, shape, max_tt_rank=100, epsilon=0.9)</span>
<span class="sd">      will probably return you a TT-matrix with TT-ranks close to 1, not 100.</span>
<span class="sd">      Note that providing a nontrivial (= not equal to None) `epsilon` will make</span>
<span class="sd">      the TT-ranks of the result undefined on the compilation stage</span>
<span class="sd">      (e.g. res.get_tt_ranks() will return None, but t3f.tt_ranks(res).eval()</span>
<span class="sd">      will work).</span>

<span class="sd">  Returns:</span>
<span class="sd">    `TensorTrain` object containing a TT-matrix.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError if max_tt_rank is less than 0, if max_tt_rank is not a number and</span>
<span class="sd">      not a vector of length d + 1 where d is the number of dimensions (rank) of</span>
<span class="sd">      the input tensor, if epsilon is less than 0.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
  <span class="c1"># In case the shape is immutable.</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="c1"># In case shape represents a vector, e.g. [None, [2, 2, 2]]</span>
  <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="c1"># In case shape represents a vector, e.g. [[2, 2, 2], None]</span>
  <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

  <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">tens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">shape</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
  <span class="n">d</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="c1"># transpose_idx = 0, d, 1, d+1 ...</span>
  <span class="n">transpose_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
  <span class="n">transpose_idx</span> <span class="o">=</span> <span class="n">transpose_idx</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">tens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tens</span><span class="p">,</span> <span class="n">transpose_idx</span><span class="p">)</span>
  <span class="n">new_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">tens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tens</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>
  <span class="n">tt_tens</span> <span class="o">=</span> <span class="n">to_tt_tensor</span><span class="p">(</span><span class="n">tens</span><span class="p">,</span> <span class="n">max_tt_rank</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>
  <span class="n">tt_cores</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">static_tt_ranks</span> <span class="o">=</span> <span class="n">tt_tens</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>
  <span class="n">dynamic_tt_ranks</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">tt_ranks</span><span class="p">(</span><span class="n">tt_tens</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="n">curr_core</span> <span class="o">=</span> <span class="n">tt_tens</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">curr_rank</span> <span class="o">=</span> <span class="n">static_tt_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="k">if</span> <span class="n">curr_rank</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">curr_rank</span> <span class="o">=</span> <span class="n">dynamic_tt_ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">next_rank</span> <span class="o">=</span> <span class="n">static_tt_ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="k">if</span> <span class="n">next_rank</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">next_rank</span> <span class="o">=</span> <span class="n">dynamic_tt_ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">curr_core_new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">curr_rank</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">core_idx</span><span class="p">],</span>
                           <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">core_idx</span><span class="p">],</span> <span class="n">next_rank</span><span class="p">)</span>
    <span class="n">curr_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">curr_core</span><span class="p">,</span> <span class="n">curr_core_new_shape</span><span class="p">)</span>
    <span class="n">tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_core</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tt_tens</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">())</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.to_tt_tensor">
    <p>def <span class="ident">to_tt_tensor</span>(</p><p>tens, max_tt_rank=10, epsilon=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Converts a given tf.Tensor to a TT-tensor of the same shape.</p>
<p>Args:
  tens: tf.Tensor
  max_tt_rank: a number or a list of numbers
    If a number, than defines the maximal TT-rank of the result.
    If a list of numbers, than <code>max_tt_rank</code> length should be d+1
    (where d is the rank of <code>tens</code>) and <code>max_tt_rank[i]</code> defines
    the maximal (i+1)-th TT-rank of the result.
    The following two versions are equivalent
      <code>max_tt_rank = r</code>
    and
      <code>max_tt_rank = r * np.ones(d-1)</code>
  epsilon: a floating point number or None
    If the TT-ranks are not restricted (<code>max_tt_rank=np.inf</code>), then
    the result would be guarantied to be <code>epsilon</code> close to <code>tens</code>
    in terms of relative Frobenius error:
      ||res - tens||_F / ||tens||_F &lt;= epsilon
    If the TT-ranks are restricted, providing a loose <code>epsilon</code> may
    reduce the TT-ranks of the result.
    E.g.
      to_tt_tensor(tens, max_tt_rank=100, epsilon=0.9)
    will probably return you a TT-tensor with TT-ranks close to 1, not 100.
    Note that providing a nontrivial (= not equal to None) <code>epsilon</code> will make
    the TT-ranks of the result undefined on the compilation stage
    (e.g. res.get_tt_ranks() will return None, but t3f.tt_ranks(res).eval()
    will work).</p>
<p>Returns:
  <code>TensorTrain</code> object containing a TT-tensor.</p>
<p>Raises:
  ValueError if the rank (number of dimensions) of the input tensor is
    not defined, if max_tt_rank is less than 0, if max_tt_rank is not a number
    and not a vector of length d + 1 where d is the number of dimensions (rank)
    of the input tensor, if epsilon is less than 0.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.to_tt_tensor', this);">Show source &equiv;</a></p>
  <div id="source-t3f.to_tt_tensor" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">to_tt_tensor</span><span class="p">(</span><span class="n">tens</span><span class="p">,</span> <span class="n">max_tt_rank</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Converts a given tf.Tensor to a TT-tensor of the same shape.</span>

<span class="sd">  Args:</span>
<span class="sd">    tens: tf.Tensor</span>
<span class="sd">    max_tt_rank: a number or a list of numbers</span>
<span class="sd">      If a number, than defines the maximal TT-rank of the result.</span>
<span class="sd">      If a list of numbers, than `max_tt_rank` length should be d+1</span>
<span class="sd">      (where d is the rank of `tens`) and `max_tt_rank[i]` defines</span>
<span class="sd">      the maximal (i+1)-th TT-rank of the result.</span>
<span class="sd">      The following two versions are equivalent</span>
<span class="sd">        `max_tt_rank = r`</span>
<span class="sd">      and</span>
<span class="sd">        `max_tt_rank = r * np.ones(d-1)`</span>
<span class="sd">    epsilon: a floating point number or None</span>
<span class="sd">      If the TT-ranks are not restricted (`max_tt_rank=np.inf`), then</span>
<span class="sd">      the result would be guarantied to be `epsilon` close to `tens`</span>
<span class="sd">      in terms of relative Frobenius error:</span>
<span class="sd">        ||res - tens||_F / ||tens||_F &lt;= epsilon</span>
<span class="sd">      If the TT-ranks are restricted, providing a loose `epsilon` may</span>
<span class="sd">      reduce the TT-ranks of the result.</span>
<span class="sd">      E.g.</span>
<span class="sd">        to_tt_tensor(tens, max_tt_rank=100, epsilon=0.9)</span>
<span class="sd">      will probably return you a TT-tensor with TT-ranks close to 1, not 100.</span>
<span class="sd">      Note that providing a nontrivial (= not equal to None) `epsilon` will make</span>
<span class="sd">      the TT-ranks of the result undefined on the compilation stage</span>
<span class="sd">      (e.g. res.get_tt_ranks() will return None, but t3f.tt_ranks(res).eval()</span>
<span class="sd">      will work).</span>

<span class="sd">  Returns:</span>
<span class="sd">    `TensorTrain` object containing a TT-tensor.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError if the rank (number of dimensions) of the input tensor is</span>
<span class="sd">      not defined, if max_tt_rank is less than 0, if max_tt_rank is not a number</span>
<span class="sd">      and not a vector of length d + 1 where d is the number of dimensions (rank)</span>
<span class="sd">      of the input tensor, if epsilon is less than 0.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">tens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tens</span><span class="p">)</span>
  <span class="n">static_shape</span> <span class="o">=</span> <span class="n">tens</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
  <span class="n">dynamic_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tens</span><span class="p">)</span>
  <span class="c1"># Raises ValueError if ndims is not defined.</span>
  <span class="n">d</span> <span class="o">=</span> <span class="n">static_shape</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()</span>
  <span class="n">max_tt_rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">max_tt_rank</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">max_tt_rank</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Maximum TT-rank should be greater or equal to 1.&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">epsilon</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">epsilon</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Epsilon should be non-negative.&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">max_tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">max_tt_rank</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_tt_rank</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="k">elif</span> <span class="n">max_tt_rank</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">d</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;max_tt_rank should be a number or a vector of size (d+1) &#39;</span>
                     <span class="s1">&#39;where d is the number of dimensions (rank) of the tensor.&#39;</span><span class="p">)</span>
  <span class="n">ranks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">d</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">tt_cores</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">are_tt_ranks_defined</span> <span class="o">=</span> <span class="bp">True</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">curr_mode</span> <span class="o">=</span> <span class="n">static_shape</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="k">if</span> <span class="n">curr_mode</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">curr_mode</span> <span class="o">=</span> <span class="n">dynamic_shape</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">curr_mode</span>
    <span class="n">tens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tens</span><span class="p">,</span> <span class="p">[</span><span class="n">rows</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="n">tens</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="k">if</span> <span class="n">columns</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">columns</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tens</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">s</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">tens</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_tt_rank</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">max_tt_rank</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="p">)</span>
      <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
        <span class="c1"># Some of the values are undefined on the compilation stage and thus</span>
        <span class="c1"># they are tf.tensors instead of values.</span>
        <span class="n">min_dim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="p">)</span>
        <span class="n">ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">max_tt_rank</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">min_dim</span><span class="p">)</span>
        <span class="n">are_tt_ranks_defined</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span>
    <span class="n">core_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">ranks</span><span class="p">[</span><span class="n">core_idx</span><span class="p">],</span> <span class="n">curr_mode</span><span class="p">,</span> <span class="n">ranks</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">core_shape</span><span class="p">))</span>
    <span class="n">tens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
  <span class="n">last_mode</span> <span class="o">=</span> <span class="n">static_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
  <span class="k">if</span> <span class="n">last_mode</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">last_mode</span> <span class="o">=</span> <span class="n">dynamic_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">core_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">ranks</span><span class="p">[</span><span class="n">d</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">last_mode</span><span class="p">,</span> <span class="n">ranks</span><span class="p">[</span><span class="n">d</span><span class="p">])</span>
  <span class="n">tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tens</span><span class="p">,</span> <span class="n">core_shape</span><span class="p">))</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">are_tt_ranks_defined</span><span class="p">:</span>
    <span class="n">ranks</span> <span class="o">=</span> <span class="bp">None</span>
  <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">static_shape</span><span class="p">,</span> <span class="n">ranks</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.transpose">
    <p>def <span class="ident">transpose</span>(</p><p>tt_matrix)</p>
    </div>
    

    
  
    <div class="desc"><p>Transpose a TT-matrix or a batch of TT-matrices.</p>
<p>Args:
  tt_matrix: <code>TensorTrain</code> or <code>TensorTrainBatch</code> object containing a TT-matrix
    (or a batch of TT-matrices).</p>
<p>Returns:
  <code>TensorTrain</code> or <code>TensorTrainBatch</code> object containing a transposed TT-matrix
    (or a batch of TT-matrices).</p>
<p>Raises:
  ValueError if the argument is not a TT-matrix.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.transpose', this);">Show source &equiv;</a></p>
  <div id="source-t3f.transpose" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="n">tt_matrix</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Transpose a TT-matrix or a batch of TT-matrices.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt_matrix: `TensorTrain` or `TensorTrainBatch` object containing a TT-matrix</span>
<span class="sd">      (or a batch of TT-matrices).</span>

<span class="sd">  Returns:</span>
<span class="sd">    `TensorTrain` or `TensorTrainBatch` object containing a transposed TT-matrix</span>
<span class="sd">      (or a batch of TT-matrices).</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError if the argument is not a TT-matrix.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_matrix</span><span class="p">,</span> <span class="n">TensorTrainBase</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">tt_matrix</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The argument should be a TT-matrix.&#39;</span><span class="p">)</span>

  <span class="n">transposed_tt_cores</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tt_matrix</span><span class="o">.</span><span class="n">ndims</span><span class="p">()):</span>
    <span class="n">curr_core</span> <span class="o">=</span> <span class="n">tt_matrix</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_matrix</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
      <span class="n">transposed_tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">curr_core</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># TensorTrainBatch.</span>
      <span class="n">transposed_tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">curr_core</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>

  <span class="n">tt_matrix_shape</span> <span class="o">=</span> <span class="n">tt_matrix</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span>
  <span class="n">transposed_shape</span> <span class="o">=</span> <span class="n">tt_matrix_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">tt_matrix_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">tt_ranks</span> <span class="o">=</span> <span class="n">tt_matrix</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tt_matrix</span><span class="p">,</span> <span class="n">TensorTrain</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">transposed_tt_cores</span><span class="p">,</span> <span class="n">transposed_shape</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tt_matrix</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">transposed_tt_cores</span><span class="p">,</span> <span class="n">transposed_shape</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="p">,</span>
                            <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="t3f.tt_ranks">
    <p>def <span class="ident">tt_ranks</span>(</p><p>tt)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the TT-ranks of a TensorTrain.</p>
<p>This operation returns a 1-D integer tensor representing the TT-ranks of
the input.</p>
<p>Args:
  tt: <code>TensorTrain</code> or <code>TensorTrainBatch</code> object.</p>
<p>Returns:
  A <code>Tensor</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.tt_ranks', this);">Show source &equiv;</a></p>
  <div id="source-t3f.tt_ranks" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">tt_ranks</span><span class="p">(</span><span class="n">tt</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the TT-ranks of a TensorTrain.</span>

<span class="sd">  This operation returns a 1-D integer tensor representing the TT-ranks of</span>
<span class="sd">  the input.</span>

<span class="sd">  Args:</span>
<span class="sd">    tt: `TensorTrain` or `TensorTrainBatch` object.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">num_dims</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span>
  <span class="n">ranks</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_dims</span><span class="p">):</span>
    <span class="n">ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="n">tt</span><span class="o">.</span><span class="n">left_tt_rank_dim</span><span class="p">])</span>
  <span class="n">ranks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  

    <h2 class="section-title" id="header-classes">Classes</h2>
      
      <div class="item">
      <p id="t3f.TensorTrain" class="name">class <span class="ident">TensorTrain</span></p>
      
  
    <div class="desc"><p>Represents a Tensor Train object (a TT-tensor or TT-matrix).</p>
<p>t3f represents a Tensor Train object as a tuple of TT-cores.
```
@@<strong>init</strong>
@@get_raw_shape
@@get_shape
@@tt_cores
@@dtype
@@name
@@graph
@@ndims
@@get_tt_ranks
@@left_tt_rank_dim
@@right_tt_rank_dim
@@is_tt_matrix
@@is_variable
@@eval</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrain', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrain" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">TensorTrain</span><span class="p">(</span><span class="n">TensorTrainBase</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Represents a Tensor Train object (a TT-tensor or TT-matrix).</span>

<span class="sd">  t3f represents a Tensor Train object as a tuple of TT-cores.</span>
<span class="sd">  ```</span>
<span class="sd">  @@__init__</span>
<span class="sd">  @@get_raw_shape</span>
<span class="sd">  @@get_shape</span>
<span class="sd">  @@tt_cores</span>
<span class="sd">  @@dtype</span>
<span class="sd">  @@name</span>
<span class="sd">  @@graph</span>
<span class="sd">  @@ndims</span>
<span class="sd">  @@get_tt_ranks</span>
<span class="sd">  @@left_tt_rank_dim</span>
<span class="sd">  @@right_tt_rank_dim</span>
<span class="sd">  @@is_tt_matrix</span>
<span class="sd">  @@is_variable</span>
<span class="sd">  @@eval</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">convert_to_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `TensorTrain`.</span>

<span class="sd">    Args:</span>
<span class="sd">      tt_cores: A tuple of 3d or 4d tensor-like objects of shape</span>
<span class="sd">        `[r_k-1, n_k, r_k]`.</span>
<span class="sd">        Tensor-like can be numpy array, tf.Tensor, of tf.Variable</span>
<span class="sd">      shape: Shape of the underlying tensor. If None, tries to infer from the</span>
<span class="sd">        cores (not always possible even if it should be, e.g. if ranks are</span>
<span class="sd">        unknown, than the whole shape of a core can be unknown).</span>
<span class="sd">      tt_ranks: a TensorShape of length d+1 (d is the dimensionality of</span>
<span class="sd">        the underlying tensor). The first and the last ranks are assumed to</span>
<span class="sd">        equal to 1. If None, tries to infer the ranks from the cores.</span>
<span class="sd">      convert_to_tensors: bool, if True than convert each element of the</span>
<span class="sd">        tt_cores tuple into a tf.Tensor (e.g. to initialize from np.array)</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `TensorTrain`.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError if the provided TT-cores are not valid or inconsistent with</span>
<span class="sd">        the provided shape.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tt_cores</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">convert_to_tensors</span><span class="p">:</span>
      <span class="c1"># TODO: what does this namescope do?</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;TensorTrain&quot;</span><span class="p">,</span> <span class="n">tt_cores</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)):</span>
          <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;core</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">i</span>
          <span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">_are_tt_cores_valid</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The tt_cores provided to TensorTrain constructor are &#39;</span>
                       <span class="s1">&#39;not valid, have different dtypes, or are inconsistent &#39;</span>
                       <span class="s1">&#39;with the provided shape or TT-ranks.&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">clean_raw_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="o">=</span> <span class="n">_infer_raw_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="o">=</span> <span class="bp">None</span> <span class="k">if</span> <span class="n">tt_ranks</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">tt_ranks</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="o">=</span> <span class="n">_infer_tt_ranks</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">tt_cores</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A tuple of TT-cores.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple of 3d or 4d tensors shape</span>
<span class="sd">        `[r_k-1, n_k, r_k]`</span>
<span class="sd">      or</span>
<span class="sd">        `[r_k-1, n_k, m_k, r_k]`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">left_tt_rank_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The dimension of the left TT-rank in each TT-core.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mi">0</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">right_tt_rank_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The dimension of the right TT-rank in each TT-core.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
      <span class="c1"># The dimensions of each TT-core are</span>
      <span class="c1"># [left_rank, n, m, right_rank]</span>
      <span class="k">return</span> <span class="mi">3</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># The dimensions of each TT-core are</span>
      <span class="c1"># [left_rank, n, right_rank]</span>
      <span class="k">return</span> <span class="mi">2</span>

  <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A string describing the TensorTrain object, its TT-rank, and shape.&quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
    <span class="n">tt_ranks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>
    <span class="n">variable_str</span> <span class="o">=</span> <span class="s1">&#39; variable&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_variable</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
      <span class="n">raw_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span>
      <span class="k">return</span> <span class="s2">&quot;A TT-Matrix</span><span class="si">%s</span><span class="s2"> of size </span><span class="si">%d</span><span class="s2"> x </span><span class="si">%d</span><span class="s2">, underlying tensor &quot;</span> \
             <span class="s2">&quot;shape: </span><span class="si">%s</span><span class="s2"> x </span><span class="si">%s</span><span class="s2">, TT-ranks: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">variable_str</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                               <span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                               <span class="n">tt_ranks</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="s2">&quot;A Tensor Train</span><span class="si">%s</span><span class="s2"> of shape </span><span class="si">%s</span><span class="s2">, TT-ranks: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">variable_str</span><span class="p">,</span>
                                                              <span class="n">shape</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="p">)</span>

  <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">slice_spec</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Basic indexing, returns a `TensorTrain` containing the specified region.</span>

<span class="sd">    Examples:</span>
<span class="sd">      &gt;&gt;&gt; a = t3f.random_tensor((2, 3, 4))</span>
<span class="sd">      &gt;&gt;&gt; a[1, :, :]</span>
<span class="sd">      is a 2D TensorTrain 3 x 4.</span>
<span class="sd">      &gt;&gt;&gt; a[1:2, :, :]</span>
<span class="sd">      is a 3D TensorTrain 1 x 3 x 4</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Expected </span><span class="si">%d</span><span class="s1"> indices, got </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">(),</span>
                                                        <span class="nb">len</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">)))</span>
    <span class="n">new_tt_cores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">remainder</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">()):</span>
      <span class="n">curr_core</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">sliced_core</span> <span class="o">=</span> <span class="n">curr_core</span><span class="p">[:,</span> <span class="n">slice_spec</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">:]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">curr_core</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sliced_core</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()):</span>
          <span class="c1"># This index is specified exactly and we want to collapse this axis.</span>
          <span class="k">if</span> <span class="n">remainder</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="n">sliced_core</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">remainder</span><span class="p">,</span> <span class="n">sliced_core</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">remainder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c1"># Add reminder from the previous collapsed cores to the current</span>
            <span class="c1"># core.</span>
            <span class="n">sliced_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ab,bid-&gt;aid&#39;</span><span class="p">,</span> <span class="n">remainder</span><span class="p">,</span> <span class="n">sliced_core</span><span class="p">)</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="bp">None</span>
          <span class="n">new_tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sliced_core</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">remainder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="c1"># The reminder obtained from collapsing the last cores.</span>
      <span class="n">new_tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;aib,bd-&gt;aid&#39;</span><span class="p">,</span> <span class="n">new_tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">remainder</span><span class="p">)</span>
      <span class="n">remainder</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="c1"># TODO: infer the output ranks and shape.</span>
    <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">new_tt_cores</span><span class="p">)</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#t3f.TensorTrain">TensorTrain</a></li>
          <li><a href="#t3f.TensorTrainBase">TensorTrainBase</a></li>
          <li>__builtin__.object</li>
          </ul>
          <h3>Instance variables</h3>
            <div class="item">
            <p id="t3f.TensorTrain.dtype" class="name">var <span class="ident">dtype</span></p>
            
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.dtype">dtype</a></code>
    </p>

            
  
    <div class="desc inherited"><p>The <code>DType</code> of elements in this tensor.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrain.graph" class="name">var <span class="ident">graph</span></p>
            
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.graph">graph</a></code>
    </p>

            
  
    <div class="desc inherited"><p>The <code>Graph</code> that contains the tt_cores tensors.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrain.left_tt_rank_dim" class="name">var <span class="ident">left_tt_rank_dim</span></p>
            

            
  
    <div class="desc"><p>The dimension of the left TT-rank in each TT-core.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrain.name" class="name">var <span class="ident">name</span></p>
            
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.name">name</a></code>
    </p>

            
  
    <div class="desc inherited"><p>The name of the TensorTrain.</p>
<p>Returns:
  String, the scope in which the TT-cores are defined.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrain.op" class="name">var <span class="ident">op</span></p>
            
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.op">op</a></code>
    </p>

            
  
    <div class="desc inherited"><p>The <code>Operation</code> that evaluates all the cores.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrain.right_tt_rank_dim" class="name">var <span class="ident">right_tt_rank_dim</span></p>
            

            
  
    <div class="desc"><p>The dimension of the right TT-rank in each TT-core.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrain.tt_cores" class="name">var <span class="ident">tt_cores</span></p>
            
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.tt_cores">tt_cores</a></code>
    </p>

            
  
    <div class="desc"><p>A tuple of TT-cores.</p>
<p>Returns:
  A tuple of 3d or 4d tensors shape
    <code>[r_k-1, n_k, r_k]</code>
  or
    <code>[r_k-1, n_k, m_k, r_k]</code></p></div>
  <div class="source_cont">
</div>

            </div>
          <h3>Methods</h3>
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrain.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, tt_cores, shape=None, tt_ranks=None, convert_to_tensors=True)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.__init__">__init__</a></code>
    </p>

    
  
    <div class="desc"><p>Creates a <code>TensorTrain</code>.</p>
<p>Args:
  tt_cores: A tuple of 3d or 4d tensor-like objects of shape
    <code>[r_k-1, n_k, r_k]</code>.
    Tensor-like can be numpy array, tf.Tensor, of tf.Variable
  shape: Shape of the underlying tensor. If None, tries to infer from the
    cores (not always possible even if it should be, e.g. if ranks are
    unknown, than the whole shape of a core can be unknown).
  tt_ranks: a TensorShape of length d+1 (d is the dimensionality of
    the underlying tensor). The first and the last ranks are assumed to
    equal to 1. If None, tries to infer the ranks from the cores.
  convert_to_tensors: bool, if True than convert each element of the
    tt_cores tuple into a tf.Tensor (e.g. to initialize from np.array)</p>
<p>Returns:
  A <code>TensorTrain</code>.</p>
<p>Raises:
  ValueError if the provided TT-cores are not valid or inconsistent with
    the provided shape.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrain.__init__', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrain.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">convert_to_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates a `TensorTrain`.</span>
<span class="sd">  Args:</span>
<span class="sd">    tt_cores: A tuple of 3d or 4d tensor-like objects of shape</span>
<span class="sd">      `[r_k-1, n_k, r_k]`.</span>
<span class="sd">      Tensor-like can be numpy array, tf.Tensor, of tf.Variable</span>
<span class="sd">    shape: Shape of the underlying tensor. If None, tries to infer from the</span>
<span class="sd">      cores (not always possible even if it should be, e.g. if ranks are</span>
<span class="sd">      unknown, than the whole shape of a core can be unknown).</span>
<span class="sd">    tt_ranks: a TensorShape of length d+1 (d is the dimensionality of</span>
<span class="sd">      the underlying tensor). The first and the last ranks are assumed to</span>
<span class="sd">      equal to 1. If None, tries to infer the ranks from the cores.</span>
<span class="sd">    convert_to_tensors: bool, if True than convert each element of the</span>
<span class="sd">      tt_cores tuple into a tf.Tensor (e.g. to initialize from np.array)</span>
<span class="sd">  Returns:</span>
<span class="sd">    A `TensorTrain`.</span>
<span class="sd">  Raises:</span>
<span class="sd">    ValueError if the provided TT-cores are not valid or inconsistent with</span>
<span class="sd">      the provided shape.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">tt_cores</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">convert_to_tensors</span><span class="p">:</span>
    <span class="c1"># TODO: what does this namescope do?</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;TensorTrain&quot;</span><span class="p">,</span> <span class="n">tt_cores</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)):</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;core</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">i</span>
        <span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">_are_tt_cores_valid</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The tt_cores provided to TensorTrain constructor are &#39;</span>
                     <span class="s1">&#39;not valid, have different dtypes, or are inconsistent &#39;</span>
                     <span class="s1">&#39;with the provided shape or TT-ranks.&#39;</span><span class="p">)</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">clean_raw_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="o">=</span> <span class="n">_infer_raw_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span><span class="p">)</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="o">=</span> <span class="bp">None</span> <span class="k">if</span> <span class="n">tt_ranks</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">tt_ranks</span><span class="p">)</span>
  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="o">=</span> <span class="n">_infer_tt_ranks</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrain.eval">
    <p>def <span class="ident">eval</span>(</p><p>self, feed_dict=None, session=None)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.eval">eval</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Evaluates this sparse tensor in a <code>Session</code>.</p>
<p>Calling this method will execute all preceding operations that
produce the inputs needed for the operation that produces this
tensor.
<em>N.B.</em> Before invoking <code>SparseTensor.eval()</code>, its graph must have been
launched in a session, and either a default session must be
available, or <code>session</code> must be specified explicitly.</p>
<p>Args:
  feed_dict: A dictionary that maps <code>Tensor</code> objects to feed values.
    See <a href="../../api_docs/python/client.md#Session.run"><code>Session.run()</code></a> for a
    description of the valid feed values.
  session: (Optional.) The <code>Session</code> to be used to evaluate this sparse
    tensor. If none, the default session will be used.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrain.eval', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrain.eval" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Evaluates this sparse tensor in a `Session`.</span>
<span class="sd">  Calling this method will execute all preceding operations that</span>
<span class="sd">  produce the inputs needed for the operation that produces this</span>
<span class="sd">  tensor.</span>
<span class="sd">  *N.B.* Before invoking `SparseTensor.eval()`, its graph must have been</span>
<span class="sd">  launched in a session, and either a default session must be</span>
<span class="sd">  available, or `session` must be specified explicitly.</span>
<span class="sd">  Args:</span>
<span class="sd">    feed_dict: A dictionary that maps `Tensor` objects to feed values.</span>
<span class="sd">      See [`Session.run()`](../../api_docs/python/client.md#Session.run) for a</span>
<span class="sd">      description of the valid feed values.</span>
<span class="sd">    session: (Optional.) The `Session` to be used to evaluate this sparse</span>
<span class="sd">      tensor. If none, the default session will be used.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># TODO: implement feed_dict</span>
  <span class="k">if</span> <span class="n">session</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_session</span><span class="p">()</span>
  <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrain.get_raw_shape">
    <p>def <span class="ident">get_raw_shape</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.get_raw_shape">get_raw_shape</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Get tuple of <code>TensorShapes</code> representing the shapes of the underlying TT-tensor.</p>
<p>Tuple contains one <code>TensorShape</code> for TT-tensor and 2 <code>TensorShapes</code> for
TT-matrix</p>
<p>Returns:
  A tuple of <code>TensorShape</code> objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrain.get_raw_shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrain.get_raw_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_raw_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get tuple of `TensorShapes` representing the shapes of the underlying TT-tensor.</span>
<span class="sd">  Tuple contains one `TensorShape` for TT-tensor and 2 `TensorShapes` for</span>
<span class="sd">  TT-matrix</span>
<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `TensorShape` objects.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrain.get_shape">
    <p>def <span class="ident">get_shape</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.get_shape">get_shape</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Get the <code>TensorShape</code> representing the shape of the dense tensor.</p>
<p>Returns:
  A <code>TensorShape</code> object.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrain.get_shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrain.get_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get the `TensorShape` representing the shape of the dense tensor.</span>
<span class="sd">  Returns:</span>
<span class="sd">    A `TensorShape` object.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">raw_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span>
  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
    <span class="c1"># TODO: as list is not available if shape is partly known.</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">raw_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrain.get_tt_ranks">
    <p>def <span class="ident">get_tt_ranks</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.get_tt_ranks">get_tt_ranks</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Get the TT-ranks in an array of size <code>num_dims</code>+1.</p>
<p>The first and the last TT-rank are guarantied to be 1.</p>
<p>Returns:
  TensorShape of size <code>num_dims</code>+1.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrain.get_tt_ranks', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrain.get_tt_ranks" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_tt_ranks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get the TT-ranks in an array of size `num_dims`+1.</span>
<span class="sd">  The first and the last TT-rank are guarantied to be 1.</span>
<span class="sd">  Returns:</span>
<span class="sd">    TensorShape of size `num_dims`+1.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrain.is_tt_matrix">
    <p>def <span class="ident">is_tt_matrix</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.is_tt_matrix">is_tt_matrix</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Returns True if the TensorTrain object represents a TT-matrix.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrain.is_tt_matrix', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrain.is_tt_matrix" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">is_tt_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns True if the TensorTrain object represents a TT-matrix.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">2</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrain.is_variable">
    <p>def <span class="ident">is_variable</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.is_variable">is_variable</a></code>
    </p>

    
  
    <div class="desc inherited"><p>True if the TensorTrain object is a variable (e.g. is trainable).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrain.is_variable', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrain.is_variable" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">is_variable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;True if the TensorTrain object is a variable (e.g. is trainable).&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrain.ndims">
    <p>def <span class="ident">ndims</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.ndims">ndims</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Get the number of dimensions of the underlying TT-tensor.</p>
<p>Returns:
  A number.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrain.ndims', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrain.ndims" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">ndims</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get the number of dimensions of the underlying TT-tensor.</span>
<span class="sd">  Returns:</span>
<span class="sd">    A number.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      </div>
      </div>
      
      <div class="item">
      <p id="t3f.TensorTrainBase" class="name">class <span class="ident">TensorTrainBase</span></p>
      
  
    <div class="desc"><p>An abstract class that represents a collection of Tensor Train cores.
```
@@<strong>init</strong>
@@get_raw_shape
@@get_shape
@@tt_cores
@@dtype
@@name
@@graph
@@ndims
@@get_tt_ranks
@@is_tt_matrix
@@is_variable
@@eval</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBase', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBase" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">TensorTrainBase</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;An abstract class that represents a collection of Tensor Train cores.</span>
<span class="sd">  ```</span>
<span class="sd">  @@__init__</span>
<span class="sd">  @@get_raw_shape</span>
<span class="sd">  @@get_shape</span>
<span class="sd">  @@tt_cores</span>
<span class="sd">  @@dtype</span>
<span class="sd">  @@name</span>
<span class="sd">  @@graph</span>
<span class="sd">  @@ndims</span>
<span class="sd">  @@get_tt_ranks</span>
<span class="sd">  @@is_tt_matrix</span>
<span class="sd">  @@is_variable</span>
<span class="sd">  @@eval</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tt_cores</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `TensorTrainBase`.&quot;&quot;&quot;</span>
    <span class="k">pass</span>

  <span class="k">def</span> <span class="nf">get_raw_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get tuple of `TensorShapes` representing the shapes of the underlying TT-tensor.</span>

<span class="sd">    Tuple contains one `TensorShape` for TT-tensor and 2 `TensorShapes` for</span>
<span class="sd">    TT-matrix</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple of `TensorShape` objects.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span>

  <span class="k">def</span> <span class="nf">get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get the `TensorShape` representing the shape of the dense tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `TensorShape` object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">raw_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
      <span class="c1"># TODO: as list is not available if shape is partly known.</span>
      <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
      <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">raw_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">tt_cores</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A tuple of TT-cores.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The `DType` of elements in this tensor.&quot;&quot;&quot;</span>
    <span class="c1"># TODO: where is this created?</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The name of the TensorTrain.</span>

<span class="sd">    Returns:</span>
<span class="sd">      String, the scope in which the TT-cores are defined.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">core_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">core_name</span><span class="o">.</span><span class="n">rfind</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">core_name</span><span class="p">[:</span><span class="n">idx</span><span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The `Graph` that contains the tt_cores tensors.&quot;&quot;&quot;</span>
    <span class="c1"># TODO: check in init that the other cores are from the same graph.</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">graph</span>

  <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A string describing the TensorTrain object, its TT-rank and shape.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="ne">NotImplementedError</span>

  <span class="k">def</span> <span class="nf">ndims</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get the number of dimensions of the underlying TT-tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A number.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">get_tt_ranks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get the TT-ranks in an array of size `num_dims`+1.</span>

<span class="sd">    The first and the last TT-rank are guarantied to be 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">      TensorShape of size `num_dims`+1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span>

  <span class="k">def</span> <span class="nf">is_tt_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns True if the TensorTrain object represents a TT-matrix.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">2</span>

  <span class="k">def</span> <span class="nf">is_variable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;True if the TensorTrain object is a variable (e.g. is trainable).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">op</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The `Operation` that evaluates all the cores.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">op</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">])</span>

  <span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluates this sparse tensor in a `Session`.</span>

<span class="sd">    Calling this method will execute all preceding operations that</span>
<span class="sd">    produce the inputs needed for the operation that produces this</span>
<span class="sd">    tensor.</span>
<span class="sd">    *N.B.* Before invoking `SparseTensor.eval()`, its graph must have been</span>
<span class="sd">    launched in a session, and either a default session must be</span>
<span class="sd">    available, or `session` must be specified explicitly.</span>

<span class="sd">    Args:</span>
<span class="sd">      feed_dict: A dictionary that maps `Tensor` objects to feed values.</span>
<span class="sd">        See [`Session.run()`](../../api_docs/python/client.md#Session.run) for a</span>
<span class="sd">        description of the valid feed values.</span>
<span class="sd">      session: (Optional.) The `Session` to be used to evaluate this sparse</span>
<span class="sd">        tensor. If none, the default session will be used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: implement feed_dict</span>
    <span class="k">if</span> <span class="n">session</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_session</span><span class="p">()</span>
    <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">)</span>

  <span class="c1"># TODO: do we need this?</span>
  <span class="c1"># @staticmethod</span>
  <span class="c1"># def _override_operator(operator, func):</span>
  <span class="c1">#   _override_helper(SparseTensor, operator, func)</span>

  <span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a TensorTrain corresponding to element-wise sum tt_a + tt_b.</span>

<span class="sd">    Supports broadcasting (e.g. you can add TensorTrainBatch and TensorTrain).</span>
<span class="sd">    Just calls t3f.add, see its documentation for details.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: ugly.</span>
    <span class="c1"># We can&#39;t import ops in the beginning since it creates cyclic dependencies.</span>
    <span class="kn">from</span> <span class="nn">t3f</span> <span class="kn">import</span> <span class="n">ops</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>

  <span class="k">def</span> <span class="fm">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a TensorTrain corresponding to element-wise product tt_a * tt_b.</span>

<span class="sd">    Supports broadcasting (e.g. you can multiply TensorTrainBatch and</span>
<span class="sd">    TensorTrain).</span>
<span class="sd">    Just calls t3f.multiply, see its documentation for details.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: ugly.</span>
    <span class="c1"># We can&#39;t import ops in the beginning since it creates cyclic dependencies.</span>
    <span class="kn">from</span> <span class="nn">t3f</span> <span class="kn">import</span> <span class="n">ops</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>

  <span class="c1"># To support &#39;TT * 4&#39; as well as &#39;4 * TT&#39;.</span>
  <span class="fm">__rmul__</span> <span class="o">=</span> <span class="fm">__mul__</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#t3f.TensorTrainBase">TensorTrainBase</a></li>
          <li>__builtin__.object</li>
          </ul>
          <h3>Instance variables</h3>
            <div class="item">
            <p id="t3f.TensorTrainBase.dtype" class="name">var <span class="ident">dtype</span></p>
            

            
  
    <div class="desc"><p>The <code>DType</code> of elements in this tensor.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBase.graph" class="name">var <span class="ident">graph</span></p>
            

            
  
    <div class="desc"><p>The <code>Graph</code> that contains the tt_cores tensors.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBase.name" class="name">var <span class="ident">name</span></p>
            

            
  
    <div class="desc"><p>The name of the TensorTrain.</p>
<p>Returns:
  String, the scope in which the TT-cores are defined.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBase.op" class="name">var <span class="ident">op</span></p>
            

            
  
    <div class="desc"><p>The <code>Operation</code> that evaluates all the cores.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBase.tt_cores" class="name">var <span class="ident">tt_cores</span></p>
            

            
  
    <div class="desc"><p>A tuple of TT-cores.</p></div>
  <div class="source_cont">
</div>

            </div>
          <h3>Methods</h3>
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBase.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, tt_cores)</p>
    </div>
    

    
  
    <div class="desc"><p>Creates a <code>TensorTrainBase</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBase.__init__', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBase.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tt_cores</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates a `TensorTrainBase`.&quot;&quot;&quot;</span>
  <span class="k">pass</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBase.eval">
    <p>def <span class="ident">eval</span>(</p><p>self, feed_dict=None, session=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Evaluates this sparse tensor in a <code>Session</code>.</p>
<p>Calling this method will execute all preceding operations that
produce the inputs needed for the operation that produces this
tensor.
<em>N.B.</em> Before invoking <code>SparseTensor.eval()</code>, its graph must have been
launched in a session, and either a default session must be
available, or <code>session</code> must be specified explicitly.</p>
<p>Args:
  feed_dict: A dictionary that maps <code>Tensor</code> objects to feed values.
    See <a href="../../api_docs/python/client.md#Session.run"><code>Session.run()</code></a> for a
    description of the valid feed values.
  session: (Optional.) The <code>Session</code> to be used to evaluate this sparse
    tensor. If none, the default session will be used.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBase.eval', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBase.eval" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Evaluates this sparse tensor in a `Session`.</span>
<span class="sd">  Calling this method will execute all preceding operations that</span>
<span class="sd">  produce the inputs needed for the operation that produces this</span>
<span class="sd">  tensor.</span>
<span class="sd">  *N.B.* Before invoking `SparseTensor.eval()`, its graph must have been</span>
<span class="sd">  launched in a session, and either a default session must be</span>
<span class="sd">  available, or `session` must be specified explicitly.</span>
<span class="sd">  Args:</span>
<span class="sd">    feed_dict: A dictionary that maps `Tensor` objects to feed values.</span>
<span class="sd">      See [`Session.run()`](../../api_docs/python/client.md#Session.run) for a</span>
<span class="sd">      description of the valid feed values.</span>
<span class="sd">    session: (Optional.) The `Session` to be used to evaluate this sparse</span>
<span class="sd">      tensor. If none, the default session will be used.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># TODO: implement feed_dict</span>
  <span class="k">if</span> <span class="n">session</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_session</span><span class="p">()</span>
  <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBase.get_raw_shape">
    <p>def <span class="ident">get_raw_shape</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Get tuple of <code>TensorShapes</code> representing the shapes of the underlying TT-tensor.</p>
<p>Tuple contains one <code>TensorShape</code> for TT-tensor and 2 <code>TensorShapes</code> for
TT-matrix</p>
<p>Returns:
  A tuple of <code>TensorShape</code> objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBase.get_raw_shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBase.get_raw_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_raw_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get tuple of `TensorShapes` representing the shapes of the underlying TT-tensor.</span>
<span class="sd">  Tuple contains one `TensorShape` for TT-tensor and 2 `TensorShapes` for</span>
<span class="sd">  TT-matrix</span>
<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `TensorShape` objects.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBase.get_shape">
    <p>def <span class="ident">get_shape</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Get the <code>TensorShape</code> representing the shape of the dense tensor.</p>
<p>Returns:
  A <code>TensorShape</code> object.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBase.get_shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBase.get_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get the `TensorShape` representing the shape of the dense tensor.</span>
<span class="sd">  Returns:</span>
<span class="sd">    A `TensorShape` object.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">raw_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span>
  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
    <span class="c1"># TODO: as list is not available if shape is partly known.</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">raw_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBase.get_tt_ranks">
    <p>def <span class="ident">get_tt_ranks</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Get the TT-ranks in an array of size <code>num_dims</code>+1.</p>
<p>The first and the last TT-rank are guarantied to be 1.</p>
<p>Returns:
  TensorShape of size <code>num_dims</code>+1.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBase.get_tt_ranks', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBase.get_tt_ranks" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_tt_ranks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get the TT-ranks in an array of size `num_dims`+1.</span>
<span class="sd">  The first and the last TT-rank are guarantied to be 1.</span>
<span class="sd">  Returns:</span>
<span class="sd">    TensorShape of size `num_dims`+1.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBase.is_tt_matrix">
    <p>def <span class="ident">is_tt_matrix</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns True if the TensorTrain object represents a TT-matrix.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBase.is_tt_matrix', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBase.is_tt_matrix" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">is_tt_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns True if the TensorTrain object represents a TT-matrix.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">2</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBase.is_variable">
    <p>def <span class="ident">is_variable</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>True if the TensorTrain object is a variable (e.g. is trainable).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBase.is_variable', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBase.is_variable" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">is_variable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;True if the TensorTrain object is a variable (e.g. is trainable).&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBase.ndims">
    <p>def <span class="ident">ndims</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Get the number of dimensions of the underlying TT-tensor.</p>
<p>Returns:
  A number.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBase.ndims', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBase.ndims" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">ndims</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get the number of dimensions of the underlying TT-tensor.</span>
<span class="sd">  Returns:</span>
<span class="sd">    A number.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      </div>
      </div>
      
      <div class="item">
      <p id="t3f.TensorTrainBatch" class="name">class <span class="ident">TensorTrainBatch</span></p>
      
  
    <div class="desc"><p>Represents a batch of Tensor Train objects (TT-tensors or TT-matrices).</p>
<p>t3f represents a Tensor Train object as a tuple of TT-cores.
```
@@<strong>init</strong>
@@get_raw_shape
@@get_shape
@@tt_cores
@@dtype
@@name
@@graph
@@ndims
@@get_tt_ranks
@@left_tt_rank_dim
@@right_tt_rank_dim
@@is_tt_matrix
@@is_variable
@@eval</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBatch', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBatch" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">TensorTrainBatch</span><span class="p">(</span><span class="n">TensorTrainBase</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Represents a batch of Tensor Train objects (TT-tensors or TT-matrices).</span>

<span class="sd">  t3f represents a Tensor Train object as a tuple of TT-cores.</span>
<span class="sd">  ```</span>
<span class="sd">  @@__init__</span>
<span class="sd">  @@get_raw_shape</span>
<span class="sd">  @@get_shape</span>
<span class="sd">  @@tt_cores</span>
<span class="sd">  @@dtype</span>
<span class="sd">  @@name</span>
<span class="sd">  @@graph</span>
<span class="sd">  @@ndims</span>
<span class="sd">  @@get_tt_ranks</span>
<span class="sd">  @@left_tt_rank_dim</span>
<span class="sd">  @@right_tt_rank_dim</span>
<span class="sd">  @@is_tt_matrix</span>
<span class="sd">  @@is_variable</span>
<span class="sd">  @@eval</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">convert_to_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `TensorTrain`.</span>

<span class="sd">    Args:</span>
<span class="sd">      tt_cores: A tuple of 3d or 4d tensor-like objects of shape</span>
<span class="sd">        `[r_k-1, n_k, r_k]`.</span>
<span class="sd">        Tensor-like can be numpy array, tf.Tensor, of tf.Variable</span>
<span class="sd">      batch_size: number of elements in the batch. If None, tries to infer from</span>
<span class="sd">        the TT-cores (not always possible even if it should be, e.g. if ranks</span>
<span class="sd">        are unknown, than the whole shape of a core can be unknown).</span>
<span class="sd">      shape: Shape of the underlying tensor. If None, tries to infer from the</span>
<span class="sd">        TT-cores.</span>
<span class="sd">      tt_ranks: a TensorShape of length d+1 (d is the dimensionality of</span>
<span class="sd">        the underlying tensor). The first and the last ranks are assumed to</span>
<span class="sd">        equal to 1. If None, tries to infer the ranks from the cores.</span>
<span class="sd">      convert_to_tensors: bool, if True than convert each element of the</span>
<span class="sd">        tt_cores tuple into a tf.Tensor (e.g. to initialize from np.array)</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `TensorTrainBatch`.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError if the provided TT-cores are not valid or inconsistent with</span>
<span class="sd">        the provided shape.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tt_cores</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">convert_to_tensors</span><span class="p">:</span>
      <span class="c1"># TODO: what does this namescope do?</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;TensorTrainBatch&quot;</span><span class="p">,</span> <span class="n">tt_cores</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)):</span>
          <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;core</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">i</span>
          <span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">_are_batch_tt_cores_valid</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The tt_cores provided to TensorTrainBatch constructor &#39;</span>
                       <span class="s1">&#39;are not valid, have different dtypes, or are &#39;</span>
                       <span class="s1">&#39;inconsistent with the provided batch_size, shape, or &#39;</span>
                       <span class="s1">&#39;TT-ranks.&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">clean_raw_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="o">=</span> <span class="n">_infer_batch_raw_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="o">=</span> <span class="bp">None</span> <span class="k">if</span> <span class="n">tt_ranks</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">tt_ranks</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="o">=</span> <span class="n">_infer_batch_tt_ranks</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get the `TensorShape` representing the shape of the dense tensor.</span>

<span class="sd">    The first dimension is the batch_size.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `TensorShape` object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">TensorTrainBase</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shape</span><span class="p">)))</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">tt_cores</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A tuple of TT-cores.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple of 4d or 5d tensors shape</span>
<span class="sd">        `[batch_size, r_k-1, n_k, r_k]`</span>
<span class="sd">      or</span>
<span class="sd">        `[batch_size, r_k-1, n_k, m_k, r_k]`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The number of elements or None if not known.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">left_tt_rank_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The dimension of the left TT-rank in each TT-core.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mi">1</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">right_tt_rank_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The dimension of the right TT-rank in each TT-core.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
      <span class="c1"># The dimensions of each TT-core are</span>
      <span class="c1"># [batch_idx, left_rank, n, m, right_rank]</span>
      <span class="k">return</span> <span class="mi">4</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># The dimensions of each TT-core are</span>
      <span class="c1"># [batch_idx, left_rank, n, right_rank]</span>
      <span class="k">return</span> <span class="mi">3</span>

  <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A string describing the TensorTrainBatch, its TT-rank and shape.&quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
    <span class="n">tt_ranks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
      <span class="n">raw_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">()</span>
      <span class="n">type_str</span> <span class="o">=</span> <span class="s1">&#39;TT-matrix variables&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_variable</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;TT-matrices&#39;</span>
      <span class="k">return</span> <span class="s2">&quot;A </span><span class="si">%d</span><span class="s2"> element batch of </span><span class="si">%s</span><span class="s2"> of size </span><span class="si">%d</span><span class="s2"> x </span><span class="si">%d</span><span class="s2">, underlying tensor &quot;</span> \
             <span class="s2">&quot;shape: </span><span class="si">%s</span><span class="s2"> x </span><span class="si">%s</span><span class="s2">, TT-ranks: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">type_str</span><span class="p">,</span>
                                               <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                               <span class="n">raw_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">raw_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                               <span class="n">tt_ranks</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_variable</span><span class="p">():</span>
        <span class="n">type_str</span> <span class="o">=</span> <span class="s1">&#39;Tensor Train variables&#39;</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">type_str</span> <span class="o">=</span> <span class="s1">&#39;Tensor Trains&#39;</span>
      <span class="k">return</span> <span class="s2">&quot;A </span><span class="si">%d</span><span class="s2"> element batch of </span><span class="si">%s</span><span class="s2"> of shape </span><span class="si">%s</span><span class="s2">, TT-ranks: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> \
             <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">type_str</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="p">)</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">_do_collapse_dim</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">):</span>
    <span class="c1"># Returns true if slice_spec is specified exactly and we want to collapse</span>
    <span class="c1"># the corresponding axis, i.e. return an object with less dims. To be used</span>
    <span class="c1"># in indexing functions.</span>
    <span class="c1"># If its a actual slice, nothing to collapse. Otherwise (a number or</span>
    <span class="c1"># a tf.Tensor) want to collapse.</span>
    <span class="k">return</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">,</span> <span class="nb">slice</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_batch_dim_getitem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">element_spec</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;__getitem__ when provided only one (batch) index.</span>

<span class="sd">    Examples:</span>
<span class="sd">      a[1]</span>
<span class="sd">      a[1:3]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># This object index is specified exactly and we want to collapse the</span>
    <span class="c1"># batch_size axis, i.e. return a TensorTrain instead of a TensorTrainBatch.</span>
    <span class="n">do_collapse_batch_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_do_collapse_dim</span><span class="p">(</span><span class="n">element_spec</span><span class="p">)</span>

    <span class="n">new_tt_cores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">()):</span>
      <span class="n">curr_core</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
        <span class="n">new_tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_core</span><span class="p">[</span><span class="n">element_spec</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">new_tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_core</span><span class="p">[</span><span class="n">element_spec</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span>
    <span class="k">if</span> <span class="n">do_collapse_batch_dim</span><span class="p">:</span>
      <span class="c1"># This index is specified exactly and we want to collapse the batch_size</span>
      <span class="c1"># axis, i.e. return a TensorTrain instead of a TensorTrainBatch.</span>
      <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">new_tt_cores</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">batch_size</span> <span class="o">=</span> <span class="n">new_tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
      <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">new_tt_cores</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">(),</span>
                              <span class="bp">self</span><span class="o">.</span><span class="n">get_tt_ranks</span><span class="p">(),</span> <span class="n">batch_size</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_full_getitem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">slice_spec</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;__getitem__ when provided full index of length ndims + 1.</span>

<span class="sd">    Examples:</span>
<span class="sd">      a = t3f.random_tensor_batch((2, 3, 4), batch_size=5)</span>
<span class="sd">      a[:3, 1:2, 4, :]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Expected </span><span class="si">%d</span><span class="s1"> indices, got </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                                        <span class="nb">len</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">)))</span>
    <span class="c1"># This object index is specified exactly and we want to collapse the</span>
    <span class="c1"># batch_size axis, i.e. return a TensorTrain instead of a TensorTrainBatch.</span>
    <span class="n">do_collapse_batch_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_do_collapse_dim</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">remainder</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">new_tt_cores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">core_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">()):</span>
      <span class="n">curr_core</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">core_idx</span><span class="p">]</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tt_matrix</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">sliced_core</span> <span class="o">=</span> <span class="n">curr_core</span><span class="p">[</span><span class="n">slice_spec</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:,</span> <span class="n">slice_spec</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="p">:]</span>
        <span class="n">do_collapse_curr_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_do_collapse_dim</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">[</span><span class="n">core_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">do_collapse_curr_dim</span><span class="p">:</span>
          <span class="c1"># This index is specified exactly and we want to collapse this axis.</span>
          <span class="k">if</span> <span class="n">remainder</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="n">sliced_core</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">do_collapse_batch_dim</span><span class="p">:</span>
              <span class="n">remainder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ab,bd-&gt;ad&#39;</span><span class="p">,</span> <span class="n">remainder</span><span class="p">,</span> <span class="n">sliced_core</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
              <span class="n">remainder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;oab,obd-&gt;oad&#39;</span><span class="p">,</span> <span class="n">remainder</span><span class="p">,</span> <span class="n">sliced_core</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">remainder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c1"># Add reminder from the previous collapsed cores to the current</span>
            <span class="c1"># core.</span>
            <span class="k">if</span> <span class="n">do_collapse_batch_dim</span><span class="p">:</span>
              <span class="n">sliced_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ab,bid-&gt;aid&#39;</span><span class="p">,</span> <span class="n">remainder</span><span class="p">,</span> <span class="n">sliced_core</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
              <span class="n">sliced_core</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;oab,obid-&gt;oaid&#39;</span><span class="p">,</span> <span class="n">remainder</span><span class="p">,</span>
                                      <span class="n">sliced_core</span><span class="p">)</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="bp">None</span>
          <span class="n">new_tt_cores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sliced_core</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">remainder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="c1"># The reminder obtained from collapsing the last cores.</span>
      <span class="k">if</span> <span class="n">do_collapse_batch_dim</span><span class="p">:</span>
        <span class="n">new_tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;aib,bd-&gt;aid&#39;</span><span class="p">,</span> <span class="n">new_tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                     <span class="n">remainder</span><span class="p">)</span>

      <span class="k">else</span><span class="p">:</span>
        <span class="n">new_tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;oaib,obd-&gt;oaid&#39;</span><span class="p">,</span> <span class="n">new_tt_cores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                     <span class="n">remainder</span><span class="p">)</span>
      <span class="n">remainder</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="c1"># TODO: infer the output ranks and shape.</span>
    <span class="k">if</span> <span class="n">do_collapse_batch_dim</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">TensorTrain</span><span class="p">(</span><span class="n">new_tt_cores</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">TensorTrainBatch</span><span class="p">(</span><span class="n">new_tt_cores</span><span class="p">)</span>

  <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">slice_spec</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Basic indexing, returns a `TensorTrainBatch` with the specified region.</span>

<span class="sd">    Examples:</span>
<span class="sd">      &gt;&gt;&gt; a = t3f.random_tensor_batch((2, 3, 4), batch_size=5)</span>
<span class="sd">      &gt;&gt;&gt; a[1:3, :, :, :]</span>
<span class="sd">      is a 3D TensorTrainBatch 2 x 3 x 4 with batch_size = 2.</span>
<span class="sd">      &gt;&gt;&gt; a[1:3]</span>
<span class="sd">      the same as above, a 3D TensorTrainBatch 2 x 3 x 4 with batch_size = 2.</span>
<span class="sd">      &gt;&gt;&gt; a[1, :, :, :]</span>
<span class="sd">      is a 3D TensorTrain 2 x 3 x 4.</span>
<span class="sd">      &gt;&gt;&gt; a[1]</span>
<span class="sd">      the same as above, a 3D TensorTrain 2 x 3 x 4.</span>
<span class="sd">      &gt;&gt;&gt; a[1:3, :, 1, :]</span>
<span class="sd">      is a 2D TensorTrainBatch 2 x 4 with batch_size = 2.</span>
<span class="sd">      &gt;&gt;&gt; a[1, :, 1, :]</span>
<span class="sd">      is a 2D TensorTrain 2 x 4.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `TensorTrainBatch` or `TensorTrain` depending on whether the first</span>
<span class="sd">      (batch) dim was specified as a range or as a number.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">slice_only_batch_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
      <span class="c1"># The argument is not iterable, so it&#39;s a single slice, or a number, or a</span>
      <span class="c1"># tf.Tensor with a number.</span>
      <span class="n">slice_only_batch_dim</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="k">if</span> <span class="n">slice_only_batch_dim</span><span class="p">:</span>
      <span class="c1"># Indexing only for the batch_size axis, e.g. a[1:3].</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_dim_getitem</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_full_getitem</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;TensorTrainBatch.__getitem__: wrong number of &#39;</span>
                       <span class="s1">&#39;dimensions, expected 1 or </span><span class="si">%d</span><span class="s1">, got </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span>
                       <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndims</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">slice_spec</span><span class="p">)))</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#t3f.TensorTrainBatch">TensorTrainBatch</a></li>
          <li><a href="#t3f.TensorTrainBase">TensorTrainBase</a></li>
          <li>__builtin__.object</li>
          </ul>
          <h3>Instance variables</h3>
            <div class="item">
            <p id="t3f.TensorTrainBatch.batch_size" class="name">var <span class="ident">batch_size</span></p>
            

            
  
    <div class="desc"><p>The number of elements or None if not known.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBatch.dtype" class="name">var <span class="ident">dtype</span></p>
            
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.dtype">dtype</a></code>
    </p>

            
  
    <div class="desc inherited"><p>The <code>DType</code> of elements in this tensor.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBatch.graph" class="name">var <span class="ident">graph</span></p>
            
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.graph">graph</a></code>
    </p>

            
  
    <div class="desc inherited"><p>The <code>Graph</code> that contains the tt_cores tensors.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBatch.left_tt_rank_dim" class="name">var <span class="ident">left_tt_rank_dim</span></p>
            

            
  
    <div class="desc"><p>The dimension of the left TT-rank in each TT-core.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBatch.name" class="name">var <span class="ident">name</span></p>
            
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.name">name</a></code>
    </p>

            
  
    <div class="desc inherited"><p>The name of the TensorTrain.</p>
<p>Returns:
  String, the scope in which the TT-cores are defined.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBatch.op" class="name">var <span class="ident">op</span></p>
            
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.op">op</a></code>
    </p>

            
  
    <div class="desc inherited"><p>The <code>Operation</code> that evaluates all the cores.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBatch.right_tt_rank_dim" class="name">var <span class="ident">right_tt_rank_dim</span></p>
            

            
  
    <div class="desc"><p>The dimension of the right TT-rank in each TT-core.</p></div>
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="t3f.TensorTrainBatch.tt_cores" class="name">var <span class="ident">tt_cores</span></p>
            
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.tt_cores">tt_cores</a></code>
    </p>

            
  
    <div class="desc"><p>A tuple of TT-cores.</p>
<p>Returns:
  A tuple of 4d or 5d tensors shape
    <code>[batch_size, r_k-1, n_k, r_k]</code>
  or
    <code>[batch_size, r_k-1, n_k, m_k, r_k]</code></p></div>
  <div class="source_cont">
</div>

            </div>
          <h3>Methods</h3>
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBatch.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, tt_cores, shape=None, tt_ranks=None, batch_size=None, convert_to_tensors=True)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.__init__">__init__</a></code>
    </p>

    
  
    <div class="desc"><p>Creates a <code>TensorTrain</code>.</p>
<p>Args:
  tt_cores: A tuple of 3d or 4d tensor-like objects of shape
    <code>[r_k-1, n_k, r_k]</code>.
    Tensor-like can be numpy array, tf.Tensor, of tf.Variable
  batch_size: number of elements in the batch. If None, tries to infer from
    the TT-cores (not always possible even if it should be, e.g. if ranks
    are unknown, than the whole shape of a core can be unknown).
  shape: Shape of the underlying tensor. If None, tries to infer from the
    TT-cores.
  tt_ranks: a TensorShape of length d+1 (d is the dimensionality of
    the underlying tensor). The first and the last ranks are assumed to
    equal to 1. If None, tries to infer the ranks from the cores.
  convert_to_tensors: bool, if True than convert each element of the
    tt_cores tuple into a tf.Tensor (e.g. to initialize from np.array)</p>
<p>Returns:
  A <code>TensorTrainBatch</code>.</p>
<p>Raises:
  ValueError if the provided TT-cores are not valid or inconsistent with
    the provided shape.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBatch.__init__', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBatch.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
             <span class="n">convert_to_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates a `TensorTrain`.</span>
<span class="sd">  Args:</span>
<span class="sd">    tt_cores: A tuple of 3d or 4d tensor-like objects of shape</span>
<span class="sd">      `[r_k-1, n_k, r_k]`.</span>
<span class="sd">      Tensor-like can be numpy array, tf.Tensor, of tf.Variable</span>
<span class="sd">    batch_size: number of elements in the batch. If None, tries to infer from</span>
<span class="sd">      the TT-cores (not always possible even if it should be, e.g. if ranks</span>
<span class="sd">      are unknown, than the whole shape of a core can be unknown).</span>
<span class="sd">    shape: Shape of the underlying tensor. If None, tries to infer from the</span>
<span class="sd">      TT-cores.</span>
<span class="sd">    tt_ranks: a TensorShape of length d+1 (d is the dimensionality of</span>
<span class="sd">      the underlying tensor). The first and the last ranks are assumed to</span>
<span class="sd">      equal to 1. If None, tries to infer the ranks from the cores.</span>
<span class="sd">    convert_to_tensors: bool, if True than convert each element of the</span>
<span class="sd">      tt_cores tuple into a tf.Tensor (e.g. to initialize from np.array)</span>
<span class="sd">  Returns:</span>
<span class="sd">    A `TensorTrainBatch`.</span>
<span class="sd">  Raises:</span>
<span class="sd">    ValueError if the provided TT-cores are not valid or inconsistent with</span>
<span class="sd">      the provided shape.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">tt_cores</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">convert_to_tensors</span><span class="p">:</span>
    <span class="c1"># TODO: what does this namescope do?</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;TensorTrainBatch&quot;</span><span class="p">,</span> <span class="n">tt_cores</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)):</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;core</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">i</span>
        <span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">_are_batch_tt_cores_valid</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tt_ranks</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The tt_cores provided to TensorTrainBatch constructor &#39;</span>
                     <span class="s1">&#39;are not valid, have different dtypes, or are &#39;</span>
                     <span class="s1">&#39;inconsistent with the provided batch_size, shape, or &#39;</span>
                     <span class="s1">&#39;TT-ranks.&#39;</span><span class="p">)</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tt_cores</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="o">=</span> <span class="n">shapes</span><span class="o">.</span><span class="n">clean_raw_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span> <span class="o">=</span> <span class="n">_infer_batch_raw_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span><span class="p">)</span>
  <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="o">=</span> <span class="bp">None</span> <span class="k">if</span> <span class="n">tt_ranks</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">tt_ranks</span><span class="p">)</span>
  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span> <span class="o">=</span> <span class="n">_infer_batch_tt_ranks</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tt_cores</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBatch.eval">
    <p>def <span class="ident">eval</span>(</p><p>self, feed_dict=None, session=None)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.eval">eval</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Evaluates this sparse tensor in a <code>Session</code>.</p>
<p>Calling this method will execute all preceding operations that
produce the inputs needed for the operation that produces this
tensor.
<em>N.B.</em> Before invoking <code>SparseTensor.eval()</code>, its graph must have been
launched in a session, and either a default session must be
available, or <code>session</code> must be specified explicitly.</p>
<p>Args:
  feed_dict: A dictionary that maps <code>Tensor</code> objects to feed values.
    See <a href="../../api_docs/python/client.md#Session.run"><code>Session.run()</code></a> for a
    description of the valid feed values.
  session: (Optional.) The <code>Session</code> to be used to evaluate this sparse
    tensor. If none, the default session will be used.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBatch.eval', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBatch.eval" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Evaluates this sparse tensor in a `Session`.</span>
<span class="sd">  Calling this method will execute all preceding operations that</span>
<span class="sd">  produce the inputs needed for the operation that produces this</span>
<span class="sd">  tensor.</span>
<span class="sd">  *N.B.* Before invoking `SparseTensor.eval()`, its graph must have been</span>
<span class="sd">  launched in a session, and either a default session must be</span>
<span class="sd">  available, or `session` must be specified explicitly.</span>
<span class="sd">  Args:</span>
<span class="sd">    feed_dict: A dictionary that maps `Tensor` objects to feed values.</span>
<span class="sd">      See [`Session.run()`](../../api_docs/python/client.md#Session.run) for a</span>
<span class="sd">      description of the valid feed values.</span>
<span class="sd">    session: (Optional.) The `Session` to be used to evaluate this sparse</span>
<span class="sd">      tensor. If none, the default session will be used.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># TODO: implement feed_dict</span>
  <span class="k">if</span> <span class="n">session</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_session</span><span class="p">()</span>
  <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBatch.get_raw_shape">
    <p>def <span class="ident">get_raw_shape</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.get_raw_shape">get_raw_shape</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Get tuple of <code>TensorShapes</code> representing the shapes of the underlying TT-tensor.</p>
<p>Tuple contains one <code>TensorShape</code> for TT-tensor and 2 <code>TensorShapes</code> for
TT-matrix</p>
<p>Returns:
  A tuple of <code>TensorShape</code> objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBatch.get_raw_shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBatch.get_raw_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_raw_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get tuple of `TensorShapes` representing the shapes of the underlying TT-tensor.</span>
<span class="sd">  Tuple contains one `TensorShape` for TT-tensor and 2 `TensorShapes` for</span>
<span class="sd">  TT-matrix</span>
<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `TensorShape` objects.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_shape</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBatch.get_shape">
    <p>def <span class="ident">get_shape</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.get_shape">get_shape</a></code>
    </p>

    
  
    <div class="desc"><p>Get the <code>TensorShape</code> representing the shape of the dense tensor.</p>
<p>The first dimension is the batch_size.</p>
<p>Returns:
  A <code>TensorShape</code> object.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBatch.get_shape', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBatch.get_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get the `TensorShape` representing the shape of the dense tensor.</span>
<span class="sd">  The first dimension is the batch_size.</span>
<span class="sd">  Returns:</span>
<span class="sd">    A `TensorShape` object.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">TensorTrainBase</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shape</span><span class="p">)))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBatch.get_tt_ranks">
    <p>def <span class="ident">get_tt_ranks</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.get_tt_ranks">get_tt_ranks</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Get the TT-ranks in an array of size <code>num_dims</code>+1.</p>
<p>The first and the last TT-rank are guarantied to be 1.</p>
<p>Returns:
  TensorShape of size <code>num_dims</code>+1.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBatch.get_tt_ranks', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBatch.get_tt_ranks" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_tt_ranks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get the TT-ranks in an array of size `num_dims`+1.</span>
<span class="sd">  The first and the last TT-rank are guarantied to be 1.</span>
<span class="sd">  Returns:</span>
<span class="sd">    TensorShape of size `num_dims`+1.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tt_ranks</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBatch.is_tt_matrix">
    <p>def <span class="ident">is_tt_matrix</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.is_tt_matrix">is_tt_matrix</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Returns True if the TensorTrain object represents a TT-matrix.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBatch.is_tt_matrix', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBatch.is_tt_matrix" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">is_tt_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns True if the TensorTrain object represents a TT-matrix.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_raw_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">2</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBatch.is_variable">
    <p>def <span class="ident">is_variable</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.is_variable">is_variable</a></code>
    </p>

    
  
    <div class="desc inherited"><p>True if the TensorTrain object is a variable (e.g. is trainable).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBatch.is_variable', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBatch.is_variable" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">is_variable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;True if the TensorTrain object is a variable (e.g. is trainable).&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="t3f.TensorTrainBatch.ndims">
    <p>def <span class="ident">ndims</span>(</p><p>self)</p>
    </div>
    
    <p class="inheritance">
     <strong>Inheritance:</strong>
       <code><a href="#t3f.TensorTrainBase">TensorTrainBase</a></code>.<code><a href="#t3f.TensorTrainBase.ndims">ndims</a></code>
    </p>

    
  
    <div class="desc inherited"><p>Get the number of dimensions of the underlying TT-tensor.</p>
<p>Returns:
  A number.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-t3f.TensorTrainBatch.ndims', this);">Show source &equiv;</a></p>
  <div id="source-t3f.TensorTrainBatch.ndims" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">ndims</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get the number of dimensions of the underlying TT-tensor.</span>
<span class="sd">  Returns:</span>
<span class="sd">    A number.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tt_cores</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      </div>
      </div>

  </section>

    </article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Documentation generated by
      <a href="https://github.com/BurntSushi/pdoc">pdoc 0.3.2</a>
    </p>

    <p>pdoc is in the public domain with the
      <a href="http://unlicense.org">UNLICENSE</a></p>

    <p>Design by <a href="http://nadh.in">Kailash Nadh</a></p>
  </footer>
</div>
</body>
</html>
