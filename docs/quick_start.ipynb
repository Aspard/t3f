{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start\n",
    "\n",
    "#### [Open](https://colab.research.google.com/github/Bihaqo/t3f/blob/develop/docs/quick_start.ipynb) this page in an interactive mode via Google Colaboratory.\n",
    "\n",
    "In this quick starting guide we show the basics of working with t3f library. The main concept of the library is a TensorTrain object -- a compact (factorized) representation of a tensor (=multidimensional array). This is generalization of the matrix low-rank decomposition.\n",
    "\n",
    "\n",
    "To begin, [install T3F](https://t3f.readthedocs.io/en/latest/installation.html), import some libraries, and enable [eager execution mode](https://www.tensorflow.org/guide/eager) which simplifies workflow with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "try:\n",
    "    import t3f\n",
    "except ImportError:\n",
    "    # Install T3F if it's not already installed.\n",
    "    !git clone https://github.com/Bihaqo/t3f.git\n",
    "    !cd t3f; pip install .\n",
    "    import t3f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to and from TT-format\n",
    "------------------------------------------------\n",
    "\n",
    "Let's start with converting a dense (numpy) matrix into the TT-format, which in this case coinsides with the low-rank format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factors of the matrix:  (<tf.Tensor: id=21, shape=(1, 3, 3), dtype=float64, numpy=\n",
      "array([[[ 0.65136176, -0.73746107,  0.17854696],\n",
      "        [-0.35756836, -0.50587943, -0.78500374],\n",
      "        [ 0.66923293,  0.44747867, -0.59320327]]])>, <tf.Tensor: id=33, shape=(3, 4, 1), dtype=float64, numpy=\n",
      "array([[[-1.24713583],\n",
      "        [ 2.91632087],\n",
      "        [-1.11601069],\n",
      "        [ 0.64274219]],\n",
      "\n",
      "       [[-0.62437771],\n",
      "        [-0.24637761],\n",
      "        [-0.53469532],\n",
      "        [-1.02201685]],\n",
      "\n",
      "       [[-0.15679071],\n",
      "        [-0.16141657],\n",
      "        [-0.12988253],\n",
      "        [ 0.20265188]]])>)\n",
      "Original matrix: \n",
      "[[-0.37987684  2.05245337 -0.35579983  1.2085382 ]\n",
      " [ 0.88487745 -0.7914341   0.77149975  0.12811055]\n",
      " [-1.02101132  1.93720209 -0.90908913 -0.14740026]]\n",
      "Reconstructed matrix: \n",
      "tf.Tensor(\n",
      "[[-0.37987684  2.05245337 -0.35579983  1.2085382 ]\n",
      " [ 0.88487745 -0.7914341   0.77149975  0.12811055]\n",
      " [-1.02101132  1.93720209 -0.90908913 -0.14740026]], shape=(3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Generate a random dense matrix of size 3 x 4.\n",
    "a_dense = np.random.randn(3, 4)\n",
    "# Convert the matrix into the TT-format with TT-rank = 3 (the larger the TT-rank, the more exactly the tensor will be converted, but the more memory and time everything will take). For matrices, matrix rank coinsides with TT-rank.\n",
    "a_tt = t3f.to_tt_tensor(a_dense, max_tt_rank=3)\n",
    "# a_tt stores the factorized representation of the matrix, namely it stores the matrix as a product of two smaller matrices which are called TT-cores. You can access the TT-cores directly.\n",
    "print('factors of the matrix: ', a_tt.tt_cores)\n",
    "# To check that the convertions into the TT-format didn't change the matrix too much, let's convert it back and compare to the original.\n",
    "reconstructed_matrix = t3f.full(a_tt)\n",
    "print('Original matrix: ')\n",
    "print(a_dense)\n",
    "print('Reconstructed matrix: ')\n",
    "print(reconstructed_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same idea applies to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between the original tensor and the reconsrtucted one is 0.000001\n"
     ]
    }
   ],
   "source": [
    "# Generate a random dense tensor of size 3 x 2 x 2.\n",
    "a_dense = np.random.randn(3, 2, 2).astype(np.float32)\n",
    "# Convert the tensor into the TT-format with TT-rank = 3.\n",
    "a_tt = t3f.to_tt_tensor(a_dense, max_tt_rank=3)\n",
    "# The 3 TT-cores are available in \n",
    "# To check that the convertions into the TT-format didn't change the tensor too much, let's convert it back and compare to the original.\n",
    "reconstructed_tensor = t3f.full(a_tt)\n",
    "print('The difference between the original tensor and the reconsrtucted '\n",
    "      'one is %f' % np.linalg.norm(reconstructed_tensor - a_dense))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ariphmetic operations\n",
    "--------------------------------\n",
    "\n",
    "T3F is a library of different operations that can be applied to the tensors in the TT-format by working directly with the compact representation, i.e. without the need to materialize the tensors themself.\n",
    "Here are some basic examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm of the tensor is 0.968410\n",
      "The TT-ranks of a and b are 3 and 2. The TT-rank of their elementwise product is 6. The TT-rank of their product after rounding is 3. The difference between the exact and the rounded elementwise product is 0.003162.\n"
     ]
    }
   ],
   "source": [
    "# Create a random tensor of shape (3, 2, 2) directly in the TT-format (in contrast to generating a dense tensor and then converting it to TT).\n",
    "b_tt = t3f.random_tensor((3, 2, 2), tt_rank=2)\n",
    "# Compute the Frobenius norm of the tensor.\n",
    "norm = t3f.frobenius_norm(b_tt)\n",
    "print('Frobenius norm of the tensor is %f' % norm)\n",
    "# Compute the TT-representation of the sum or elementwise product of two TT-tensors.\n",
    "sum_tt = a_tt + b_tt\n",
    "prod_tt = a_tt * b_tt\n",
    "twice_a_tt = 2 * a_tt\n",
    "# Most operations on TT-tensors increase the TT-rank. After applying a seqeunce of operations the TT-rank can increase by too much and we may want to reduce it. To do that there is a rounding operation, which finds the closes tensor to the given one of a smaller rank.\n",
    "rounded_prod_tt = t3f.round(prod_tt, max_tt_rank=3)\n",
    "a_max_tt_rank = np.max(a_tt.get_tt_ranks())\n",
    "b_max_tt_rank = np.max(b_tt.get_tt_ranks())\n",
    "exact_prod_max_tt_rank = np.max(prod_tt.get_tt_ranks())\n",
    "rounded_prod_max_tt_rank = np.max(rounded_prod_tt.get_tt_ranks())\n",
    "difference = t3f.frobenius_norm(prod_tt - rounded_prod_tt)\n",
    "print('The TT-ranks of a and b are %d and %d. The TT-rank '\n",
    "      'of their elementwise product is %d. The TT-rank of '\n",
    "      'their product after rounding is %d. The difference '\n",
    "      'between the exact and the rounded elementwise '\n",
    "      'product is %f.' % (a_max_tt_rank, b_max_tt_rank,\n",
    "                         exact_prod_max_tt_rank,\n",
    "                         rounded_prod_max_tt_rank,\n",
    "                         difference))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with TT-matrices\n",
    "------------------------------------\n",
    "\n",
    "Recall that for 2-dimensional tensors the TT-format coincides with the matrix low-rank format. Hovewer, sometimes matrices can have full matrix rank, but some tensor structure (for example a kronecker product of matrices). In this case there is a special object called Matrix TT-format. You can think of it as a sum of kronecker products (although it's a bit more complicated than that).\n",
    "\n",
    "Let's say that you have a matrix of size 8 x 27. You can convert it into the matrix TT-format with 3 TT-cores of tensor shape (2, 2, 2) x (3, 3, 3) or, for example, into the matrix TT-format with 2 TT-cores of tensor shape (4, 2) x (3, 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm of the matrix is 8.127118\n"
     ]
    }
   ],
   "source": [
    "a_dense = np.random.rand(8, 27).astype(np.float32)\n",
    "a_matrix_tt = t3f.to_tt_matrix(a_dense, shape=((2, 2, 2), (3, 3, 3)), max_tt_rank=4)\n",
    "# Now you can work with 'a_matrix_tt' like with any other TT-object, e.g.\n",
    "print('Frobenius norm of the matrix is %f' % t3f.frobenius_norm(a_matrix_tt))\n",
    "2.0 * a_matrix_tt  # multiplication by a number.\n",
    "prod_tt = a_matrix_tt * a_matrix_tt  # Elementwise product of two TT-matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, additionally, you can also compute matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between multiplying matrix by vector in the TT-format and then converting the result into dense vector and multiplying dense matrix by dense vector is 0.000002.\n"
     ]
    }
   ],
   "source": [
    "vector_tt = t3f.random_matrix(((3, 3, 3), (1, 1, 1)), tt_rank=3)\n",
    "matvec_tt = t3f.matmul(a_matrix_tt, vector_tt)\n",
    "# Check that the result coinsides with np.matmul.\n",
    "matvec_expected = np.matmul(t3f.full(a_matrix_tt), t3f.full(vector_tt))\n",
    "difference = np.linalg.norm(matvec_expected - t3f.full(matvec_tt))\n",
    "print('Difference between multiplying matrix by vector in '\n",
    "      'the TT-format and then converting the result into '\n",
    "      'dense vector and multiplying dense matrix by '\n",
    "      'dense vector is %f.' % difference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
